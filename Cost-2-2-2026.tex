\documentclass[12pt,reqno]{amsart}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[pagebackref,colorlinks=true]{hyperref}
\usepackage{verbatim}
\usepackage{eucal,url,amssymb,stmaryrd,enumerate,amscd,}
%\usepackage{showkeys}
%\usepackage{refcheck}
\usepackage{amsfonts,amsmath,amsthm,amssymb,amscd,enumerate,eucal,url,stmaryrd}
\usepackage{mathtools}
\usepackage[margin=1in]{geometry}

\usepackage{mathrsfs}
%\setcounter{MaxMatrixCols}{10}

\numberwithin{equation}{section}


\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Rp}{\R_{>0}}
\newcommand{\Rpp}{\R_{\geq 0}}
\newcommand{\e}{\mathrm{e}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\newtheorem{notation}{Notation}
\newtheorem{convention}{Convention}
\usepackage{amsthm}

\newtheoremstyle{axiomstyle}
  {}{}                 % razmaci
  {\itshape}           % telo
  {}                   % indent
  {\bfseries}          % naslov
  {.}                  % tačka iza broja
  {0.5em}              % razmak
  {\thmname{#1}~\thmnumber{#2}\thmnote{ (#3)}} % OVO PRIKAZUJE (RG0...)
  
\theoremstyle{axiomstyle}
\newtheorem{axiom}{Axiom}

%\linespread{1.06} \sloppy \allowdisplaybreaks
%\def\R{\hbox{\ddpp R}}
%\def\medR{\hbox{\rcmed R}}
%\def\C{{\hbox{\ddpp C}}}
%\def\peqC{{\hbox{\rcpeq C}}}
%\def\toro{\hbox{\ddpp T}}
%\def\Z{\hbox{\ddpp Z}}
%\def\Q{\hbox{\ddpp Q}}
%\def\ene{\hbox{\ddpp N}}
%\def\Q{\hbox{\ddpp Q}}
%\def\L{\hbox{\ddpp L}}
%\def\P{\hbox{\ddpp P}}
%\def\ppp{\hspace*{-6pt}{\sc .}\hspace*{6pt}}
%\def\fra{{\frak a}}
%\def\frg{{\frak g}}
%\def\frh{{\frak h}}
%\def\frk{{\frak K}}
%\def\frt{{\frak t}}
%\def\gc{\frg_\peqC}
%\def\Re{{\frak R}{\frak e}\,}
%\def\Im{{\frak I}{\frak m}\,}
%\def\nilm{\Gamma\backslash G}
%\def\Mod{{\mathcal M}}
%\def\db{{\bar{\partial}}}
%\def\zzz{{\!\!\!}}
%\def\sqi{{\sqrt{-1\,}}}


\begin{document}

\begin{abstract}

 
We study a rigidity question for nonnegative functions on \(\R_{>0}\) that measure deviation of positive ratios from the equilibrium.
Our main result gives a uniqueness theorem for a function \(F:\R_{>0}\to\R_{\ge 0}\) under three explicit assumptions:
normalization \(F(1)=0\), a d'Alembert composition law on \(\R_{>0}\), and a quadratic calibration at the identity. 
We show that these conditions force \(F\) to coincide with the canonical reciprocal cost
\(J(x)=\tfrac12(x+x^{-1})-1\).
The associated function \(H(t)=F(e^t)+1\) satisfies the d'Alembert
functional equation and the calibration fixes the remaining scaling freedom,  
forcing the hyperbolic
cosine branch \(H(t)=\cosh t\) rather than \(H(t)=\cos t\). We also explain how each assumption is used, and we give counterexamples showing that without the composition law or the calibration the solution is no longer unique.





 


\vskip1.mm\noindent
\textbf{Keywords}:   d'Alembert functional equation; canonical cost; calibration; hyperbolic cosine.

\vskip1.mm
\noindent
\textbf{Mathematics Subject Classifications (2010)}: 39B52, 39B05, 39B22
\end{abstract}

\title[Uniqueness of the Canonical Reciprocal Cost]{Uniqueness of the Canonical Reciprocal Cost}
\date{\today}


\author{Jonathan Washburn}
\address[Jonathan Washburn]{Recognition Physics Institute Austin, Texas, USA}
\email{jon@recognitionphysics.org}
\author{Milan Zlatanovi\'c}
\address[Milan Zlatanovi\'c]{Department of Mathematics, Faculty of Science and Mathematics, University of Ni\v s, Vi\v segradska 33, 18000 Ni\v s, Serbia}
\email{zlatmilan@yahoo.com}
 


%\author{Elshad Allahyarov}
%\address[Elshad Allahyarov]{Recognition Physics Institute, Austin, TX, USA \\Institut für Theoretische Physik II: Weiche Materie, Heinrich-Heine-Universität Düsseldorf, Germany \\ 
%Theoretical Department, Joint Institute for High Temperatures, RAS, Moscow, Russia \\  Department of Physics, Case Western Reserve University, Cleveland, OH, USA }
%\email{elshad.allakhyarov@case.edu}

 
 
 

 
\maketitle 

\setcounter{tocdepth}{3}

%\tableofcontents

%%%\author{xxxx...}
%%%\address[xxxx...]{Univ...}
%%%\email{xxxx...}
\newcommand{\config}{\mathcal{C}}
\newcommand{\configR}{\mathcal{C}_R}



\section{Motivation and Introduction}

In many problems one measures deviation between positive ratios by a function
\(F:\R_{>0}\to\R_{\ge 0}\) with a minimum at \(x=1\). Typical examples appear in normalization problems,
multiplicative errors, and scale-invariant penalties. The choice of \(F\) is not uniquely determined by the basic requirements:
several different functions satisfy the same conditions
(symmetry, convexity, minimum at \(1\)) and lead to different conclusions.


For this reason we focus on a rigidity problem: under which explicit structural
assumptions is \(F\) uniquely determined?  In this paper we show that a
d'Alembert--type composition law on \(\R_{>0}\), together with normalization and a
single quadratic calibration at \(1\), forces
\[
F(x)=\frac12(x+x^{-1})-1.
\]
Equivalently, for \(H(t)=F(e^t)+1\) the assumptions imply that \(H\) satisfies the
d'Alembert functional equation and the calibration selects the hyperbolic branch
\(H(t)=\cosh t\).

 
%%%
Similar rigidity phenomena are well known in the theory of functional equations.
In particular, d’Alembert--type equations often admit only a very restricted class
of solutions once trivial cases are excluded. In many situations the functional
form is forced by the algebraic structure, with no free continuous parameters
\cite{EbanksStetkaer}.

A related rigidity already appears in the discrete case.
On the additive group $\mathbb{Z}$, solutions of d’Alembert’s functional equation
are completely determined by a single value, and all solutions are generated by
Chebyshev polynomials \cite{Davison}. This shows that even in the absence of any
regularity assumptions, the functional form can be fixed by the underlying
composition structure.

In the continuous case, bounded measurable solutions of d’Alembert’s equation
are again forced to have a fixed form, namely a cosine function \cite{Akkouchi}.
Taken together, rigidity results in discrete, continuous, and algebraic contexts
show that d’Alembert-type symmetry strongly restricts admissible solutions.

Motivated by these results, we study functions on $\mathbb{R}_{>0}$ satisfying a
d’Alembert composition law, namely
\[
F(xy)+F\Big(\dfrac x y\Big)=2F(x)F(y)+2F(x)+2F(y).
\]
Under a natural and minimal set of
assumptions, we show that such a function is uniquely determined.

We emphasize that the composition law is the central assumption in
Theorem~\ref{thm:main}. Indeed, there exist families of functions satisfying
normalization, reciprocity, and the quadratic behavior \eqref{behavior0}, but
failing to satisfy the composition law. For example,
\[
J_\varepsilon(x)
=\tfrac12(x+x^{-1}-2)+\varepsilon(x+x^{-1}-2)^2,\qquad \varepsilon>0,
\]
has these properties, but does not satisfy \eqref{eq1}.
Thus the composition law is essential for uniqueness.

In this sense, the canonical reciprocal function is not a modeling choice,
but a structural consequence of the imposed symmetry.

\smallskip
The paper is organized as follows. 
In Section~2 we introduce the basic definitions and notation, and we rewrite the problem in logarithmic coordinates.
We also recall the d’Alembert functional equation and some elementary properties.
In Section~3 we prove the main uniqueness theorem.
We show that the composition law, together with normalization and single quadratic calibration at $1$, forces the cost to be the canonical reciprocal function
\(J(x)=\tfrac12(x+x^{-1})-1\). Section 4 contains a stability result for approximate solutions of the d’Alembert equation.
In Section~5 we discuss further properties of \(J\), including its interpretation as a Bregman divergence, the associated metric, and the Chebyshev structure.
We also give examples showing that the assumptions of the main theorem are necessary.

Finally, the conclusion summarizes the results and points to possible future work.
%%


\subsection{The canonical reciprocal cost}

%{\color{red} za $x>0$, $x$ je strogo vece, mora $y>=0$}

\begin{definition} 
The function \(J:\Rp\to\Rpp\) defined by
\begin{equation}\label{canonreccost}
J(x):=\frac{x+x^{-1}}{2}-1
\end{equation}
is called {\rm the canonical reciprocal cost} function.
\end{definition}

The function \(J\) satisfies the following properties:
\begin{itemize}
    \item[(i)]  \emph{Normalization:} \(J(1)=0\);
    \item[(ii)]  \emph{Reciprocity:} \(J(x)=J(x^{-1})\);
    \item[(iii)] \emph{Nonnegativity:} For all $x\in \Rp$
    \[
    J(x)=\frac{(x-1)^2}{2x}\ge 0.
    \]
\end{itemize}

If we substitute $t=\ln x$, then
\[
J(\e^t)=\cosh(t)-1.
\]
 

\subsection{Main result}
We now state the main theorem of this paper, which establishes the uniqueness of the canonical reciprocal cost.

\begin{theorem}\label{thm:main}
Let \(F:\Rp\to\Rpp\). Assume that $F$ satisfies:
\begin{enumerate}
  \item[(i)] {Normalization:} \(F(1)=0\) 
 % \item[(ii)] {Reciprocity:} \(F(x)=F(x^{-1})\) for all \(x>0\).
  \item[(ii)] {Composition law on \(\Rp\):} for all \(x,y>0\),
  \begin{equation}\label{eq1}
  F(xy)+F\Big(\dfrac xy\Big)=2\,F(x)\,F(y)+2\,F(x)+2\,F(y).
  \end{equation}
  \item[(iii)] 
  \begin{equation}\label{behavior0}
  \lim_{t\to 0}\frac{2\,F(\e^t)}{t^2}=1.
  \end{equation}
\end{enumerate}
Then for all \(x>0\),
\[
F(x)=\frac{x+x^{-1}}{2}-1 \;=\; J(x).
\]
\end{theorem}

 





\section{Definitions and basic properties}\label{sec:prelim}


In this section, we introduce the basic definitions and elementary results that prepare the ground for the main theorem.


\begin{definition}\label{def:recip-norm}
A function \(F:\Rp\to\R\) is called a \emph{reciprocal cost} if
\[
F(x)=F(x^{-1})\qquad\text{for all }x>0.
\]
It is \emph{normalized} if \(F(1)=0\).
\end{definition}



\noindent Let us consider \(F:\Rp\to\R\), and define 
\begin{equation}
\label{GH}
G(t):=F(\e^t),\qquad H(t):=G(t)+1=F(\e^t)+1,\qquad t\in\R.
\end{equation}
From \(F(1)=0\) it immediately follows that \(G(0)=0\) and \(H(0)=1\).

\begin{lemma}\label{lem:recip-even}
If \(F\) is reciprocal, then \(G\) and \(H\) are even.
%\[
%G(-t)=G(t),\qquad H(-t)=H(t)\qquad(t\in\R).
%\]
\end{lemma}
\begin{proof}
Since \(\e^{-t}=(\e^t)^{-1}\) and \(F(x)=F(x^{-1})\), we have
\[
G(-t)=F(\e^{-t})=F\bigl((\e^t)^{-1}\bigr)=F(\e^t)=G(t).
\]
Further, for $H(-t)$, we have \[H(-t)=G(-t)+1=G(t)+1=H(t)\].
\end{proof}


%Let us define the   function
%\[
%J(x):=\frac{x+x^{-1}}{2}-1,\qquad x>0.
%\]
%Clearly, for all \(x>0\),
%\[
%J(x)=\frac{(x-1)^2}{2x}\ge 0,
%\]
%with equality if and only if \%(x=1\).
 

 

 
%For all \(t\in\R\),
%\(
%J(\e^t)=\cosh(t)-1.
%\)
%In particular, for the canonical cost \(J\), the associated functions in \eqref{GH} are
%\[
%G(t)=\cosh(t)-1
%\quad\text{and}\quad
%H(t)=\cosh(t).
%\]

\subsection{The d'Alembert functional equation} 
The key structural identity considered in this paper is the d’Alembert functional equation, which is also known in the literature as the cosine equation or the Poisson equation.

\begin{definition} \label{def:dalembert}
A function \(H:\R\to\R\) is said to satisfy the d'Alembert functional equation if,
for all \(t,u\in\R\),
\begin{equation}\label{dal}
H(t+u)+H(t-u)=2\,H(t)\,H(u).
\end{equation}
\end{definition}
D'Alembert's functional equation
has a long history going back to d'Alembert \cite{dAlembert1769}, Poisson \cite{Poisson1804}, and Picard \cite{Picard1922}. The equation plays an important role in determining the sum of two vectors in
various Euclidean and non-Euclidean geometries.

Functional equations arise from the parallelogram law of forces
or the rule for addition of vectors. 
Closely related functional equations arise in the study of
vibration of strings \cite{Kannappan2}, leading to equations of the form
\begin{equation} 
H(t+u)-H(t-u)=\,H(t)\,H(u), \quad\mbox{for all}\quad t,u\in\R .
\end{equation}  

The solution of (\ref{dal}) was obtained by d’Alembert by reducing
it to a differential equation. One of the interesting aspects of functional equations is that, unlike differential equations, functional equations can admit many solutions  unless additional   assumptions are imposed.\\


 

 



If $t=u= 0$ in (\ref{dal}), then $2H(0) = 2H(0)^2$ so that, we have
$$H(0) =0\quad\mbox{or}\quad H(0) = 1.$$
If $H(0) =0$, then for any real $x$
$$0 = 2H(x)H(0) =H(x + 0) +H(x - 0) = 2H(x). $$ Therefore, $H$ is the identically zero function. We will assume from now $H(0)=1$.




\begin{theorem}[\cite{Papp}]
If \(H:\R\to\R\) is a continuous   function and satisfies equation (\ref{dal}), then the only solutions are
\[H(x)\equiv 0,\quad H(x)\equiv 1, \quad H(x)=\cos(kx), \quad
H(x)=\cosh(kx),\] where \(k\) is a real constant. The classical Cauchy
method determines \(H\) on a dense subset of \(\R\) and extends it to the
whole real line by continuity.
    \end{theorem}

More general, it holds the following theorem
\begin{theorem}[\cite{Kannappan}]\label{22} The general complex-valued solutions of dAlembert 's functional equation (\ref{dal})
on the cartesian square of an abelian group $G$ are given by
\[
H(x)=\frac{h(x)+h(-x)}{2},
\]
where \(h : G \to \mathbb{C}\) satisfies 
\(
h(x+y)=h(x)h(y), \; x,y\in G.
\)
\end{theorem}

The function \(H\) in Theorem \ref{22} is continuous, and it follows that \(h\) is also
continuous. Then there exists a continuous linear functional
\(f : V \to \mathbb{C}\) such that
\[
h(x)=\e^{f(x)} \qquad \text{for all } x\in V.
\]
It follows that
\[
H(x)=\cosh\bigl(f(x)\bigr) \qquad \text{for all } x\in V.
\]
Writing \(f=f_1+i f_2\), where \(f_1\) and \(f_2\) denote the real and imaginary
parts of \(f\), respectively, we obtain
\[
H(x)=\cosh\bigl(f_1(x)+i f_2(x)\bigr)
= \cosh f_1(x)\cos f_2(x)
- i\,\sinh f_1(x)\sin f_2(x).
\]
Since \(H(x)\) is real-valued, it follows that either \(f_1=0\) or \(f_2=0\).



\begin{lemma} \label{lem:dalembert-even}
If \(H\) satisfies Definition~\ref{def:dalembert}, then \(H\) is even.
\end{lemma}
\begin{proof}
Fix \(u\in\R\) and apply the d'Alembert equation (\ref{dal}) with \(t=0\):
\[
H(u)+H(-u)=2\,H(0)\,H(u)=2H(u),
\]
so \(H(-u)=H(u)\).
\end{proof}

\begin{lemma}\label{lem:dalembert-product}
If \(H\) satisfies Definition~\ref{def:dalembert}, then for all \(t,u\in\R\),
\[
H(t+u)\,H(t-u)=H(t)^2+H(u)^2-1.
\]
\end{lemma}
\begin{proof}
Apply (\ref{dal}) with \(a=t+u\) and \(b=t-u\):
\[
H((t+u)+(t-u))+H((t+u)-(t-u))=2H(t+u)H(t-u),
\]
so \[H(2t)+H(2u)=2H(t+u)H(t-u).\] Using that
\[
H(2t)=2H(t)^2-1
\]
(obtained from (\ref{dal}) with \((t,t)\) and \(H(0)=1\)), and similarly for \(u\), yields the claim.
\end{proof}

\begin{lemma}\label{lem:dalembert-diff-square}
If \(H\) satisfies Definition~\ref{def:dalembert}, then for all \(t,u\in\R\),
\[
\bigl(H(t+u)-H(t-u)\bigr)^2=4\,(H(t)^2-1)\,(H(u)^2-1).
\]
\end{lemma}
\begin{proof}
Let \(A:=H(t+u)\) and \(B:=H(t-u)\). Then \(A+B=2H(t)H(u)\) by Definition \ref{def:dalembert}, and \(AB=H(t)^2+H(u)^2-1\)
by Lemma~\ref{lem:dalembert-product}. Hence
\begin{align*}
        (A-B)^2&=(A+B)^2-4AB\\
&=4H(t)^2H(u)^2-4(H(t)^2+H(u)^2-1)\\
&=4(H(t)^2-1)(H(u)^2-1).
\end{align*}
\end{proof}

\begin{lemma}\label{lem:dalembert-continuity}
If \(H\) satisfies Definition~\ref{def:dalembert} and 
\(\lim_{t\to 0}2(H(t)-1)/t^2\) exists. Then \(H\) is continuous on \(\R\).
\end{lemma}
\begin{proof}
The limit assumption implies that \(\lim_{t\to 0} H(t)=1\).
Since \(H(0)=1\), it follows that \(H\) is continuous at \(0\).


Fix \(t\in\R\). For \(u\to 0\), the equation (\ref{dal}) gives
\[
\lim_{u\to 0}\bigl(H(t+u)+H(t-u)\bigr)
=2H(t)\lim_{u\to 0}H(u)
=2H(t).
\]
By Lemma~\ref{lem:dalembert-diff-square}, we have
\[
\lim_{u\to 0}\bigl(H(t+u)-H(t-u)\bigr)^2
=4\bigl(H(t)^2-1\bigr)\lim_{u\to 0}\bigl(H(u)^2-1\bigr)=0,
\]
hence
\[
\lim_{u\to 0}\bigl(H(t+u)-H(t-u)\bigr)=0.
\]
Moreover,
\[
H(t+u)
=\frac{H(t+u)+H(t-u)}{2}
+\frac{H(t+u)-H(t-u)}{2}.
\]
Taking limits as \(u\to 0\) and using
\[
\lim_{u\to 0}\bigl(H(t+u)+H(t-u)\bigr)=2H(t),
\qquad
\lim_{u\to 0}\bigl(H(t+u)-H(t-u)\bigr)=0,
\]
we obtain
\[
\lim_{u\to 0} H(t+u)=H(t).
\]
Similarly, \(\lim_{u\to 0} H(t-u)=H(t)\).
Therefore, \(H\) is continuous at every \(t\in\R\).
\end{proof}





Let \(H\) satisfies the d'Alembert equation (\ref{dal}), and set \(G:=H-1\).
In this case, a direct calculation shows that \(G\) satisfies
\[
G(t+u)+G(t-u)=2\,G(t)\,G(u)+2\,G(t)+2\,G(u).
\]

For example (see \cite{Papp}), the function
\[
H(t)=J(\e^t)+1=\cosh(t)
\]
satisfies the d'Alembert equation~(\ref{dal}), and the corresponding
\(G(t)=\cosh(t)-1\) satisfies the identity above.




\subsection{Composition law on \texorpdfstring{$\Rp$}{R\_>0}}\label{sec:rp-law}
The main theorem is stated directly on \(\Rp\), logarithmic coordinates are used as a proof tool.


\begin{definition}\label{def:rp-law}
A function \(F:\Rp\to\R\) satisfies the \emph{composition law on \(\Rp\)} if for all
\(x,y>0\),
\begin{equation}\label{comp}
F(xy)+F\Big(\dfrac xy\Big)=2\,F(x)\,F(y)+2\,F(x)+2\,F(y).
    \end{equation}
\end{definition}

\begin{lemma}\label{lem:equiv-rp-dalembert}
Let \(F:\Rp\to\R\), and  \(H:\R\to\R\) such that \(H(t)=F(\e^t)+1\).
Then \(F\) satisfies Definition~\ref{def:rp-law} if and only if \(H\) satisfies the d'Alembert
equation (\ref{dal}).
\end{lemma}
\begin{proof}
Assume \(F\) satisfies Definition~\ref{def:rp-law}. Let \(t,u\in\R\) and set \(x=\e^t\), \(y=\e^u\). Then
\begin{align*}
H(t+u)+H(t-u)
&=\bigl(F(\e^{t+u})+1\bigr)+\bigl(F(\e^{t-u})+1\bigr)\\
&=\bigl(F(xy)+F\Big(\dfrac xy\Big)\bigr)+2\\
&=\bigl(2F(x)F(y)+2F(x)+2F(y)\bigr)+2\\
&=2\bigl(F(x)+1\bigr)\bigl(F(y)+1\bigr)
=2H(t)H(u),
\end{align*}
so \(H\) satisfies (\ref{dal}).

Conversely, if \(H\) satisfies (\ref{dal}), by reverse calculation with \(x=\e^t\), \(y=\e^u\), we obtain
that $F$ satisfies Definition~\ref{def:rp-law}.
\end{proof}

\begin{definition}\label{def:calibration}
Let \(F:\Rp\to\R\). 
Define the \emph{log-curvature} of \(F\), denoted \(\kappa(F)\), as
\[
\kappa(F) \;:=\; \lim_{t\to 0}\frac{2\,F(\e^t)}{t^2}
\]
provided this limit exists.
\end{definition}
In other words, when the limit exists, \(\kappa(F)\) coincides with the quadratic
coefficient of \(F(\e^t)\) at \(t=0\).
 Clearly, the limit above exists if and only if 
\[
\lim_{x\to 1}\frac{2\,F(x)}{(\log x)^2}
\]
exists, and when one exists the two limits coincide.  




\section{Main results}\label{sec:results}

In this section, we prove the main theorem in the paper. 

\begin{lemma}\label{lem:J-meets}
Let \(J(x)=\tfrac12(x+x^{-1})-1\) on \(\Rp\).
Then:
\begin{enumerate}
  \item[(i)] \(J\) is reciprocal and normalized: \(J(x)=J(x^{-1})\) for all \(x>0\) and \(J(1)=0\).
  \item[(ii)] \(J\) satisfies the composition law on \(\Rp\) (Definition~\ref{def:rp-law}).
  \item[(iii)] \(J\) has unit log-curvature: \(\kappa(J)=1\).
\end{enumerate}
\end{lemma}
\begin{proof}
(i) Reciprocity follows directly from the definition of $J(x)$. Also \(J(1)=\tfrac12(1+1)-1=0\).

\noindent(ii) Let \(H(t)=J(\e^t)+1, \; t\in\R.\)
Let us first compute \(H\)
\begin{align*}
H(t)
&= \left(\frac12\bigl(\e^t+\e^{-t}\bigr)-1\right)+1
 = \frac12\bigl(\e^t+\e^{-t}\bigr)
 = \cosh(t).
\end{align*}
Hence \(H(t)=\cosh(t)\) for all \(t\in\R\).

The function \(\cosh\) satisfies the d'Alembert equation  
\begin{equation}\label{eq:H-dalembert}
H(t+u)+H(t-u)=2\,H(t)\,H(u)\qquad\text{for all }t,u\in\R.
\end{equation}
Let \(x,y>0\) and
\[
t=\log x,\qquad u=\log y.
\]
Then \(\e^t=x\), \(\e^u=y\), and consequently
\[
\e^{t+u}=xy,\qquad \e^{t-u}=\frac{x}{y}.
\]
Using the definition of \(H\), we can rewrite \eqref{eq:H-dalembert} as
\begin{align*}
\bigl(J(\e^{t+u})+1\bigr)+\bigl(J(\e^{t-u})+1\bigr)
&=2\bigl(J(\e^t)+1\bigr)\bigl(J(\e^u)+1\bigr).
\end{align*}
Substituting \(\e^{t+u}=xy\), \(\e^{t-u}=x/y\), \(\e^t=x\), and \(\e^u=y\), we obtain
\[
\bigl(J(xy)+1\bigr)+\bigl(J\Big(\dfrac xy\Big)+1\bigr)
=2\bigl(J(x)+1\bigr)\bigl(J(y)+1\bigr).
\]
%i.e.
%\[
%J(xy)+J\Big(\dfrac xy\Big)+2
%=2J(x)J(y)+2J(x)+2J(y)+2.
%\]
Therefore, $J$ satisfies the composition law on
on \(\Rp\) given by Definition \ref{def:rp-law}:
\[
J(xy)+J\Bigl(\frac{x}{y}\Bigr)
=2\,J(x)\,J(y)+2\,J(x)+2\,J(y),
\qquad x,y>0.
\]

\noindent (iii) Using \(J(\e^t)=\cosh(t)-1\) and the Taylor expansion
\(\cosh(t)=1+t^2/2+o(t^2)\) as \(t\to 0\), we have
\[
\lim_{t\to 0}\frac{2J(\e^t)}{t^2}
=\lim_{t\to 0}\frac{2(\cosh(t)-1)}{t^2}=1,
\]
so \(\kappa(J)=1\).
\end{proof}
 
\begin{theorem}\label{thm:cosh-unique}
Let \(H:\R\to\R\) satisfy the d'Alembert equation (\ref{dal}).
Assume the following limit exists:
\begin{equation}\label{kal}
\kappa_H:=\lim_{t\to 0}\frac{2\,(H(t)-1)}{t^2}\in\R.
\end{equation}
Then:
\begin{enumerate}
  \item If \(\kappa_H>0\), then \(H(t)=\cosh(\sqrt{\kappa_H}\,t)\) for all \(t\in\R\).
  \item If \(\kappa_H<0\), then \(H(t)=\cos(\sqrt{-\kappa_H}\,t)\) for all \(t\in\R\).
  \item If \(\kappa_H=0\), then \(H(t)=1\) for all \(t\in\R\).
\end{enumerate}
In particular, if \(\kappa_H=1\), then \(H(t)=\cosh(t)\) for all \(t\in\R\).
\end{theorem}

\begin{proof} 
By Lemma~\ref{lem:dalembert-continuity}, the existence of
\[
\lim_{t\to 0}\frac{2\,(H(t)-1)}{t^2}\in\R
\]
implies that \(H\) is continuous on \(\R\).  
Hence we will apply the classical classification of continuous real-valued
solutions of the d'Alembert equation \eqref{dal} (see, for example, \cite{Aczel}).
\[
H(t)\equiv 1,\quad
H(t)=\cos(kt)\qquad H(t)=\cosh(kt),\quad k\in\R.
\]

If \(H(t)\equiv 1\), then \(H(t)-1\equiv 0\), so \(\kappa_H=0\), and the conclusion in (3) holds.

\medskip
If \(H(t)=\cosh(kt)\) for some \(k\in\R\).
Using the Taylor expansion \(\cosh(t)=1+t^2/2+o(t^2)\) as \(t\to 0\), we have 
\[
\cosh(kt)-1=\frac{(kt)^2}{2}+o(t^2),\qquad t\to 0.
\]
Therefore,
\[
\kappa_H
=\lim_{t\to 0}\frac{2(\cosh(kt)-1)}{t^2}
=\lim_{t\to 0}\frac{2\left(\frac{k^2t^2}{2}+o(t^2)\right)}{t^2}
=k^2\ge 0.
\]
If \(\kappa_H>0\), then \(k\neq 0\) and \(|k|=\sqrt{\kappa_H}\), hence
\[
H(t)=\cosh(kt)=\cosh(\sqrt{\kappa_H}\,t),\qquad t\in\R,
\]
since \(\cosh\) is even. If \(k=0\), then \(H\equiv 1\) and \(\kappa_H=0\),
which is already covered by the first case.

\medskip
Similarly to the second case, if \(H(t)=\cos(kt)\) for some \(k\in\R\),  the claim follows.
\end{proof}

\begin{corollary}\label{cor:cost-unique}
Let \(F:\Rp\to\R\) and \(F(1)=0\). Assume \(F\) satisfies the
composition law on \(\mathbb{R}_{>0}\) and has unit log-curvature \(\kappa(F)=1\). Then
\[
F(x)=\frac{x+x^{-1}}{2}-1
\qquad\text{for all }x>0.
\]
\end{corollary}
\begin{proof}
Let \(H(t)=F(\e^t)+1\). By Lemma~\ref{lem:equiv-rp-dalembert}, \(H\) satisfies d'Alembert
equation (\ref{dal}), and
moreover,
\[
\kappa_H=\lim_{t\to 0}\frac{2(H(t)-1)}{t^2}=\lim_{t\to 0}\frac{2F(\e^t)}{t^2}=\kappa(F)=1.
\]
From Theorem~\ref{thm:cosh-unique} then \(H(t)=\cosh(t)\), hence
\(
F(\e^t)=\cosh(t)-1=J(\e^t)
\). For \(x>0\) and \(x=\e^{\log x}\), we have \(F(x)=J(x)\).
\end{proof}






\begin{remark}
If condition~\eqref{kal} is not imposed, the d'Alembert equation admits a one--parameter family of
nontrivial solutions. More precisely, for any $k>0$, the functions
\[
H(t)=\cosh(k t) \quad \text{and} \quad H(t)=\cos(k t)
\]
satisfy \eqref{dal}. In this case the parameter $k$ is not uniquely determined.
The value of the curvature $\kappa_H$ uniquely determines $k$ by
$k^2=|\kappa_H|$, and makes difference between the cases $\kappa_H>0$ and $\kappa_H<0$.
\end{remark}

 
 Theorem~\ref{thm:cosh-unique} assumes the existence of the limit $\kappa_H$.
By Lemma~\ref{lem:dalembert-continuity}, this implies that $H$ is continuous.
The conclusion then follows from the classical classification of continuous solutions
of the d'Alembert equation, together with a direct computation of $\kappa_H$ for each
canonical form.

\begin{lemma}(c.f. \cite{Rudin})\label{lem:central-diff-C2}
Let \(f:\R\to\R\) be continuous. Fix \(T>0\) and define the central second difference
\[
D_h f(t):=\frac{f(t+h)-2f(t)+f(t-h)}{h^2}\qquad(|t|\le T,\ h\ne 0).
\]
If there is a continuous function \(L:[-T,T]\to\R\) such that
\[
\lim_{h\to 0}\ \sup_{|t|\le T}\ \bigl|D_h f(t)-L(t)\bigr|=0,
\]
then \(f\in C^2([-T,T])\) and \(f''(t)=L(t)\) for all \(|t|\le T\).
\end{lemma}
%\begin{proof}{\color{red}\%MZ The proof should be given or cited from the literature; it is first carried out on compact subintervals $[-T+\delta,T-\delta]$, $\delta>0$, where the central difference is well defined, and then extended to $[-T,T]$ by continuity.}
%\end{proof}

\begin{lemma}\label{lem:dalembert-curvature-ode}
Let \(H:\R\to\R\) satisfy the d'Alembert equation (\ref{dal}). Suppose the following limit exists
\begin{equation*}
\kappa_H:=\lim_{t\to 0}\frac{2\,(H(t)-1)}{t^2}\in\R.
\end{equation*}Then \(H\in C^2(\R)\) and
\[
H''(t)=\kappa_H\,H(t)\qquad\text{for all }t\in\R.
\]
\end{lemma}


\begin{proof}
By Lemma~\ref{lem:dalembert-continuity}, \(H\) is continuous.
Fix \(T>0\). Let \(t\in[-T,T]\) be arbitrary and let \(h\in\R\) with \(0<|h|\le 1\).
Since \(H\) is defined on \(\R\), then \(H(t\pm h)\) are well-defined.
The d'Alembert equation yields
\[
H(t+h)+H(t-h)=2H(t)H(h).
\]
Rearranging, we obtain
\[
\frac{H(t+h)-2H(t)+H(t-h)}{h^2}
=2H(t)\,\frac{H(h)-1}{h^2}.
\]
Define
\[
q(h):=\frac{2(H(h)-1)}{h^2}.
\]
By assumption, \(q(h)\to\kappa_H\) as \(h\to 0\).

Since \(H\) is continuous on \([-T-1,\,T+1]\),
there exists \(M_T>0\) such that
\[
|H(t)|\le M_T \qquad \text{for all } |t|\le T.
\]
Hence
\[
\begin{aligned}
\sup_{|t|\le T}
\left|
\frac{H(t+h)-2H(t)+H(t-h)}{h^2}
-\kappa_H H(t)
\right|
&=
\sup_{|t|\le T}
|H(t)|\,|q(h)-\kappa_H| \\
&\le M_T\,|q(h)-\kappa_H|
\xrightarrow[h\to 0]{} 0.
\end{aligned}
\]

By Lemma~\ref{lem:central-diff-C2} (applied with \(f=H\) and \(L(t)=\kappa_H H(t)\)),
it follows that \(H\in C^2([-T,T])\) and
\[
H''(t)=\kappa_H H(t)\qquad \text{for all } t\in[-T,T].
\]
Since \(T>0\) is arbitrary, the conclusion holds for all \(t\in\R\).
\end{proof}


 

\begin{lemma} \label{lem:dalembert-to-ode}
Let \(H\in C^2(\R)\) satisfy the d'Alembert equation (\ref{dal}). Then for all \(t\in\R\),
\[
H''(t)=H''(0)\,H(t).
\]
\end{lemma}
\begin{proof}
Given that $H$ satisfies  \[H(t+u)+H(t-u)-2H(t)H(u)=0.\]

Taking the second derivative with respect to \(u\) for fixed $t$, we get
\[
H''(t+u)+H''(t-u)-2H(t)H''(u)=0.
\]
Therefore, evaluating at $u=0$, we have
\[
%H''(t)+H''(t)-2H(t)H''(0)=
2H''(t)-2H(t)H''(0)=0,
\]
so \(H''(t)=H''(0)H(t)\) for all \(t\).
\end{proof}

 

\begin{lemma}\label{lem:even-deriv0}
Let \(H\in C^1(\R)\) be even. Then \(H'(0)=0\).
\end{lemma}

\begin{proof}
Since $H$ is even, $H(t)=H(-t)$ for all $t$.
Then
\[
H'(0)=\lim_{t\to 0}\frac{H(t)-H(0)}{t}
=\lim_{t\to 0}\frac{H(-t)-H(0)}{t}
=-\lim_{t\to 0}\frac{H(t)-H(0)}{t}
=-H'(0),
\]
hence $H'(0)=0$.
\end{proof}




\begin{lemma}\label{lem:ode-zero-pos}
Let \(\kappa>0\) and let \(f\in C^2(\R)\) satisfy \(f''(t)=\kappa f(t)\) for all \(t\), with
\(f(0)=0\) and \(f'(0)=0\). Then \(f(t)=0\) for all \(t\).
\end{lemma}

\begin{proof}
Let \(\lambda:=\sqrt{\kappa}\). Define \(g(t):=f'(t)-\lambda f(t)\) and \(h(t):=f'(t)+\lambda f(t)\).
Then
\begin{align*}
g'(t) &= f''(t)-\lambda f'(t)
      = \kappa f(t)-\lambda f'(t)
      = \lambda(\lambda f(t)-f'(t))
      = -\lambda g(t),\\
h'(t) &= f''(t)+\lambda f'(t)
      = \kappa f(t)+\lambda f'(t)
      = \lambda(\lambda f(t)+f'(t))
      = \lambda h(t).
\end{align*}
Since \(g(0)=f'(0)-\lambda f(0)=0\) and \(h(0)=f'(0)+\lambda f(0)=0\), the unique solutions are
\(g(t)=g(0)e^{-\lambda t}\equiv 0\) and \(h(t)=h(0)e^{\lambda t}\equiv 0\).
Hence \(f'=\tfrac12(g+h)\equiv 0\), so \(f\) is constant, and with \(f(0)=0\) we conclude \(f\equiv 0\).
\end{proof} The following lemma can be proved in a similar way as previous one, using the energy function
\(E(t):=f'(t)^2+\lambda^2 f(t)^2\) with \(\kappa=-\lambda^2\) (\(\lambda>0\)),
instead of exponential combinations.

\begin{lemma}\label{lem:ode-zero-neg}
Let \(\kappa<0\) and let \(f\in C^2(\R)\) satisfy \(f''(t)=\kappa f(t)\) for all \(t\), with
\(f(0)=0\) and \(f'(0)=0\). Then \(f(t)=0\) for all \(t\).
\end{lemma}
%\begin{proof}
%Let \(\kappa=-\lambda^2\) with \(\lambda=\sqrt{-\kappa}>0\). Let us define
%\[
%E(t):=f'(t)^2+\lambda^2 f(t)^2\ge 0.
%\]
%Then \(E\in C^1(\R)\) and
%\[
%E'(t)=2f'(t)f''(t)+2\lambda^2 %f(t)f'(t)=2f'(t)\bigl(f''(t)+\lambda^2 f(t)\bigr)=0,
%\]
%so \(E\) is constant. Since \(E(0)=f'(0)^2+\lambda^2 f(0)^2=0\), we have \(E(t)=0\) for all \(t\), hence
%\(f'(t)=0\) and \(f(t)=0\) for %all \(t\).
%\end{proof}


%{\color{red}\%MZ another proof of Theorem~\ref{thm:cosh-unique}
%\begin{proof}[Proof of Theorem~\ref{thm:cosh-unique}]
%Let \(H\) satisfy the hypotheses, and let \(\kappa_H\) be as in the statement.
%By Lemma~\ref{lem:dalembert-curvature-ode}, \(H\in C^2(\R)\) and \(H''=\kappa_H H\).
%Also, by Lemma~\ref{lem:dalembert-even2}, \(H\) is even, hence (since \(H\in C^1\))
%\(H'(0)=0\) by Lemma~\ref{lem:even-deriv0}.

%\paragraph{Case \(\kappa_H=0\).}
%Then \(H''=0\), so \(H(t)=at+b\). Evenness forces \(a=0\), and \(H(0)=1\) gives \(b=1\), hence
%\(H\equiv 1\).

%\paragraph{Case \(\kappa_H>0\).}
%Let \(\lambda:=\sqrt{\kappa_H}\) and set \(y(t):=\cosh(\lambda t)\). Then \(y\in C^2(\R)\),
%\(y''=\kappa_H y\), \(y(0)=1\), and %\(y'(0)=0\). Define \(f:=H-y\). Then \(f\in C^2(\R)\),
%\(f''=\kappa_H f\), and \(f(0)=f'(0)=0\). By Lemma~\ref{lem:ode-zero-pos}, \(f\equiv 0\), so
%\(H(t)=\cosh(\lambda t)\).

%\paragraph{Case \(\kappa_H<0\).}
%Let \(\mu:=\sqrt{-\kappa_H}\) and set \(y(t):=\cos(\mu t)\). Then \%(y\in C^2(\R)\),
%\(y''=\kappa_H y\), \(y(0)=1\), and %\(y'(0)=0\). With \(f:=H-y\) as above, we have
%\(f''=\kappa_H f\) and \(f(0)=f'(0)=0\). By Lemma~\ref{lem:ode-zero-neg}, \(f\equiv 0\), so
%\(H(t)=\cos(\mu t)\).
%\end{proof}}




Theorem~\ref{thm:main} eliminates ambiguity in the functional form of \(H\) by proving
that any solution of d'Alembert's equation satisfying the prescribed regularity
condition is uniquely determined up to the forms
\(H(t)=\cosh(\sqrt{\kappa_H}\,t)\) or \(H(t)=\cos(\sqrt{-\kappa_H}\,t)\).

\smallskip

Theorem~\ref{thm:main} is intentionally minimal: each assumption plays a distinct role. The following propositions show what fails when individual assumptions are removed.

\begin{proposition}\label{prop:reciprocity-forced}
Let \(F:\Rp\to\R\) satisfy \eqref{comp} and \(F(1)=0\). Then \(F(x)=F(x^{-1})\) for all
\(x>0\).
\end{proposition}
\begin{proof}
Plug \(x=1\) into Definition~\ref{def:rp-law} to obtain
\[
F(y)+F\Big(\dfrac 1 y\Big)=2F(1)F(y)+2F(1)+2F(y)=2F(y),
\]
hence \(F\Big(\dfrac 1 y\Big)=F(y)\) for all \(y>0\).
\end{proof}


 \begin{proposition}
Assume there is a function \(W:\Rp\to(0,\infty)\) satisfying 
\[
W(xy)=W(x)W(y)\qquad x,y>0.
\]
Define \(F_W:\Rp\to\R\) by
\[
F_W(x):=\frac{W(x)+W(x)^{-1}}{2}-1.
\]
Then \(F_W(1)=0\), and \(F_W\) satisfies the \(\Rp\) composition law
(Definition~\ref{def:rp-law}). If, in addition, \(W\) is continuous, then there exists \(\lambda\in\R\)
with \(W(x)=x^\lambda\) for all \(x>0\), hence
\[
F_W(x)=\cosh(\lambda\log x)-1.
\]
\end{proposition}
\begin{proof}
First, \(W(1)=W(1\cdot 1)=W(1)^2\) and \(W(1)>0\) force \(W(1)=1\), so \(F_W(1)=\tfrac12(1+1)-1=0\).
Also,
\[
W(x)W(x^{-1})=W(xx^{-1})=W(1)=1,
\]
so \(W(x^{-1})=W(x)^{-1}\) and hence \(F_W(x)=F_W(x^{-1})\).

Define \(H(t):=F_W(\e^t)+1=\tfrac12(W(\e^t)+W(\e^t)^{-1})\). Let \(t,u\in\R\). Then
\begin{align*}
H(t+u)+H(t-u)
&=\frac{W(\e^{t+u})+W(\e^{t+u})^{-1}+W(\e^{t-u})+W(\e^{t-u})^{-1}}{2}\\
&=\frac{(W(\e^t)+W(\e^t)^{-1})(W(\e^u)+W(\e^u)^{-1})}{2}
=2H(t)H(u),
\end{align*}
so \(H\) satisfies d'Alembert. By Lemma~\ref{lem:equiv-rp-dalembert}, \(F_W\) satisfies the \(\Rp\)
composition law.

Finally, if \(W\) is continuous, define \(w(t):=\log W(\e^t)\). Then \(w:\R\to\R\) is additive:
using \(W(\e^{t+u})=W(\e^t)W(\e^u)\), we get \(w(t+u)=w(t)+w(u)\). Continuity of \(W\) implies
continuity of \(w\), hence \(w(t)=\lambda t\) for some \(\lambda\in\R\). Therefore
\(
W(\e^t)=\e^{\lambda t}
\),
i.e. \(W(x)=x^\lambda\) for \(x>0\), and
\(
F_W(\e^t)=\cosh(\lambda t)-1
\),
equivalently \(F_W(x)=\cosh(\lambda\log x)-1\).
\end{proof}


\begin{corollary}\label{cor:no-calibration-family}
For any \(\lambda>0\), define
\[
F_\lambda(x):=\cosh(\lambda\log x)-1 \qquad (x>0).
\]
Then \(F_\lambda\) is continuous on \(\Rp\), satisfies \(F_\lambda(1)=0\),
satisfies the composition law \eqref{comp}, and has \(\kappa(F_\lambda)=\lambda^2\).
In particular, the unit calibration \(\kappa(F)=1\) fixes \(\lambda=1\).
\end{corollary}

\begin{proof}
Take \(W(x)=x^\lambda\) in the previous proposition, so \(F_\lambda=F_W\) and \eqref{comp} holds.
Moreover, since \(\cosh(\lambda t)-1=\frac{\lambda^2 t^2}{2}+o(t^2)\) as \(t\to 0\), we get
\[
\kappa(F_\lambda)
=\lim_{t\to 0}\frac{2(\cosh(\lambda t)-1)}{t^2}
=\lambda^2.
\]
\end{proof}

 

The following proposition shows that normalization and unit calibration alone 
do not imply the composition law on \(\mathbb{R}_{>0}\).

\begin{proposition}\label{prop:no-law-counterexample}
Let us define \(F(x):=\tfrac12(\log x)^2\) on \(\Rp\). Then \(F\) is
continuous, satisfies \(F(1)=0\), and has \(\kappa(F)=1\), but it does
\emph{not} satisfy the  composition law on \(\mathbb{R}_{>0}\).
\end{proposition}
\begin{proof}
Continuity and \(F(1)=0\) are immediate. Moreover,
\(F(\e^t)=t^2/2\), so
\[
\kappa(F)=\lim_{t\to 0}\frac{2(t^2/2)}{t^2}=1.
\]
Define \(H(t):=F(\e^t)+1=1+t^2/2\). Then for \(t,u\in\R\),
\[
H(t+u)+H(t-u)=2+\frac{(t+u)^2+(t-u)^2}{2}=2+t^2+u^2,
\]
while
\[
2H(t)H(u)
=2\left(1+\frac{t^2}{2}\right)\left(1+\frac{u^2}{2}\right)
=2+t^2+u^2+\frac{t^2u^2}{2}.
\]
The last two expressions differ when \(tu\neq 0\), hence \(H\) does not satisfy
d'Alembert's functional equation. By Lemma~\ref{lem:equiv-rp-dalembert},
\(F\) does not satisfy the composition law on \(\mathbb{R}_{>0}\).

\end{proof}


The following proposition shows that, without a regularity assumption,
the composition law on \(\mathbb{R}_{>0}\) (\ref{comp}) admits pathological solutions.

 

%%%%%%%%%%%%%
\begin{proposition}\label{prop:pathological}
There exist functions \(F:\mathbb{R}_{>0}\to\mathbb{R}\) satisfying \(F(1)=0\) and the
composition law on \(\mathbb{R}_{>0}\)~\eqref{comp} that are not measurable (and hence not continuous).
\end{proposition}

\begin{proof}
It is a  consequence of the existence of a Hamel basis of \(\mathbb{R}\) over \(\mathbb{Q}\)
that there exists an additive function \(a:\mathbb{R}\to\mathbb{R}\),
\(a(t+u)=a(t)+a(u)\), which is not measurable (and hence not continuous).

Let us define
\[
H(t):=\cosh(a(t)), \qquad t\in\mathbb{R}.
\]
The function \(H\) is not measurable. Indeed, if \(H\) were measurable, then
\[
|a(t)|=\operatorname{arcosh}(H(t))
\]
would be measurable as well, since \(\operatorname{arcosh}\) is continuous on \([1,\infty)\).
Consider the set
\[
E:=\{t\in\mathbb{R}:\ |a(t)|\le 1\}.
\]
Then \(E\) is measurable and \(a\) is bounded on \(E\).
Since that any additive function which is bounded (or measurable)
on a set of positive measure must be linear, hence continuous on \(\mathbb{R}\).
This contradicts the choice of \(a\). Therefore \(H\) is not measurable.

Using the additivity of \(a\) and the identity
\(\cosh(x+y)+\cosh(x-y)=2\cosh(x)\cosh(y)\), we compute for all \(t,u\in\mathbb{R}\),
\begin{align*}
H(t+u)+H(t-u)
&=\cosh(a(t)+a(u))+\cosh(a(t)-a(u))\\
&=2\cosh(a(t))\cosh(a(u))
=2H(t)H(u).
\end{align*}
Thus \(H\) satisfies d'Alembert's functional equation and \(H(0)=\cosh(a(0))=1\).

Finally, we define
\[
F(x):=H(\log x)-1, \qquad x>0.
\]
Then \(F(1)=0\), and by Lemma~\ref{lem:equiv-rp-dalembert}, \(F\) satisfies the composition law
on \(\mathbb{R}_{>0}\)~\eqref{comp}.
If \(F\) were measurable, then \(H(t)=F(e^t)+1\) would be measurable as a composition
of measurable functions, contradicting the non-measurability of \(H\).
Hence \(F\) is not measurable.
\end{proof}



\section{Stability under bounded defect}\label{app:robustness}


In this part, we give a local stability result.
If the d’Alembert equation holds with a uniform defect on a compact set and the function is sufficiently smooth, then the solution is close to the hyperbolic cosine case.

\begin{definition}\label{def:defect}
For \(H:\R\to\R\), we define the {\rm d'Alembert defect}
\begin{equation}\label{defect}
\Delta_H(t,u):=H(t+u)+H(t-u)-2H(t)H(u).
\end{equation}
\end{definition}

\begin{theorem}\label{thm:stability}
Fix \(T>0\). Let \(H\in C^3([-T,T])\) be even with \(H(0)=1\), and set \(a:=H''(0)\).
Assume \(a>0\). Let
\[
\varepsilon:=\sup_{|t|\le T,\ |u|\le T}\ |\Delta_H(t,u)|,\qquad
B:=\sup_{|t|\le T}\ |H(t)|,\qquad
K:=\sup_{|t|\le T}\ |H^{(3)}(t)|.
\]
Then for every \(h\) with \(0<h\le T\) and every \(t\) with \(|t|\le T-h\),
\[
\bigl|H(t)-\cosh(\sqrt{a}\,t)\bigr|
\le
\frac{\delta(h)}{a}\,\bigl(\cosh(\sqrt{a}\,|t|)-1\bigr),
\]
where
\[
\delta(h):=\frac{\varepsilon}{h^2}+\frac{(1+B)K}{3}\,h.
\]
\end{theorem}
\begin{proof}
Fix \(0<h\le T\) and \(|t|\le T-h\).

 
Using the integral form of Taylor's theorem, we have
\[
H(t+h)=H(t)+hH'(t)+\frac{h^2}{2}H''(t)+\int_0^h\frac{(h-s)^2}{2}\,H^{(3)}(t+s)\,ds,
\]
\[
H(t-h)=H(t)-hH'(t)+\frac{h^2}{2}H''(t)-\int_0^h\frac{(h-s)^2}{2}\,H^{(3)}(t-s)\,ds.
\]
Adding the last two equations and bounding \(|H^{(3)}|\le K\) yields \begin{equation}\label{eq:taylor1}
\bigl|H(t+h)+H(t-h)-2H(t)-h^2H''(t)\bigr|\le \frac{K}{3}\,h^3.
\end{equation}
Since \(H\) is even, \(H'(0)=0\), and the integral form at \(0\) gives
\begin{equation}\label{eq:taylor2}
\bigl|H(h)-1-\frac{a}{2}h^2\bigr|\le \frac{K}{6}\,h^3.
\end{equation}
Now, by definition of $\Delta_H$ (\ref{defect}), we have for $(t,h)$ 
\[
H(t+h)+H(t-h)=2H(t)H(h)+\Delta_H(t,h).
\]
Subtract \(2H(t)+a h^2 H(t)\) from both sides, we obtain
\begin{align*}
h^2\bigl(H''(t)-aH(t)\bigr)
&=\bigl(H(t+h)+H(t-h)-2H(t)-h^2H''(t)\bigr)\\
&\quad+\Delta_H(t,h)
+2H(t)\bigl(H(h)-1-\frac{a}{2}h^2\bigr).
\end{align*}
Taking absolute values in the last equation and using \eqref{eq:taylor1}, \eqref{eq:taylor2}, \(|H(t)|\le B\), and
\(|\Delta_H(t,h)|\le\varepsilon\), we obtain
\[
h^2|H''(t)-aH(t)|
\le \frac{K}{3}h^3+\varepsilon+2B\cdot\frac{K}{6}h^3
\le \varepsilon+\frac{(1+B)K}{3}h^3.
\]
Dividing by \(h^2\) yields the uniform bound
\begin{equation}\label{eq:resid}
|H''(t)-aH(t)|\le \delta(h)
\qquad(|t|\le T-h).
\end{equation}

Let \(y(t):=\cosh(\sqrt{a}\,t)\), so \(y''=ay\), \(y(0)=1\), and since \(H\) is even, \(H'(0)=0=y'(0)\).
Define \(e(t):=H(t)-y(t)\). Then \(e\in C^2([-T+h,T-h])\), \(e(0)=e'(0)=0\), and
\[
e''(t)-a e(t)=H''(t)-aH(t),
\]
so by \eqref{eq:resid}, \(|e''(t)-a e(t)|\le\delta(h)\) for \(|t|\le T-h\).
For \(t\in[0,T-h]\), the equation for \(e''=ae+r\) with zero initial condition gives
\[
e(t)=\int_0^t \frac{1}{\sqrt{a}}\sinh(\sqrt{a}(t-s))\,r(s)\,ds,
\]
where \(r(s):=e''(s)-ae(s)\). Hence
\[
|e(t)|
\le \delta(h)\int_0^t \frac{1}{\sqrt{a}}\sinh(\sqrt{a}(t-s))\,ds
=\frac{\delta(h)}{a}\bigl(\cosh(\sqrt{a}\,t)-1\bigr).
\]
Since \(e\) is even as difference of even functions, this bound holds for negative \(t\), yielding
the inequality for all \(|t|\le T-h\).
\end{proof}


%%%%%%%%%%%

\begin{corollary}\label{cor:stability-rp}
Let the assumptions of Theorem~\ref{thm:stability} hold and define
\[
F(x):=H(\log x)-1,\qquad x\in\mathbb{R}_{\geq 0}.
\]
Then for every \(x\in\bigl(e^{-(T-h)},e^{T-h}\bigr)\),
\[
\bigl|F(x)-\bigl(\cosh(\sqrt{a}\,\log x)-1\bigr)\bigr|
\;\le\;
\frac{\delta(h)}{a}\Bigl(\cosh\bigl(\sqrt{a}\,|\log x|\bigr)-1\Bigr).
\]

In particular, for every \(S\in(0,T-h)\) the function \(F\) is uniformly close to
\(\cosh(\sqrt{a}\,\log x)-1\) on the compact interval \([e^{-S},e^{S}]\).

If moreover \(a\) is close to \(1\) and \(\delta(h)\) is small, then \(F\) is uniformly
close to \(J(x)=\cosh(\log x)-1\) on \([e^{-S},e^{S}]\).

\medskip

In the special case \(a=1\), the estimate simplifies to
\[
\bigl|F(x)-J(x)\bigr|\le\delta(h)\,J(x),
\qquad x\in\bigl(e^{-(T-h)},e^{T-h}\bigr),
\]
since \(\cosh(|\log x|)-1=\cosh(\log x)-1=J(x)\).
\end{corollary}

\begin{proof}
Apply Theorem~\ref{thm:stability} with \(t=\log x\). Since \(F(x)=H(t)-1\), we obtain
\[
|F(x)-(\cosh(\sqrt a\,t)-1)|
\le \frac{\delta(h)}{a}\,(\cosh(\sqrt a\,|t|)-1),
\]
which is the required inequality after substituting \(t=\log x\).


The case \(a=1\) follows from \(\cosh(|\log x|)-1=\cosh(\log x)-1=J(x)\).
\end{proof}%%%%%%%%%
 

 

%%%



\section{Properties of canonical reciprocal cost}

In this section, we will give some properties of the function $J(x)$ given by (\ref{canonreccost}).


\subsection{Arithmetical and geometrical means.} 
The function \(J(x)\) can be written as
\[
J(x)
=\mathrm{AM}\Big(x,\dfrac 1x\Big)-\mathrm{GM}\Big(x,\dfrac 1x\Big),
\]
hence \(J(x)\ge 0\) for all \(x>0\), with equality if and only if \(x=1\).

%%%
 
\subsection{Bregman divergence.}
The logarithmic expression of the canonical reciprocal cost is
\[
G(t)=J(\e^t)=\cosh t-1.
\]
Let \(\Phi:\R\to\R\) be defined by \(\Phi(t)=\cosh t\).
Then \(G\) coincides with the Bregman divergence generated by \(\Phi\) at the point \(0\), namely
\[
G(t)=D_\Phi(t,0)
=\Phi(t)-\Phi(0)-\Phi'(0)(t-0),
\]
since \(\Phi(0)=1\) and \(\Phi'(0)=\sinh 0=0\).

Since \(\Phi\in C^2(\R)\) and
\[
\Phi''(t)=\cosh t>0 \qquad \text{for all } t\in\R,
\]
the function \(\Phi\) is strictly convex. Consequently,
\[
D_\Phi(t,0)>0 \quad \text{for } t\neq 0,
\qquad
D_\Phi(0,0)=0,
\]
and \(0\) is the unique global minimizer of \(\Phi\).

In logarithmic coordinates, the function \(F\) therefore coincides with a Bregman divergence,
which explains its non-negativity, unique minimizer, and quadratic behavior at the minimum.



%%%%%




%\subsection{Behavior near $x=1$.}
%Near the equilibrium point \(x=1\), $J(x)$ has quadratic behavior.
%If \(x=\e^{\varepsilon}\), we obtain
%\[
%J(\e^{\varepsilon})
%=\cosh(\varepsilon)-1
%=\frac{\varepsilon^2}{2}+\frac{\varepsilon^4}{24}+O(\varepsilon^6).
%\]
%In particular, the linear term vanishes and the leading contribution is quadratic.
%This shows that small reciprocal deviations from equilibrium are penalized symmetrically.\\

 



%%%%%%%%




%%%%%%
\subsection{Metric associated with \(J\).}
Starting from the canonical reciprocal cost function
\[
J(x)=\dfrac12\Big(x+\frac1x\Big)-1,
\]
we introduce logarithmic coordinates \(t=\log x\) and set
\[
G(t)=J(\e^t)=\cosh t-1,
\qquad
\Phi(t)=G(t)+1=\cosh t.
\]
The function \(\Phi\) is smooth and strictly convex on \(\R\), since
\[
\Phi''(t)=\cosh t>0 \qquad \text{for all } t\in\R.
\]
The Hessian metric induced by \(\Phi\) on \(\R\) is
\[
ds^2=\Phi''(t)\,dt^2=\cosh t\,dt^2.
\]
In \(x\)-coordinates, we get
\[
ds^2=\cosh(\log x)\,\frac{dx^2}{x^2}
=\frac{x^2+1}{2x^3}\,dx^2.
\]
The corresponding Riemannian distance is 
\[
d_J(x,y)
=\left|\int_{\log x}^{\log y}\sqrt{\cosh u}\,du\right|
=\left|\int_x^y \sqrt{\frac{\xi^2+1}{2\xi^3}}\,d\xi\right|.
\]
 

Since \(\cosh\) is an even function, the distance is reciprocally symmetric, i.e.
\[
d_J(x,y)=d_J\Big(\frac1x,\frac1y\Big).
\]

Near \(x=1\) (that is, \(t=0\)), one has \(\cosh t=1+O(t^2)\), and hence
\(d_J(x,y)\) is locally equivalent to the logarithmic distance
\(\lvert \log y-\log x\rvert\).
More precisely, there exist constants \(c,C>0\) and a neighborhood \(U\) of \(1\)
such that
\[
c\,\lvert \log y-\log x\rvert
\le d_J(x,y)
\le C\,\lvert \log y-\log x\rvert,
\qquad x,y\in U.
\]

Globally, the behavior is  different.
As \(|t|\to\infty\), one has \(\cosh t\sim \tfrac12 e^{|t|}\), and therefore
\[
d_J(1,R)\sim \sqrt{2}\,R^{1/2}
\qquad \text{as } R\to\infty,
\]
reflecting the exponential growth of \(\Phi''(t)\) for large \(|t|\).
%%%%%
\subsection{Chebyshev structure of $J$}

It is known that normalized solutions of d’Alembert equation
\[
H(m+n)+H(m-n)=2H(m)H(n), \qquad m,n\in\mathbb Z,
\]
can be expressed in terms of Chebyshev polynomials (see, for example, \cite{Davison}).
In particular, such solutions satisfy 

\begin{equation}\label{rec}
H_{n+1}=2H_1H_n-H_{n-1}
\end{equation}
and can be written in the form \(H_n=T_n(H_1)\), where \(T_n\) denotes the
Chebyshev polynomials.

Now, we will show that this discrete Chebyshev structure is realized for the
canonical reciprocal cost
\(
J(x).
\)
Let us consider $H(t)=J(e^t)+1=\cosh t$ which satisfies the (continuous) d’Alembert equation. By using \(t\mapsto nt\), we obtain
\[
J(x^n)+1=\cosh(n\log x)
= T_n(\cosh(\log x))
= T_n(J(x)+1),
\]
that is,
\[
J(x^n)=T_n(J(x)+1)-1 ,\qquad n\in\mathbb Z.
\]
Since \(H_1=J(x)+1=\cosh(\log x)\ge 1\), the recursion \eqref{rec}
corresponds to the hyperbolic case of the Chebyshev recursion.
Hence \(H_n=T_n(H_1)=\cosh(n\log x)\), and oscillatory (trigonometric)
solutions are excluded.

Thus, the Chebyshev recursion associated with the discrete d’Alembert equation
is realized explicitly by the functional \(J\).

%%%

\subsection{Golden ratio}

A natural connection with the golden ratio follows from the fixed-point structure
associated with the canonical reciprocal cost. To identify a reciprocal scale compatible with the symmetry $x \leftrightarrow
x^{-1}$, consider the Möbius transformation
\[
T(x)=1+\frac{1}{x},
\]
which maps \(\R_{>0}\) onto itself. 
The fixed points of \(T\) satisfy
\[
x=T(x)=1+\frac{1}{x},
\]
or equivalently
\[
x^2-x-1=0.
\]
This equation has two real solutions
\(
x=\frac{1\pm\sqrt5}{2},
\)
among which the golden ratio
\[
\varphi=\frac{1+\sqrt5}{2}
\]
is the unique positive fixed point.

Since \(J(x)=J(x^{-1})\), each reciprocal pair \((x,x^{-1})\) is assigned the same
value of the cost.
In particular, the reciprocal pair \((\varphi,\varphi^{-1})\) (for $\varphi^2-\varphi-1=0$ we have $\varphi^{-1}=\varphi-1$) yields 
\[
J(\varphi)=J(\varphi^{-1})=\varphi-\frac32.
\]



\begin{corollary}
For any initial value $x_0>0$, the sequence
\[
x_{n+1}=T(x_n)=1+\frac{1}{x_n}
\]
converges to $\varphi$.
\end{corollary}

In the paper \cite{golden}, the golden ratio is obtained as a fixed point of an
operator induced by a mean.
More precisely, for a homogeneous mean $M$, the operator
\[
h(t)=M(1,1+t)
\]
admits a unique fixed point, which defines the golden ratio associated with the
mean $M$.


 
\section{Physical interpretation of the canonical reciprocal cost}

The canonical reciprocal cost \(J(x)\) admits a natural interpretation as an
\emph{energy balance functional}.


Since \(J\) is nonnegative and minimized at the equilibrium \(x=1\),
the equilibrium corresponds to zero cost, while any deviation from balance
gives a positive energetic cost.
This is typical for an energy-type quantity: it measures how far the system
is from a stable reference state.

\smallskip

The function \(J\) is symmetric under the reciprocal transformation
\(x \mapsto 1/x\), i.e.
\[
J(x) = J\Big(\dfrac{1}{x}\Big) \quad \text{for all } x > 0.
\]
This reflects a fundamental balance: an increase (\(x>1\)) or a decrease (\(x<1\))
by the same factor leads to the same energetic cost.


\smallskip

The quadratic behavior near equilibrium shows that \(J\) has a second-order
leading term at its minimum.
If we set \(x=e^t\), we obtain
\[
J(e^t)=\cosh t-1=\frac{t^2}{2}+O(t^4)\quad (t\to0).
\]
Thus, small deviations from equilibrium are penalized quadratically, with no linear term present. This is consistent with the standard quadratic behavior near a stable equilibrium.





\medskip

Although we use the language of energy, \(J\) is a cost function measuring
multiplicative imbalance, not a physical energy in the Hamiltonian sense.
It arises uniquely from the assumptions of Theorem~\ref{thm:main} and plays a role mathematically analogous to that of an energy functional,
in that it characterizes equilibrium, stability, and deviations, without
reference to a specific dynamical system.



 


 


\section{Conclusion} 

In this paper we proved a rigidity result for reciprocal cost functions on $\mathbb{R}_{>0}$.
Assuming normalization, the d’Alembert composition law, and single quadratic calibration at \(1\), we showed that the cost is uniquely determined and equals  $J(x)=\tfrac12(x+x^{-1})-1$.
Thus, once the composition law is fixed, the cost is not a free modeling choice but a
consequence of the imposed structure.
However, this also points to a deeper question: whether the d’Alembert composition law should
be assumed, or whether it can be derived.
This question will be addressed in a further paper, where we will assume the existence of a symmetric polynomial relation between $F(xy)+F(x/y)$ and
$(F(x),F(y))$.

\begin{thebibliography}{99}


%%%
 

\bibitem{Aczel}
J.~Acz\'el,
\textit{Lectures on Functional Equations and Their Applications},
Academic Press, New York, 1966.

\bibitem{Akkouchi}
M.~Akkouchi,
\emph{A note on d’Alembert’s functional equation},
Ann. Math. Blaise Pascal \textbf{8} (2001), no.~1, 1--6.

\bibitem{dAlembert1769}
J.~d'Alembert,
{\it M\'emoire sur les principes de m\'ecanique,}
Hist. Acad. Sci. Paris (1769), 278--286.

\bibitem{golden} I. Cr{\u{a}}ciun, D. Inoan, D. Popa, L. Tudose,
\emph{Generalized Golden Ratios Defined by Means},
Applied Mathematics and Computation \textbf{250} (2015), 221--227.


\bibitem{Davison}
T.~M.~K.~Davison,
\emph{D’Alembert’s functional equation and Chebyshev polynomials},
Ann. Acad. Paed. Cracov., Studia Math. \textbf{4} (2001), 31--38.

\bibitem{EbanksStetkaer}
B.~Ebanks and H.~Stetk{\ae}r,
\emph{d’Alembert’s other functional equation},
Publ. Math. Debrecen \textbf{87} (2015), 319--349.

\bibitem{Kannappan}
P.~Kannappan,
{\it On the Functional Equation $f(x + y) + f(x - y) = 2f(x)f(y)$,}
The American Mathematical Monthly, 72:4, 374--377, (1965).

\bibitem{Kannappan2}
P.~Kannappan,
{\it Functional Equations and Inequalities with Applications,}
Springer, 2009.

\bibitem{Kuczma}
M.~Kuczma,
\emph{An Introduction to the Theory of Functional Equations and Inequalities},
2nd ed., Birkh\"auser (2009).

\bibitem{Papp}
F.~J.~Papp,
{\it The D'Alembert functional equation,}
Amer. Math. Monthly \textbf{92} (1985), 273--275.

\bibitem{Picard1922}
C.-E.~Picard,
{\it Deux le\c{c}ons sur certaines \'equations fonctionnelles et la g\'eom\'etrie non-euclidienne,}
Bull. Soc. Math. France \textbf{46} (1922), 404--416, 425--432.

\bibitem{Poisson1804}
S.~Poisson,
{\it Du parall\'elogramme des forces,}
Correspondance sur l'\'Ecole Polytechnique \textbf{1} (1804), 356--360.

\bibitem{Rudin}
W.~Rudin,
\emph{Principles of Mathematical Analysis},
3rd edition,
McGraw--Hill,
New York, 1976.

 


%%

\end{thebibliography}

 

\end{document}
 
 
\begin{lemma}\label{lem:cosh-dalembert}
The function \(\cosh:\R\to\R\) satisfies the d'Alembert equation
\[
\cosh(t+u)+\cosh(t-u)=2\,\cosh(t)\cosh(u),
\qquad \text{for all } t,u\in\R.
\]
\end{lemma}
\begin{proof}
Recall that \(\cosh(s)=\frac{e^{s}+e^{-s}}{2}\). Then
\begin{align*}
\cosh(t+u)+\cosh(t-u)
&=\frac{e^{t+u}+e^{-(t+u)}}{2}+\frac{e^{t-u}+e^{-(t-u)}}{2}\\
&=\frac{e^{t}(e^{u}+e^{-u})+e^{-t}(e^{u}+e^{-u})}{2}\\
&=\frac{(e^{t}+e^{-t})(e^{u}+e^{-u})}{2}\\
&=2\cdot \frac{e^{t}+e^{-t}}{2}\cdot \frac{e^{u}+e^{-u}}{2}\\
&=2\,\cosh(t)\cosh(u).
\end{align*}
\end{proof}