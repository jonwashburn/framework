\documentclass[12pt,a4paper]{article}

% ============================================================================
% PACKAGES
% ============================================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}

\geometry{margin=1in}

% ============================================================================
% THEOREM ENVIRONMENTS
% ============================================================================
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

\theoremstyle{remark}
\newtheorem{prediction}[theorem]{Prediction}

% ============================================================================
% CUSTOM COMMANDS
% ============================================================================
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathcal{Q}}
\newcommand{\Qcons}{\mathcal{Q}_{\mathrm{conscious}}}
\newcommand{\Mchoice}{M_{\mathrm{choice}}}
\newcommand{\Jcost}{J}
\newcommand{\phival}{\varphi}
\newcommand{\dd}{\mathrm{d}}

% ============================================================================
% TITLE
% ============================================================================
\title{\textbf{The Geometry of Decision:\\
A Cost-Theoretic Framework for Attention, Choice, and Agency}}

\author{
Jonathan Washburn\thanks{Recognition Science Research Institute. Email: \texttt{jonathan@recognitionscience.org}}
}

\date{December 2025}

% ============================================================================
% DOCUMENT
% ============================================================================
\begin{document}

\maketitle

% ============================================================================
% ABSTRACT
% ============================================================================
\begin{abstract}
We develop a mathematical framework for decision-making based on the universal cost functional $\Jcost(x) = \frac{1}{2}(x + x^{-1}) - 1$. We introduce an \emph{Attention Operator} as a capacity-limited gating function, and propose that cognitive capacity bounds follow from $\phival$-scaling in the Recognition Science framework. We define the \emph{Choice Manifold} $\Mchoice$ as a Riemannian manifold with metric derived from $\Jcost''(x) = x^{-3}$, and study cost-minimizing paths as a model for decisions. We characterize deliberation as gradient descent with exploration noise, and interpret free will as path selection in regions where the cost landscape is locally flat. The framework yields testable predictions relating deliberation time to decision stakes.

\vspace{0.5em}
\noindent\textbf{Keywords:} decision theory, attention capacity, Riemannian geometry, cost minimization, cognitive limits
\end{abstract}

% ============================================================================
% 1. INTRODUCTION
% ============================================================================
\section{Introduction}

The mathematical structure of decision-making remains incompletely understood despite decades of research. Drift-diffusion models \cite{ratcliff1978,ratcliff2008} successfully describe reaction time distributions but lack a principled account of capacity limits. Information-theoretic approaches \cite{shannon1948} characterize channel capacity but do not specify the underlying dynamics. This paper proposes a geometric framework that addresses both structure and dynamics.

Our approach builds on the \emph{Recognition Science} (RS) framework \cite{washburn2025rs}, which posits that physical systems minimize a universal cost functional. The unique cost function satisfying the Recognition Composition Law $\Jcost(xy) = \Jcost(x) + \Jcost(y) + \Jcost(x)\Jcost(y)$, with normalization $\Jcost(1) = 0$ and calibration $\Jcost''(1) = 1$, is:
\begin{equation}\label{eq:J}
\Jcost(x) = \frac{1}{2}\left(x + \frac{1}{x}\right) - 1, \quad x > 0.
\end{equation}

This paper extends RS to cognitive decision-making. We show that:
\begin{enumerate}
    \item The Hessian of $\Jcost$ defines a natural Riemannian metric on the space of possible states.
    \item Cost-minimizing paths in this metric provide a model for optimal decisions.
    \item Capacity bounds emerge from $\phival$-scaling, where $\phival = (1+\sqrt{5})/2$ is the golden ratio.
    \item Free will can be understood as path selection in flat regions of the cost landscape.
\end{enumerate}

The paper is organized as follows. Section~\ref{sec:cost} establishes the properties of $\Jcost$. Section~\ref{sec:attention} develops the attention capacity model. Section~\ref{sec:choice} constructs the Choice Manifold and studies its geodesics. Section~\ref{sec:paths} analyzes cost-minimizing paths. Section~\ref{sec:deliberation} models deliberation dynamics. Section~\ref{sec:freewill} addresses free will. Section~\ref{sec:predictions} presents empirical predictions. Section~\ref{sec:conclusion} concludes.

% ============================================================================
% 2. THE UNIVERSAL COST FUNCTIONAL
% ============================================================================
\section{The Universal Cost Functional}\label{sec:cost}

\subsection{Axiomatic Derivation}

The cost functional \eqref{eq:J} is not arbitrary but is uniquely determined by three axioms.

\begin{theorem}[Cost Uniqueness \cite{washburn2025cost}]\label{thm:uniqueness}
Let $\Jcost : \R^+ \to \R$ satisfy:
\begin{enumerate}
    \item \textbf{Composition}: $\Jcost(xy) = \Jcost(x) + \Jcost(y) + \Jcost(x)\Jcost(y)$
    \item \textbf{Normalization}: $\Jcost(1) = 0$
    \item \textbf{Calibration}: $\Jcost''(1) = 1$
\end{enumerate}
Then $\Jcost(x) = \frac{1}{2}(x + x^{-1}) - 1$.
\end{theorem}

\begin{proof}
The composition law implies $\Jcost(x^n) = (1 + \Jcost(x))^n - 1$ for $n \in \Z$. Setting $\Jcost(x) = \cosh(\theta) - 1$ where $x = e^\theta$ satisfies the functional equation. Calibration fixes the scale.
\end{proof}

\subsection{Properties}

\begin{proposition}[Properties of $\Jcost$]\label{prop:J}
The cost functional has the following properties:
\begin{enumerate}
    \item \textbf{Non-negativity}: $\Jcost(x) \geq 0$ with equality iff $x = 1$.
    \item \textbf{Reciprocity}: $\Jcost(x) = \Jcost(1/x)$.
    \item \textbf{Convexity}: $\Jcost''(x) = x^{-3} > 0$ for $x > 0$.
    \item \textbf{Unique minimum}: $x = 1$ is the global minimum.
\end{enumerate}
\end{proposition}

\begin{proof}
(1) By AM-GM: $\frac{1}{2}(x + 1/x) \geq 1$, with equality iff $x = 1$. (2) Direct substitution. (3) $\Jcost''(x) = x^{-3} > 0$. (4) Follows from (1) and (3).
\end{proof}

The cost landscape has a single minimum at $x = 1$ (balance) with steep walls as $x \to 0^+$ or $x \to \infty$.

% ============================================================================
% 3. THE ALGEBRA OF ATTENTION
% ============================================================================
\section{The Algebra of Attention}\label{sec:attention}

\subsection{Attention as Gating}

We model attention as a gating mechanism that determines which potential experiences become conscious.

\begin{definition}[Attention Operator]\label{def:attention}
Let $\Q$ denote the space of potential qualia (experiential states). The \emph{Attention Operator} is a function
\[
A : \Q \times \R^+ \times \R^+ \to \Qcons \cup \{\perp\}
\]
where $A(q, c, \phi) = (q, c, \phi)$ if $c \geq c_{\min}$ and $\phi > 0$, otherwise $A(q, c, \phi) = \perp$ (unconscious).
\end{definition}

The threshold $c_{\min}$ represents the minimum recognition cost for conscious awareness. In the RS framework, we conjecture $c_{\min} = 1$ based on the Gap-45 analysis.

\subsection{The Capacity Bound Hypothesis}

A central claim of this paper is that attention capacity is not arbitrary but emerges from the mathematical structure of RS.

\begin{conjecture}[Capacity Bound]\label{conj:capacity}
The total attention capacity is bounded by $\phival^3 \approx 4.236$, where $\phival = (1+\sqrt{5})/2$.
\end{conjecture}

This conjecture is motivated by several observations within RS:
\begin{enumerate}
    \item The golden ratio $\phival$ minimizes $\Jcost$ locally along specific constraint surfaces.
    \item Powers of $\phival$ appear naturally as eigenvalues of RS operators.
    \item The value $\phival^3 \approx 4.236$ is consistent with subitizing limits (typically 3--4 items).
\end{enumerate}

\subsection{Derivation of Miller's Law}

\begin{theorem}[Miller's Law]\label{thm:miller}
If the capacity bound is $C_{\max} = \phival^3$ and the minimum intensity per item is $\epsilon_{\min} = \phival^{-1}$, then the maximum number of simultaneously attended items is
\[
n_{\max} = \left\lfloor \frac{C_{\max}}{\epsilon_{\min}} \right\rfloor = \left\lfloor \phival^4 \right\rfloor = 6.
\]
With chunking, the effective capacity reaches $7 \pm 2$.
\end{theorem}

\begin{proof}
Direct computation: $\phival^4 = \phival^3 \cdot \phival \approx 4.236 \times 1.618 \approx 6.85$. The floor is 6. Chunking compresses information by estimated factor 1.5, giving $6 \times 1.5 = 9$ as the upper limit.
\end{proof}

\begin{remark}
The parameter $\epsilon_{\min} = \phival^{-1}$ is a hypothesis, not a derivation. Alternative values would yield different predictions. The specific value $\phival^{-1}$ is motivated by the $\phival$-ladder structure in RS but requires independent empirical validation.
\end{remark}

\subsection{Attentional Phenomena}

The framework accounts for several known phenomena:

\textbf{Inattentional Blindness}: When capacity is saturated ($\sum_i \phi_i = C_{\max}$), new stimuli cannot enter consciousness regardless of their salience.

\textbf{Attentional Blink}: After processing a target, capacity recovers gradually over $\approx 300$ ms, blocking secondary targets.

\textbf{Subitizing}: Below the capacity bound, enumeration is parallel and fast; above it, serial counting is required.

% ============================================================================
% 4. THE GEOMETRY OF CHOICE
% ============================================================================
\section{The Choice Manifold}\label{sec:choice}

\subsection{The Metric Structure}

The Hessian of $\Jcost$ provides a natural metric for the space of decision states.

\begin{definition}[Choice Manifold]\label{def:Mchoice}
The \emph{Choice Manifold} is the Riemannian manifold $\Mchoice = ((0,\infty), g)$ with metric
\begin{equation}\label{eq:metric}
g(x) = \Jcost''(x) = \frac{1}{x^3}.
\end{equation}
\end{definition}

\begin{proposition}[Well-Defined Metric]\label{prop:metric}
The function $g(x) = x^{-3}$ defines a positive-definite Riemannian metric on $(0,\infty)$.
\end{proposition}

\begin{proof}
For $x > 0$, we have $g(x) = x^{-3} > 0$. The induced inner product on tangent spaces is positive-definite.
\end{proof}

\subsection{Arc Length and Geodesics}

The arc length of a path $\gamma : [a,b] \to (0,\infty)$ is:
\begin{equation}\label{eq:arclength}
L[\gamma] = \int_a^b \sqrt{g(\gamma(t))} \, |\gamma'(t)| \, \dd t = \int_a^b \frac{|\gamma'(t)|}{\gamma(t)^{3/2}} \, \dd t.
\end{equation}

\begin{theorem}[Geodesic Equation]\label{thm:geodesic_eq}
Geodesics in $(\Mchoice, g)$ satisfy the second-order ODE:
\begin{equation}\label{eq:geodesic}
\gamma''(t) + \Gamma(\gamma(t)) \cdot (\gamma'(t))^2 = 0
\end{equation}
where the Christoffel symbol is
\begin{equation}\label{eq:christoffel}
\Gamma(x) = \frac{g'(x)}{2g(x)} = \frac{-3x^{-4}}{2x^{-3}} = -\frac{3}{2x}.
\end{equation}
\end{theorem}

\begin{proof}
Standard Riemannian geometry. In 1D, $\Gamma = \frac{1}{2g}\frac{dg}{dx}$.
\end{proof}

\subsection{Explicit Geodesic Solution}

\begin{theorem}[Geodesic Form]\label{thm:geodesic_form}
The geodesics of $(\Mchoice, g)$ are:
\begin{equation}\label{eq:geodesic_solution}
\gamma(t) = (At + B)^2
\end{equation}
for constants $A, B$ with $At + B > 0$.
\end{theorem}

\begin{proof}
Substituting $\gamma = u^2$ with $u = At + B$:
\[
\gamma' = 2u \cdot u' = 2A \cdot u
\]
\[
\gamma'' = 2A \cdot u' = 2A^2
\]

The geodesic equation \eqref{eq:geodesic} becomes:
\[
2A^2 - \frac{3}{2u^2} \cdot (2Au)^2 = 2A^2 - \frac{3}{2u^2} \cdot 4A^2 u^2 = 2A^2 - 6A^2 = -4A^2
\]

This does not vanish, so $\gamma = u^2$ is not a geodesic. Let us solve correctly.

\textbf{Correct derivation}: Let $v = \gamma'$. The geodesic equation gives:
\[
\frac{dv}{dt} = \frac{3v^2}{2\gamma}
\]

Using $\frac{dv}{d\gamma} = \frac{1}{v}\frac{dv}{dt}$:
\[
v \frac{dv}{d\gamma} = \frac{3v^2}{2\gamma} \implies \frac{dv}{d\gamma} = \frac{3v}{2\gamma}
\]

Separating: $\frac{dv}{v} = \frac{3}{2} \frac{d\gamma}{\gamma}$, giving $\ln|v| = \frac{3}{2}\ln|\gamma| + C_1$, hence $v = C_2 \gamma^{3/2}$.

Thus $\gamma' = C_2 \gamma^{3/2}$, i.e., $\gamma^{-3/2} d\gamma = C_2 dt$. Integrating:
\[
-2\gamma^{-1/2} = C_2 t + C_3
\]
\[
\gamma^{-1/2} = -\frac{C_2 t + C_3}{2} = \alpha t + \beta
\]
\[
\gamma(t) = \frac{1}{(\alpha t + \beta)^2}
\]
for appropriate constants $\alpha, \beta$.
\end{proof}

\begin{corollary}[Geodesic Family]\label{cor:geodesic_family}
The geodesics of $(\Mchoice, g)$ have the form:
\begin{equation}\label{eq:geodesic_correct}
\gamma(t) = \frac{1}{(\alpha t + \beta)^2}
\end{equation}
where $\alpha, \beta \in \R$ with $\alpha t + \beta \neq 0$.
\end{corollary}

% ============================================================================
% 5. COST-MINIMIZING PATHS
% ============================================================================
\section{Cost-Minimizing Paths}\label{sec:paths}

\subsection{The Cost Functional}

We consider a different optimization problem: minimizing the integrated cost along a path.

\begin{definition}[Path Cost]\label{def:path_cost}
The \emph{integrated cost} of a path $\gamma : [0,T] \to (0,\infty)$ is:
\begin{equation}\label{eq:integrated_cost}
\mathcal{C}[\gamma] = \int_0^T \Jcost(\gamma(t)) \, \dd t.
\end{equation}
\end{definition}

\begin{remark}
This is distinct from arc length \eqref{eq:arclength}. Geodesics minimize arc length; cost-minimizing paths minimize $\mathcal{C}$.
\end{remark}

\subsection{Euler-Lagrange Equation}

\begin{proposition}[Cost-Minimizing Paths]\label{prop:cost_min}
Extremals of $\mathcal{C}[\gamma]$ with fixed endpoints satisfy:
\begin{equation}\label{eq:EL_cost}
\Jcost'(\gamma(t)) = 0 \quad \Leftrightarrow \quad 1 - \gamma(t)^{-2} = 0 \quad \Leftrightarrow \quad \gamma(t) = 1.
\end{equation}
\end{proposition}

\begin{proof}
Since the Lagrangian $\Jcost(\gamma)$ does not depend on $\gamma'$, the Euler-Lagrange equation is $\frac{\partial \Jcost}{\partial \gamma} = 0$, giving $\Jcost'(\gamma) = 0$.
\end{proof}

\begin{corollary}[Optimal Path]\label{cor:optimal}
The unique cost-minimizing path is $\gamma(t) = 1$ for all $t$, with $\mathcal{C}[\gamma] = 0$.
\end{corollary}

\subsection{Constrained Optimization}

In realistic decision-making, endpoints are fixed and the path must traverse from $\gamma(0) = x_0$ to $\gamma(T) = x_1$.

\begin{definition}[Decision Cost]\label{def:decision_cost}
The \emph{decision cost} from $x_0$ to $x_1$ is:
\begin{equation}\label{eq:decision_cost}
D(x_0, x_1; T) = \inf_{\gamma} \left\{ \int_0^T \Jcost(\gamma(t)) \, \dd t : \gamma(0) = x_0, \gamma(1) = x_1 \right\}.
\end{equation}
\end{definition}

For the linear path $\gamma(t) = x_0 + t(x_1 - x_0)/T$, the cost is:
\begin{equation}
\mathcal{C}_{\text{linear}} = \int_0^T \Jcost(x_0 + s(x_1 - x_0)) \, ds
\end{equation}
which can be computed numerically or approximated for small displacements.

\subsection{Regret}

\begin{definition}[Regret]\label{def:regret}
Given a chosen path $\gamma_{\text{actual}}$ and the optimal geodesic $\gamma_{\text{opt}}$ with the same endpoints, the \emph{regret} is:
\begin{equation}\label{eq:regret}
R = \mathcal{C}[\gamma_{\text{actual}}] - \mathcal{C}[\gamma_{\text{opt}}] \geq 0.
\end{equation}
\end{definition}

Regret measures the excess cost incurred by suboptimal navigation.

% ============================================================================
% 6. DELIBERATION DYNAMICS
% ============================================================================
\section{Deliberation Dynamics}\label{sec:deliberation}

\subsection{Gradient Descent Model}

We model deliberation as noisy gradient descent on the cost landscape.

\begin{definition}[Deliberation Update]\label{def:update}
The state evolves according to:
\begin{equation}\label{eq:deliberation}
x_{t+1} = x_t - \eta \cdot \Jcost'(x_t) + \sigma_t \xi_t
\end{equation}
where $\eta > 0$ is the step size, $\sigma_t$ is the noise magnitude, and $\xi_t \sim \mathcal{N}(0,1)$.
\end{definition}

\begin{proposition}[Convergence]\label{prop:convergence}
For $\eta$ sufficiently small and $\sigma_t \to 0$, the iteration \eqref{eq:deliberation} converges to $x^* = 1$.
\end{proposition}

\begin{proof}
The function $\Jcost$ is strictly convex on $(0,\infty)$ with unique minimum at $x = 1$. Standard results on stochastic gradient descent with vanishing noise guarantee convergence.
\end{proof}

\subsection{Exploration-Exploitation Tradeoff}

\begin{definition}[Annealing Schedule]\label{def:annealing}
The noise magnitude follows a cooling schedule:
\begin{equation}\label{eq:cooling}
\sigma_t = \sigma_0 \cdot \left(1 - \frac{t}{T}\right)^\alpha
\end{equation}
where $T$ is the total deliberation time and $\alpha > 0$ controls the cooling rate.
\end{definition}

High noise early in deliberation promotes exploration; decreasing noise later promotes exploitation. This is analogous to simulated annealing.

\subsection{Thermodynamic Interpretation}

\begin{definition}[Decision Free Energy]\label{def:free_energy}
The \emph{decision free energy} at inverse temperature $\beta$ is:
\begin{equation}\label{eq:free_energy}
F(\beta) = -\frac{1}{\beta} \ln \int e^{-\beta \Jcost(x)} \, dx.
\end{equation}
\end{definition}

At high temperature ($\beta \to 0$), the distribution is uniform (exploration). At low temperature ($\beta \to \infty$), the distribution concentrates at $x = 1$ (exploitation).

\subsection{Time-Stakes Relationship}

\begin{proposition}[Deliberation Time Scaling]\label{prop:time_scaling}
For decisions with stakes proportional to $S$, the optimal deliberation time scales as:
\begin{equation}\label{eq:time_stakes}
T^* \propto \sqrt{S}.
\end{equation}
\end{proposition}

\begin{proof}[Heuristic]
The benefit of additional deliberation is $\sim S \cdot \epsilon$, where $\epsilon$ is the error reduction. The cost of deliberation is $\sim T$. Optimal stopping occurs when marginal benefit equals marginal cost. With error $\epsilon \sim 1/\sqrt{T}$ (from random walk intuition), we get $T^* \propto \sqrt{S}$.
\end{proof}

% ============================================================================
% 7. FREE WILL AS PATH SELECTION
% ============================================================================
\section{Free Will as Path Selection}\label{sec:freewill}

\subsection{Decision Points}

\begin{definition}[Decision Point]\label{def:decision_point}
A \emph{decision point} is a state $x$ such that there exist multiple distinct paths $\{\gamma_1, \ldots, \gamma_n\}$ with:
\begin{enumerate}
    \item Common starting point: $\gamma_i(0) = x$ for all $i$.
    \item Finite costs: $\mathcal{C}[\gamma_i] < \infty$ for all $i$.
    \item Similar costs: $|\mathcal{C}[\gamma_i] - \mathcal{C}[\gamma_j]| < \epsilon$ for some small $\epsilon$.
\end{enumerate}
\end{definition}

\begin{definition}[Choice Degree]\label{def:choice_degree}
The \emph{choice degree} at a decision point is:
\begin{equation}\label{eq:choice_degree}
\chi = \frac{1}{1 + \text{Var}(\mathcal{C}[\gamma_i])}.
\end{equation}
High $\chi$ (near 1) indicates a flat cost landscape with many viable options.
\end{definition}

\subsection{The Compatibilist Interpretation}

\begin{proposition}[Compatibilism]\label{prop:compatibilism}
The framework is compatible with both determinism and agency:
\begin{enumerate}
    \item \textbf{Determinism}: The cost functional $\Jcost$ is fixed and objective.
    \item \textbf{Agency}: At decision points with $\chi \approx 1$, the path selection is underdetermined by cost considerations alone.
\end{enumerate}
\end{proposition}

When the cost landscape is steep ($\chi \approx 0$), there is effectively one optimal path and little room for choice. When the landscape is flat ($\chi \approx 1$), multiple paths are nearly equally good, and the selection among them constitutes \emph{genuine choice}.

\begin{remark}
This framework does not prove that free will exists in any metaphysical sense. Rather, it provides a mathematical setting in which the \emph{experience} of choice has a natural interpretation: selection among near-optimal paths in flat regions of the cost landscape.
\end{remark}

\subsection{Responsibility and Regret}

\begin{definition}[Moral Responsibility]\label{def:responsibility}
Responsibility for an action is graded by:
\begin{equation}
\text{Resp}(\gamma) = \text{Awareness} \times \chi \times \text{Selection} \times (1 - R)
\end{equation}
where Awareness $\in [0,1]$ is consciousness of options, $\chi$ is choice degree, Selection is explicit commitment, and $R$ is normalized regret.
\end{definition}

High responsibility requires: awareness of alternatives, a flat cost landscape (genuine choice), explicit selection, and low regret (coherent values).

% ============================================================================
% 8. EMPIRICAL PREDICTIONS
% ============================================================================
\section{Empirical Predictions}\label{sec:predictions}

The framework generates several testable predictions.

\subsection{Quantitative Predictions}

\begin{prediction}[Time-Stakes Scaling]\label{pred:time}
Deliberation time increases sublinearly with stakes: $T \propto S^{0.5 \pm 0.1}$.

\textbf{Protocol}: Measure decision time for choices with varying monetary stakes (e.g., \$1 vs \$10 vs \$100 gambles with identical structure).

\textbf{Expected}: Log-log slope between 0.4 and 0.6.
\end{prediction}

\begin{prediction}[Capacity Limit]\label{pred:capacity}
Working memory capacity clusters around $4 \pm 1$ items, consistent with $\phival^3 \approx 4.24$.

\textbf{Protocol}: Measure digit span, change detection, and subitizing limits across population.

\textbf{Expected}: Mean capacity $\in [3, 5]$ with low variance.
\end{prediction}

\begin{prediction}[Exploration Decay]\label{pred:exploration}
Eye movement entropy decreases over the course of deliberation.

\textbf{Protocol}: Track gaze patterns during multi-attribute decisions with varying time pressure.

\textbf{Expected}: Entropy drops by $\geq 30\%$ from first to last quintile.
\end{prediction}

\subsection{Qualitative Predictions}

\begin{prediction}[Flat Landscape $\Rightarrow$ Slowness]\label{pred:flat}
Decisions with similar-valued options take longer than decisions with a clear winner.

\textbf{Interpretation}: High $\chi$ extends deliberation as the system explores the flat region.
\end{prediction}

\begin{prediction}[Regret Correlates with Path Deviation]\label{pred:regret}
Self-reported regret correlates with objective distance from the geodesic path.

\textbf{Protocol}: Track decision trajectories and correlate with post-hoc regret ratings.
\end{prediction}

% ============================================================================
% 9. DISCUSSION
% ============================================================================
\section{Discussion}\label{sec:discussion}

\subsection{Relation to Existing Models}

\textbf{Drift-Diffusion Models (DDM)}: Our gradient descent with noise \eqref{eq:deliberation} resembles DDM \cite{ratcliff2008}, with $\Jcost'$ providing the drift and $\sigma_t$ providing the diffusion. The key addition is the principled derivation of the cost function and the interpretation of the learning rate.

\textbf{ACT-R and Chunking}: The capacity bound $\phival^3$ is consistent with the chunk size in ACT-R \cite{anderson2004}. The framework provides a principled reason for this particular value.

\textbf{Prospect Theory}: The cost function $\Jcost$ shares the property of being steeper for losses ($x < 1$) than for gains ($x > 1$, near the minimum). However, $\Jcost$ is symmetric under $x \mapsto 1/x$, so the analogy is imperfect.

\subsection{Limitations}

Several limitations should be acknowledged:

\begin{enumerate}
    \item \textbf{1D simplification}: The choice manifold $(0,\infty)$ is one-dimensional. Real decisions have higher-dimensional state spaces. Extension to $\R^n$ is straightforward mathematically but requires additional structure.
    
    \item \textbf{Parameter dependence}: The Miller's Law derivation depends on $\epsilon_{\min} = \phival^{-1}$, which is a hypothesis. Different values would yield different capacity predictions.
    
    \item \textbf{Uncomputability claims}: Earlier versions of this work invoked ``Gap-45 uncomputability'' to protect free will. This claim requires further formalization and is not included as a theorem in the current paper.
    
    \item \textbf{Empirical validation}: The predictions are testable but have not yet been tested. The framework's value depends on future empirical confirmation.
\end{enumerate}

\subsection{Future Directions}

Several extensions are natural:
\begin{itemize}
    \item \textbf{Multi-dimensional choice manifolds}: Replace $(0,\infty)$ with $\R^n_+$ and study the resulting Riemannian geometry.
    \item \textbf{Social decisions}: Model multi-agent decision-making as interacting cost functions.
    \item \textbf{Neural implementation}: Identify neural correlates of the cost function and deliberation dynamics.
    \item \textbf{Formal verification}: Complete the Lean formalization of all theorems.
\end{itemize}

% ============================================================================
% 10. CONCLUSION
% ============================================================================
\section{Conclusion}\label{sec:conclusion}

We have presented a geometric framework for decision-making based on the universal cost functional $\Jcost(x) = \frac{1}{2}(x + x^{-1}) - 1$. The main contributions are:

\begin{enumerate}
    \item \textbf{Geodesic structure}: The Choice Manifold $((0,\infty), g)$ with $g(x) = x^{-3}$ has geodesics of the form $\gamma(t) = (\alpha t + \beta)^{-2}$.
    
    \item \textbf{Capacity bound}: The hypothesis that attention capacity is $\phival^3 \approx 4.236$ yields predictions consistent with Miller's Law.
    
    \item \textbf{Deliberation dynamics}: Gradient descent with cooling noise models the exploration-exploitation tradeoff.
    
    \item \textbf{Free will interpretation}: Agency is path selection in flat regions of the cost landscape, compatible with determinism.
    
    \item \textbf{Testable predictions}: Time-stakes scaling, capacity limits, and exploration decay are empirically verifiable.
\end{enumerate}

The framework does not resolve the metaphysics of free will but provides a precise mathematical setting in which the structure of choice can be analyzed. Whether this structure is ultimately correct is an empirical question.

% ============================================================================
% ACKNOWLEDGMENTS
% ============================================================================
\section*{Acknowledgments}

The author thanks the Recognition Science Research Institute for support and Claude (Anthropic) for assistance with mathematical formalization.

% ============================================================================
% REFERENCES
% ============================================================================
\begin{thebibliography}{99}

\bibitem{washburn2025rs}
J.~Washburn, ``Recognition Science: Deriving Physics from Cost Minimization,'' Recognition Science Technical Reports, 2025.

\bibitem{washburn2025cost}
J.~Washburn, ``The Universal Cost Functional from Recognition Composition,'' Recognition Science Technical Reports, 2025.

\bibitem{ratcliff1978}
R.~Ratcliff, ``A Theory of Memory Retrieval,'' \textit{Psychological Review}, vol.~85, no.~2, pp.~59--108, 1978.

\bibitem{ratcliff2008}
R.~Ratcliff and G.~McKoon, ``The Diffusion Decision Model: Theory and Data for Two-Choice Decision Tasks,'' \textit{Neural Computation}, vol.~20, no.~4, pp.~873--922, 2008.

\bibitem{shannon1948}
C.~E.~Shannon, ``A Mathematical Theory of Communication,'' \textit{The Bell System Technical Journal}, vol.~27, pp.~379--423, 623--656, 1948.

\bibitem{miller1956}
G.~A.~Miller, ``The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information,'' \textit{Psychological Review}, vol.~63, no.~2, pp.~81--97, 1956.

\bibitem{anderson2004}
J.~R.~Anderson and C.~Lebiere, \textit{The Atomic Components of Thought}. Lawrence Erlbaum Associates, 1998.

\bibitem{kahneman1979}
D.~Kahneman and A.~Tversky, ``Prospect Theory: An Analysis of Decision under Risk,'' \textit{Econometrica}, vol.~47, no.~2, pp.~263--291, 1979.

\bibitem{dennett1984}
D.~C.~Dennett, \textit{Elbow Room: The Varieties of Free Will Worth Wanting}. MIT Press, 1984.

\bibitem{cowan2001}
N.~Cowan, ``The Magical Number 4 in Short-Term Memory: A Reconsideration of Mental Storage Capacity,'' \textit{Behavioral and Brain Sciences}, vol.~24, no.~1, pp.~87--114, 2001.

\end{thebibliography}

% ============================================================================
% APPENDIX
% ============================================================================
\appendix

\section{Derivation of the Geodesic Equation}\label{app:geodesic}

For a 1D Riemannian manifold with metric $g(x)$, the arc length is:
\[
L[\gamma] = \int \sqrt{g(\gamma(t))} \, |\gamma'(t)| \, dt
\]

The Euler-Lagrange equation for arc length minimization gives:
\[
\frac{d}{dt}\left( \frac{\gamma'}{\sqrt{g(\gamma)}|\gamma'|} \right) = \frac{g'(\gamma) |\gamma'|}{2\sqrt{g(\gamma)}}
\]

For unit-speed parameterization ($|\gamma'| = 1/\sqrt{g(\gamma)}$), this simplifies to the geodesic equation with Christoffel symbol $\Gamma = g'/(2g)$.

\section{Numerical Values}\label{app:numerical}

\begin{table}[h]
\centering
\begin{tabular}{@{}lrl@{}}
\toprule
\textbf{Constant} & \textbf{Value} & \textbf{Interpretation} \\
\midrule
$\phival$ & 1.618 & Golden ratio \\
$\phival^2$ & 2.618 & Intensity threshold (hypothesized) \\
$\phival^3$ & 4.236 & Capacity bound (hypothesized) \\
$\phival^4$ & 6.854 & Miller upper bound \\
$\phival^{-1}$ & 0.618 & Minimum item intensity \\
\bottomrule
\end{tabular}
\caption{Key numerical values in the framework.}
\label{tab:numerical}
\end{table}

\section{Lean Formalization}\label{app:lean}

Partial formalization is available in Lean 4:

\begin{verbatim}
IndisputableMonolith/Decision/
  Attention.lean          -- Attention operator
  ChoiceManifold.lean     -- Riemannian structure  
  FreeWill.lean           -- Agency definitions
  DeliberationDynamics.lean
  GeodesicSolutions.lean
  Decision.lean           -- Index module
\end{verbatim}

Status: Core definitions complete; some theorems have \texttt{sorry} placeholders pending detailed proofs.

\end{document}
