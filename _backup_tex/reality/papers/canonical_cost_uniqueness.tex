\documentclass[preprint,amsmath,amssymb]{revtex4-2}

\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Rp}{\R_{>0}}
\newcommand{\e}{\mathrm{e}}

\begin{document}

\preprint{Submitted to \textit{Journal of Mathematical Physics}}

\title{Cost Is Not a Dial:\\
A Self-Contained Uniqueness Theorem for the Canonical Reciprocal Cost on \texorpdfstring{$\R_{>0}$}{R\_>0}}

\author{Jonathan Washburn}
\affiliation{Recognition Physics Research Institute, Austin, Texas, USA}
\email{jon@recognitionphysics.org}

\date{\today}

\begin{abstract}
Many mathematical and physical frameworks introduce a \emph{cost} (or action, penalty, divergence, or energy) to quantify change, then proceed as if that choice were canonical. When downstream conclusions depend on the cost, the theory acquires a hidden degree of freedom: one may swap the cost to fit desired outcomes. This problem is especially acute in ``parameter-free'' derivation programs, where predictivity requires eliminating not only tunable constants but also tunable \emph{functional forms}.

This paper isolates and proves a self-contained uniqueness theorem for a cost on the positive reals. Define
\[
J(x)\;:=\;\frac{x+x^{-1}}{2}-1\qquad (x>0).
\]
We show that if a candidate cost \(F:\Rp\to\R\) is normalized (\(F(1)=0\)) and satisfies the composition law (equivalently: its log-lift \(H(t):=F(\e^t)+1\) satisfies the d'Alembert functional equation)
\[
H(t+u)+H(t-u)=2\,H(t)\,H(u)\qquad(t,u\in\R),
\]
together with the unit-curvature calibration, then necessarily \(F(x)=J(x)\) for all \(x>0\). In the strengthened form proved here, no global smoothness or continuity assumption is required: continuity (indeed \(C^2\) regularity) is derived from the functional identity plus the quadratic calibration
\[
\lim_{t\to 0}\frac{2\,F(\e^t)}{t^2}=1.
\]

The manuscript is self-contained: all proofs are given in the text. A single optional machine-check of the main theorem is available as a supplementary artifact.\footnote{Supplementary verification artifact (Lean 4): \url{https://github.com/REPLACE-WITH-ARCHIVED-REPO}. The present paper does not rely on this artifact; it is provided solely for independent auditing of the printed statements.}
\end{abstract}

\maketitle

\section{Introduction}

\subsection{Motivation: eliminating hidden functional degrees of freedom}
In many areas of mathematics and physics, one quantifies ``how different'' two states are by selecting a scalar functional: a cost, energy, divergence, or action. Such choices are often guided by symmetry, convenience, or tradition (e.g., quadratic penalties, log-likelihoods, or variational principles). But once a framework is built atop a chosen cost, it is easy to overlook that the cost itself may be a \emph{dial}: different choices can preserve superficial qualitative behavior while materially changing quantitative outputs.

If the goal is explanatory or predictive, this dial matters. In particular, claims of being ``parameter-free'' can be undermined even in the absence of explicit tunable constants: if one can vary the functional form of the cost while keeping the rest of the story fixed, then the cost selection plays the role of an implicit parameter family. For this reason, a credible parameter-free derivation program needs \emph{uniqueness} results: conditions under which the cost is forced, rather than chosen.

\subsection{Context (optional): Recognition Science}
Recognition Science (also called Recognition Physics) is a program aiming to derive a coherent mathematical scaffold for dynamics from a small set of structural constraints, including a ledger-style consistency discipline and a composition law for ``recognition'' amplitudes. In that setting, a cost on multiplicative ratios appears as a primitive interface between composition and measurement. The present paper does \emph{not} require the broader Recognition Science framework; we mention it only as motivation for why one is led to consider reciprocal costs and cosine-type functional equations in log-coordinates.

Our aim here is narrower and purely mathematical: to prove that a natural set of explicit hypotheses forces a unique closed-form cost on \(\Rp\).

\subsection{The canonical reciprocal cost}
\begin{definition}[Canonical reciprocal cost]
Define \(J:\Rp\to\R\) by
\[
J(x)\;:=\;\frac{x+x^{-1}}{2}-1.
\]
\end{definition}
This function has three immediately visible features: reciprocity symmetry \(J(x)=J(x^{-1})\), normalization \(J(1)=0\), and nonnegativity via
\[
J(x)=\frac{(x-1)^2}{2x}\ge 0.
\]
In log-coordinates it becomes hyperbolic:
\[
J(\e^t)=\cosh(t)-1.
\]

\subsection{Main result (stated)}
We now state the main theorem proved in this paper.

\begin{theorem}[Uniqueness of the canonical reciprocal cost]\label{thm:main}
Let \(F:\Rp\to\R\). Assume:
\begin{enumerate}
  \item \textbf{Normalization:} \(F(1)=0\).
  \item \textbf{Composition law on \(\Rp\):} for all \(x,y>0\),
  \[
  F(xy)+F(x/y)=2\,F(x)\,F(y)+2\,F(x)+2\,F(y).
  \]
  \item \textbf{Quadratic calibration at the identity:}
  \[
  \lim_{t\to 0}\frac{2\,F(\e^t)}{t^2}=1.
  \]
\end{enumerate}
Then for all \(x>0\),
\[
F(x)=\frac{x+x^{-1}}{2}-1 \;=\; J(x).
\]
\end{theorem}

\subsection{Why these hypotheses are reasonable}
The theorem separates two kinds of input:
\begin{itemize}
\item \textbf{Structural symmetry (normalization)} \(F(1)=0\), which fixes the reference point. In fact, reciprocity \(F(x)=F(x^{-1})\) is then forced by the \(\Rp\) composition law by plugging \(x=1\) into Definition~\ref{def:rp-law}.
  \item \textbf{A composition identity} on \(\Rp\) that is equivalent (via log-coordinates) to the d'Alembert functional equation. This is the same addition law that characterizes cosine- and hyperbolic-cosine-type functions.
  \item \textbf{A single calibration} \(\lim_{t\to 0}2F(\e^t)/t^2=1\) that fixes the overall scale, ruling out the one-parameter family \(t\mapsto \cosh(\lambda t)-1\).
\end{itemize}
The proof shows that these constraints do not merely suggest the closed form \(J\); they force it.

\subsection{Paper organization}
Section~\ref{sec:prelim} collects definitions and elementary lemmas (log-coordinates, the canonical cost, and the d'Alembert equation). Section~\ref{sec:results} states the main uniqueness results. Section~\ref{sec:roadmap} gives short proof roadmaps. Section~\ref{sec:proof} contains complete proofs. Section~\ref{sec:discussion} discusses how the hypotheses arise in recognition-based composition models and what uniqueness does (and does not) buy downstream.

% Skeleton for the rest of the paper (to be filled in next):
\section{Definitions and basic properties}\label{sec:prelim}

\subsection{Domain and reciprocity symmetry}
We work on the multiplicative positive reals
\[
\Rp:=\{x\in\R:\ x>0\},
\]
which we interpret as \emph{ratios} (scale changes). A central structural symmetry on \(\Rp\) is inversion \(x\mapsto x^{-1}\): if \(x\) represents a change in one direction, then \(x^{-1}\) represents the inverse change.

\begin{definition}[Reciprocity symmetry and normalization]\label{def:recip-norm}
A function \(F:\Rp\to\R\) is called a \emph{reciprocal cost} if
\[
F(x)=F(x^{-1})\qquad\text{for all }x>0.
\]
It is \emph{normalized} if \(F(1)=0\).
\end{definition}

\subsection{Log-coordinates}
Log-coordinates turn multiplication into addition. Given \(F:\Rp\to\R\), define its log-lift
\[
G(t):=F(\e^t),\qquad H(t):=G(t)+1=F(\e^t)+1,\qquad t\in\R.
\]

\begin{lemma}[Reciprocity implies evenness]\label{lem:recip-even}
If \(F\) is reciprocal (Definition~\ref{def:recip-norm}), then \(G\) and \(H\) are even:
\[
G(-t)=G(t),\qquad H(-t)=H(t)\qquad(t\in\R).
\]
\end{lemma}
\begin{proof}
Since \(\e^{-t}=(\e^t)^{-1}\) and \(F(x)=F(x^{-1})\), we have
\[
G(-t)=F(\e^{-t})=F\bigl((\e^t)^{-1}\bigr)=F(\e^t)=G(t).
\]
Then \(H(-t)=G(-t)+1=G(t)+1=H(t)\).
\end{proof}

\begin{lemma}[Normalization in log-coordinates]\label{lem:norm-log}
If \(F(1)=0\), then \(G(0)=0\) and \(H(0)=1\).
\end{lemma}
\begin{proof}
Since \(\e^0=1\), we have \(G(0)=F(\e^0)=F(1)=0\), hence \(H(0)=G(0)+1=1\).
\end{proof}

\subsection{The canonical reciprocal cost and its elementary identities}
We will compare general reciprocal costs to the closed-form cost
\[
J(x):=\frac{x+x^{-1}}{2}-1,\qquad x>0.
\]

\begin{lemma}[Squared form and nonnegativity of \(J\)]\label{lem:J-squared}
For all \(x>0\),
\[
J(x)=\frac{(x-1)^2}{2x}\ge 0,
\]
with equality if and only if \(x=1\).
\end{lemma}
\begin{proof}
Compute
\[
J(x)=\frac{x+x^{-1}}{2}-1=\frac{x+\frac{1}{x}-2}{2}
=\frac{\frac{x^2+1-2x}{x}}{2}
=\frac{(x-1)^2}{2x}.
\]
Since \(x>0\), the denominator \(2x>0\), so \(J(x)\ge 0\), and \(J(x)=0\) iff \((x-1)^2=0\), i.e.\ \(x=1\).
\end{proof}

\begin{definition}[Hyperbolic cosine]\label{def:cosh}
For \(t\in\R\), define
\[
\cosh(t):=\frac{\e^t+\e^{-t}}{2}.
\]
\end{definition}

\begin{lemma}[Log--cosh identity]\label{lem:J-log-cosh}
For all \(t\in\R\),
\[
J(\e^t)=\cosh(t)-1.
\]
Equivalently, the log-lift of \(J\) is \(G_J(t)=\cosh(t)-1\) and \(H_J(t)=\cosh(t)\).
\end{lemma}
\begin{proof}
Using Definition~\ref{def:cosh},
\[
J(\e^t)=\frac{\e^t+(\e^t)^{-1}}{2}-1
=\frac{\e^t+\e^{-t}}{2}-1
=\cosh(t)-1.
\]
\end{proof}

\subsection{The d'Alembert functional equation (composition law)}
The key structural identity in this paper is the d'Alembert functional equation.

\begin{definition}[d'Alembert equation]\label{def:dalembert}
A function \(H:\R\to\R\) satisfies the d'Alembert equation if for all \(t,u\in\R\),
\[
H(t+u)+H(t-u)=2\,H(t)\,H(u).
\]
\end{definition}

\begin{lemma}[Evenness from d'Alembert and normalization]\label{lem:dalembert-even}
If \(H\) satisfies Definition~\ref{def:dalembert} and \(H(0)=1\), then \(H\) is even.
\end{lemma}
\begin{proof}
Fix \(u\in\R\) and apply the d'Alembert equation with \(t=0\):
\[
H(u)+H(-u)=2\,H(0)\,H(u)=2H(u),
\]
so \(H(-u)=H(u)\).
\end{proof}

\begin{lemma}[Product identity]\label{lem:dalembert-product}
Assume \(H\) satisfies the d'Alembert equation and \(H(0)=1\). Then for all \(t,u\in\R\),
\[
H(t+u)\,H(t-u)=H(t)^2+H(u)^2-1.
\]
\end{lemma}
\begin{proof}
Apply d'Alembert with \(a=t+u\) and \(b=t-u\):
\[
H((t+u)+(t-u))+H((t+u)-(t-u))=2H(t+u)H(t-u),
\]
so \(H(2t)+H(2u)=2H(t+u)H(t-u)\). Using the duplication formula
\(
H(2t)=2H(t)^2-1
\)
(obtained from d'Alembert at \((t,t)\) and \(H(0)=1\)), and similarly for \(u\), yields the claim.
\end{proof}

\begin{lemma}[Difference-square identity]\label{lem:dalembert-diff-square}
Assume \(H\) satisfies d'Alembert and \(H(0)=1\). Then for all \(t,u\in\R\),
\[
\bigl(H(t+u)-H(t-u)\bigr)^2=4\,(H(t)^2-1)\,(H(u)^2-1).
\]
\end{lemma}
\begin{proof}
Let \(A:=H(t+u)\) and \(B:=H(t-u)\). Then \(A+B=2H(t)H(u)\) by d'Alembert, and \(AB=H(t)^2+H(u)^2-1\)
by Lemma~\ref{lem:dalembert-product}. Hence
\[
(A-B)^2=(A+B)^2-4AB
=4H(t)^2H(u)^2-4(H(t)^2+H(u)^2-1)
=4(H(t)^2-1)(H(u)^2-1).
\]
\end{proof}

\begin{lemma}[Continuity from the curvature limit]\label{lem:dalembert-continuity}
Assume \(H\) satisfies d'Alembert and \(H(0)=1\), and that the quadratic curvature limit
\(\kappa_H=\lim_{t\to 0}2(H(t)-1)/t^2\) exists. Then \(H\) is continuous on \(\R\).
\end{lemma}
\begin{proof}
The limit assumption implies \(H(t)\to 1\) as \(t\to 0\), so \(H\) is continuous at \(0\).

Fix \(t\in\R\). For \(u\to 0\), d'Alembert gives
\[
H(t+u)+H(t-u)=2H(t)H(u)\xrightarrow[u\to 0]{}2H(t).
\]
Also, by Lemma~\ref{lem:dalembert-diff-square},
\[
\bigl(H(t+u)-H(t-u)\bigr)^2
=4(H(t)^2-1)(H(u)^2-1)\xrightarrow[u\to 0]{}0,
\]
so \(H(t+u)-H(t-u)\to 0\). Therefore
\[
H(t+u)=\frac{(H(t+u)+H(t-u))+(H(t+u)-H(t-u))}{2}\xrightarrow[u\to 0]{}H(t),
\]
and similarly \(H(t-u)\to H(t)\). Thus \(H\) is continuous at every \(t\).
\end{proof}

\begin{lemma}[Cosh satisfies d'Alembert]\label{lem:cosh-dalembert}
The function \(t\mapsto\cosh(t)\) satisfies the d'Alembert equation.
\end{lemma}
\begin{proof}
Using Definition~\ref{def:cosh},
\[
\cosh(t+u)+\cosh(t-u)
=\frac{\e^{t+u}+\e^{-(t+u)}+\e^{t-u}+\e^{-(t-u)}}{2}.
\]
Group terms:
\[
\e^{t+u}+\e^{t-u}=\e^t(\e^u+\e^{-u}),\qquad
\e^{-(t+u)}+\e^{-(t-u)}=\e^{-t}(\e^{-u}+\e^{u}).
\]
Therefore
\[
\cosh(t+u)+\cosh(t-u)
=\frac{(\e^t+\e^{-t})(\e^u+\e^{-u})}{2}
=2\left(\frac{\e^t+\e^{-t}}{2}\right)\left(\frac{\e^u+\e^{-u}}{2}\right)
=2\,\cosh(t)\,\cosh(u).
\]
\end{proof}

\begin{remark}[Shifted form for the cost lift]\label{rem:shifted}
If \(H\) satisfies the d'Alembert equation and we define \(G:=H-1\), then expanding
\(
H=G+1
\)
shows that \(G\) satisfies the shifted identity
\[
G(t+u)+G(t-u)=2\,G(t)\,G(u)+2\,G(t)+2\,G(u).
\]
In particular, by Lemma~\ref{lem:J-log-cosh} and Lemma~\ref{lem:cosh-dalembert}, the log-lift
\(
H_J(t)=J(\e^t)+1=\cosh(t)
\)
obeys the d'Alembert equation.
\end{remark}

\subsection{Composition law directly on \texorpdfstring{$\Rp$}{R\_>0}}\label{sec:rp-law}
The main theorem of this paper is stated directly on \(\Rp\), so that log-coordinates appear only as
a proof technique.

\begin{definition}[Recognition Composition Law on \(\Rp\)]\label{def:rp-law}
A function \(F:\Rp\to\R\) satisfies the \emph{Recognition Composition Law on \(\Rp\)} if for all
\(x,y>0\),
\[
F(xy)+F(x/y)=2\,F(x)\,F(y)+2\,F(x)+2\,F(y).
\]
\end{definition}

\begin{lemma}[Equivalence of the \(\Rp\) law and the log d'Alembert equation]\label{lem:equiv-rp-dalembert}
Let \(F:\Rp\to\R\), and define \(H:\R\to\R\) by \(H(t):=F(\e^t)+1\).
Then \(F\) satisfies Definition~\ref{def:rp-law} if and only if \(H\) satisfies the d'Alembert
equation (Definition~\ref{def:dalembert}).
\end{lemma}
\begin{proof}
Assume \(F\) satisfies Definition~\ref{def:rp-law}. Let \(t,u\in\R\) and set \(x=\e^t\), \(y=\e^u\),
so \(xy=\e^{t+u}\) and \(x/y=\e^{t-u}\). Then
\begin{align*}
H(t+u)+H(t-u)
&=\bigl(F(\e^{t+u})+1\bigr)+\bigl(F(\e^{t-u})+1\bigr)\\
&=\bigl(F(xy)+F(x/y)\bigr)+2\\
&=\bigl(2F(x)F(y)+2F(x)+2F(y)\bigr)+2\\
&=2\bigl(F(x)+1\bigr)\bigl(F(y)+1\bigr)
=2H(t)H(u),
\end{align*}
so \(H\) satisfies d'Alembert.

Conversely, if \(H\) satisfies d'Alembert, reverse the calculation with \(x=\e^t\), \(y=\e^u\) to
obtain Definition~\ref{def:rp-law}.
\end{proof}

\begin{definition}[Quadratic calibration at the identity]\label{def:calibration}
Let \(F:\Rp\to\R\). When the limit exists, define the \emph{log-curvature} of \(F\) at the identity as
\[
\kappa(F):=\lim_{t\to 0}\frac{2\,F(\e^t)}{t^2}.
\]
Equivalently, \(\kappa(F)=\lim_{x\to 1}\frac{2\,F(x)}{(\log x)^2}\) whenever either limit exists.
\end{definition}

\section{Main results}\label{sec:results}

This section records the main statements proved in the paper. Proofs appear in
Section~\ref{sec:proof}.

\subsection{Non-vacuity: the canonical cost satisfies the hypotheses}
\begin{lemma}[The canonical cost meets the structural conditions]\label{lem:J-meets}
Let \(J(x)=\tfrac12(x+x^{-1})-1\) on \(\Rp\).
Then:
\begin{enumerate}
  \item \(J\) is reciprocal and normalized: \(J(x)=J(x^{-1})\) for all \(x>0\) and \(J(1)=0\).
  \item \(J\) satisfies the Recognition Composition Law on \(\Rp\) (Definition~\ref{def:rp-law}).
  \item \(J\) has unit log-curvature: \(\kappa(J)=1\) (Definition~\ref{def:calibration}).
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Reciprocity is immediate from the definition since \(x+x^{-1}\) is invariant under
\(x\mapsto x^{-1}\). Also \(J(1)=\tfrac12(1+1)-1=0\).

(2) Define \(H_J(t):=J(\e^t)+1\). By Lemma~\ref{lem:J-log-cosh}, \(H_J(t)=\cosh(t)\), and by
Lemma~\ref{lem:cosh-dalembert} the function \(\cosh\) satisfies d'Alembert. The equivalence
Lemma~\ref{lem:equiv-rp-dalembert} then implies that \(J\) satisfies the \(\Rp\) composition law.

(3) Using \(J(\e^t)=\cosh(t)-1\) (Lemma~\ref{lem:J-log-cosh}) and the Taylor expansion
\(\cosh(t)=1+t^2/2+o(t^2)\) as \(t\to 0\), we have
\[
\lim_{t\to 0}\frac{2J(\e^t)}{t^2}
=\lim_{t\to 0}\frac{2(\cosh(t)-1)}{t^2}=1,
\]
so \(\kappa(J)=1\).
\end{proof}

\subsection{Core uniqueness at the level of the composition law}
\begin{theorem}[Classification of calibrated d'Alembert solutions]\label{thm:cosh-unique}
Let \(H:\R\to\R\) satisfy the d'Alembert equation with \(H(0)=1\).
Assume the quadratic curvature limit exists:
\[
\kappa_H:=\lim_{t\to 0}\frac{2\,(H(t)-1)}{t^2}\in\R.
\]
Then:
\begin{enumerate}
  \item If \(\kappa_H>0\), then \(H(t)=\cosh(\sqrt{\kappa_H}\,t)\) for all \(t\in\R\).
  \item If \(\kappa_H<0\), then \(H(t)=\cos(\sqrt{-\kappa_H}\,t)\) for all \(t\in\R\).
  \item If \(\kappa_H=0\), then \(H(t)=1\) for all \(t\in\R\).
\end{enumerate}
In particular, if \(\kappa_H=1\), then \(H(t)=\cosh(t)\) for all \(t\in\R\).
\end{theorem}

\subsection{Cost uniqueness on \texorpdfstring{$\R_{>0}$}{R\_>0}}
\begin{corollary}[Uniqueness of the canonical reciprocal cost on \(\Rp\)]\label{cor:cost-unique}
Let \(F:\Rp\to\R\) be normalized (\(F(1)=0\)). Assume \(F\) satisfies the
\(\Rp\) composition law (Definition~\ref{def:rp-law}) and has unit log-curvature \(\kappa(F)=1\)
(Definition~\ref{def:calibration}). Then
\[
F(x)=\frac{x+x^{-1}}{2}-1
\qquad\text{for all }x>0.
\]
\end{corollary}
\begin{proof}
Define \(H(t):=F(\e^t)+1\). By Lemma~\ref{lem:equiv-rp-dalembert}, \(H\) satisfies d'Alembert, and
moreover,
\[
\kappa_H=\lim_{t\to 0}\frac{2(H(t)-1)}{t^2}=\lim_{t\to 0}\frac{2F(\e^t)}{t^2}=\kappa(F)=1.
\]
Theorem~\ref{thm:cosh-unique} then yields \(H(t)=\cosh(t)\), hence
\(
F(\e^t)=\cosh(t)-1=J(\e^t)
\)
by Lemma~\ref{lem:J-log-cosh}. Writing any \(x>0\) as \(x=\e^{\log x}\) gives \(F(x)=J(x)\).
\end{proof}

\section{Proof roadmaps}\label{sec:roadmap}
This section provides compact roadmaps for the main arguments; the full details appear in
Section~\ref{sec:proof}.

\subsection{Roadmap for cost uniqueness on \texorpdfstring{$\R_{>0}$}{R\_>0}}
The proof of Corollary~\ref{cor:cost-unique} is short once the log--cosh connection is in place:
\begin{enumerate}
  \item \textbf{Lift to log-coordinates.} Define \(H(t):=F(\e^t)+1\), so the multiplicative input
  variable \(x>0\) becomes an additive variable \(t\in\R\).
  \item \textbf{Identify the lift.} The \(\Rp\) composition law is equivalent to d'Alembert for \(H\)
  (Lemma~\ref{lem:equiv-rp-dalembert}), and the log-curvature \(\kappa(F)\) becomes the quadratic
  curvature \(\kappa_H\) of \(H\) at the origin.
  \item \textbf{Classify \(H\).} Apply Theorem~\ref{thm:cosh-unique} to conclude that \(H\) is
  \(\cosh(\sqrt{\kappa_H}\,t)\), \(\cos(\sqrt{-\kappa_H}\,t)\), or identically \(1\). Under the unit
  calibration \(\kappa_H=1\), this gives \(H(t)=\cosh(t)\).
  \item \textbf{Return to \(\Rp\).} Since \(F(\e^t)=H(t)-1=\cosh(t)-1\), Lemma~\ref{lem:J-log-cosh}
  implies \(F(\e^t)=J(\e^t)\) for all \(t\). Writing any \(x>0\) as \(x=\e^{\log x}\) yields
  \(F(x)=J(x)\).
\end{enumerate}

\subsection{Roadmap for the classification theorem}
Theorem~\ref{thm:cosh-unique} is proved by using the curvature limit to justify a legitimate ODE
bootstrap from a functional equation:
\begin{enumerate}
  \item \textbf{Central-difference identity.} Rewrite d'Alembert at \((t,h)\) to express the central
  second difference \(D_h H(t)\) in terms of \(H(t)\) and the scalar quotient
  \(q(h):=2(H(h)-1)/h^2\).
  \item \textbf{Use the curvature limit.} The limit \(q(h)\to\kappa_H\) implies
  \(D_h H(t)\to \kappa_H H(t)\) uniformly on compact sets.
  \item \textbf{Bootstrap to \(C^2\).} A general real-analysis lemma (Lemma~\ref{lem:central-diff-C2})
  converts uniform convergence of central differences into classical \(C^2\) regularity, giving the
  ODE \(H''=\kappa_H H\) (Lemma~\ref{lem:dalembert-curvature-ode}).
  \item \textbf{Solve the ODE with even initial data.} d'Alembert implies evenness, hence \(H'(0)=0\).
  Comparing with the explicit solutions of \(y''=\kappa_H y\) yields
  \(H(t)=\cosh(\sqrt{\kappa_H}t)\) when \(\kappa_H>0\), \(H(t)=\cos(\sqrt{-\kappa_H}t)\) when
  \(\kappa_H<0\), and \(H\equiv 1\) when \(\kappa_H=0\).
\end{enumerate}

\begin{remark}[Why the calibration matters]
Without calibration, the d'Alembert equation admits a one-parameter family:
\(H(t)=\cosh(\lambda t)\) and \(H(t)=\cos(\lambda t)\) both satisfy the same functional identity,
and \(\lambda\) is not determined. The scalar \(\kappa_H\) fixes this rescaling freedom by pinning
\(\lambda^2=|\kappa_H|\) and selecting the hyperbolic (\(\kappa_H>0\)) versus circular
(\(\kappa_H<0\)) branch.
\end{remark}

\section{Proof of Theorem~\ref{thm:cosh-unique}}\label{sec:proof}
We prove the classification theorem and then obtain the cost-uniqueness corollary as an immediate
consequence via Lemma~\ref{lem:equiv-rp-dalembert}.

\subsection{Regularity bootstrap from the curvature limit}\label{sec:bootstrap}
Although Theorem~\ref{thm:cosh-unique} assumes only continuity, the d'Alembert equation and the
existence of the quadratic curvature \(\kappa_H\) force enough smoothness to justify the ODE
argument.

\begin{lemma}[A central-difference criterion for \(C^2\)]\label{lem:central-diff-C2}
Let \(f:\R\to\R\) be continuous. Fix \(T>0\) and define the central second difference
\[
D_h f(t):=\frac{f(t+h)-2f(t)+f(t-h)}{h^2}\qquad(|t|\le T,\ h\ne 0).
\]
If there is a continuous function \(L:[-T,T]\to\R\) such that
\[
\lim_{h\to 0}\ \sup_{|t|\le T}\ \bigl|D_h f(t)-L(t)\bigr|=0,
\]
then \(f\in C^2([-T,T])\) and \(f''(t)=L(t)\) for all \(|t|\le T\).
\end{lemma}
\begin{proof}
See Appendix~\ref{app:central-diff} for a self-contained proof.
\end{proof}

\begin{lemma}[From d'Alembert + curvature to an ODE]\label{lem:dalembert-curvature-ode}
Let \(H:\R\to\R\) satisfy the d'Alembert equation with \(H(0)=1\). Suppose
\(\kappa_H=\lim_{t\to 0}\frac{2(H(t)-1)}{t^2}\) exists. Then \(H\in C^2(\R)\) and
\[
H''(t)=\kappa_H\,H(t)\qquad\text{for all }t\in\R.
\]
\end{lemma}
\begin{proof}
By Lemma~\ref{lem:dalembert-continuity}, \(H\) is continuous.
Fix \(T>0\). For \(h\ne 0\) and \(|t|\le T\), the d'Alembert equation gives
\[
H(t+h)+H(t-h)=2H(t)H(h).
\]
Rearranging,
\[
\frac{H(t+h)-2H(t)+H(t-h)}{h^2}
=2H(t)\,\frac{H(h)-1}{h^2}.
\]
Let \(q(h):=\frac{2(H(h)-1)}{h^2}\). By assumption, \(q(h)\to\kappa_H\) as \(h\to 0\). Since \(H\)
is continuous on \([-T,T]\), it is bounded there: \(|H(t)|\le M_T\). Hence
\[
\sup_{|t|\le T}\left|\frac{H(t+h)-2H(t)+H(t-h)}{h^2}-\kappa_H H(t)\right|
=\sup_{|t|\le T}\bigl|H(t)\bigr|\cdot \bigl|q(h)-\kappa_H\bigr|
\le M_T\,|q(h)-\kappa_H|\xrightarrow[h\to 0]{}0.
\]
By Lemma~\ref{lem:central-diff-C2} (with \(f=H\) and \(L(t)=\kappa_H H(t)\)), we conclude that
\(H\in C^2([-T,T])\) and \(H''(t)=\kappa_H H(t)\) on \([-T,T]\). Since \(T>0\) was arbitrary, the
conclusion holds for all \(t\in\R\).
\end{proof}

\subsection{From d'Alembert to a linear ODE (classical derivation)}
For completeness, we also record a direct differentiation argument: if \(H\in C^2\), then
d'Alembert implies \(H''(t)=H''(0)H(t)\). This matches Lemma~\ref{lem:dalembert-curvature-ode}
once one notes that \(\kappa_H=H''(0)\) for \(C^2\) functions.

\begin{lemma}[\(C^2\) d'Alembert implies a linear ODE]\label{lem:dalembert-to-ode}
Let \(H\in C^2(\R)\) satisfy \(H(0)=1\) and the d'Alembert equation. Then for all \(t\in\R\),
\[
H''(t)=H''(0)\,H(t).
\]
\end{lemma}
\begin{proof}
Fix \(t\in\R\) and define \(\Phi(u):=H(t+u)+H(t-u)-2H(t)H(u)\). By the d'Alembert equation,
\(\Phi(u)=0\) for all \(u\). Differentiate twice with respect to \(u\).

First note that, by the chain rule,
\[
\Phi'(u)=H'(t+u)-H'(t-u)-2H(t)H'(u),
\]
and differentiating again gives
\[
\Phi''(u)=H''(t+u)+H''(t-u)-2H(t)H''(u).
\]
Since \(\Phi(u)\equiv 0\), we have \(\Phi''(0)=0\). Evaluating at \(u=0\) yields
\[
0=\Phi''(0)=H''(t)+H''(t)-2H(t)H''(0)=2H''(t)-2H(t)H''(0),
\]
so \(H''(t)=H''(0)H(t)\) for all \(t\).
\end{proof}

\subsection{Initial data}
\begin{lemma}[Evenness implies zero first derivative at the origin]\label{lem:even-deriv0}
Let \(H\in C^1(\R)\) be even. Then \(H'(0)=0\).
\end{lemma}
\begin{proof}
For \(h\neq 0\), evenness gives \(H(h)=H(-h)\). Then
\[
\frac{H(h)-H(0)}{h}=-\frac{H(-h)-H(0)}{-h}.
\]
Taking the limit \(h\to 0\) and using differentiability at \(0\) shows \(H'(0)=-H'(0)\), hence
\(H'(0)=0\).
\end{proof}

\begin{lemma}[d'Alembert solutions with \(H(0)=1\) are even]\label{lem:dalembert-even2}
If \(H\) satisfies the d'Alembert equation and \(H(0)=1\), then \(H\) is even.
\end{lemma}
\begin{proof}
This is Lemma~\ref{lem:dalembert-even}.
\end{proof}

\subsection{Uniqueness of the calibrated solution}
\begin{lemma}[ODE zero-uniqueness for positive \(\kappa\)]\label{lem:ode-zero-pos}
Let \(\kappa>0\) and let \(f\in C^2(\R)\) satisfy \(f''(t)=\kappa f(t)\) for all \(t\), with
\(f(0)=0\) and \(f'(0)=0\). Then \(f(t)=0\) for all \(t\).
\end{lemma}
\begin{proof}
Let \(\lambda:=\sqrt{\kappa}\). Define \(g(t):=f'(t)-\lambda f(t)\) and \(h(t):=f'(t)+\lambda f(t)\).
Then \(g,h\in C^1(\R)\) and
\[
g'(t)=f''(t)-\lambda f'(t)=\kappa f(t)-\lambda f'(t)=-\lambda g(t),\qquad
h'(t)=f''(t)+\lambda f'(t)=\kappa f(t)+\lambda f'(t)=\lambda h(t).
\]
Therefore \(\frac{d}{dt}(g(t)\e^{\lambda t})=0\), so \(g(t)\e^{\lambda t}\) is constant. Since
\(g(0)=f'(0)-\lambda f(0)=0\), we get \(g\equiv 0\). Similarly
\(\frac{d}{dt}(h(t)\e^{-\lambda t})=0\) and \(h(0)=f'(0)+\lambda f(0)=0\), so \(h\equiv 0\).
Then \(f'=\tfrac12(g+h)=0\), so \(f\) is constant and \(f(0)=0\) forces \(f\equiv 0\).
\end{proof}

\begin{lemma}[ODE zero-uniqueness for negative \(\kappa\)]\label{lem:ode-zero-neg}
Let \(\kappa<0\) and let \(f\in C^2(\R)\) satisfy \(f''(t)=\kappa f(t)\) for all \(t\), with
\(f(0)=0\) and \(f'(0)=0\). Then \(f(t)=0\) for all \(t\).
\end{lemma}
\begin{proof}
Write \(\kappa=-\mu^2\) with \(\mu:=\sqrt{-\kappa}>0\). Define the energy
\[
E(t):=f'(t)^2+\mu^2 f(t)^2\ge 0.
\]
Then \(E\in C^1(\R)\) and
\[
E'(t)=2f'(t)f''(t)+2\mu^2 f(t)f'(t)=2f'(t)\bigl(f''(t)+\mu^2 f(t)\bigr)=0,
\]
so \(E\) is constant. Since \(E(0)=f'(0)^2+\mu^2 f(0)^2=0\), we have \(E(t)=0\) for all \(t\), hence
\(f'(t)=0\) and \(f(t)=0\) for all \(t\).
\end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:cosh-unique}]
Let \(H\) satisfy the hypotheses, and let \(\kappa_H\) be as in the statement.
By Lemma~\ref{lem:dalembert-curvature-ode}, \(H\in C^2(\R)\) and \(H''=\kappa_H H\).
Also, by Lemma~\ref{lem:dalembert-even2}, \(H\) is even, hence (since \(H\in C^1\))
\(H'(0)=0\) by Lemma~\ref{lem:even-deriv0}.

\paragraph{Case \(\kappa_H=0\).}
Then \(H''=0\), so \(H(t)=at+b\). Evenness forces \(a=0\), and \(H(0)=1\) gives \(b=1\), hence
\(H\equiv 1\).

\paragraph{Case \(\kappa_H>0\).}
Let \(\lambda:=\sqrt{\kappa_H}\) and set \(y(t):=\cosh(\lambda t)\). Then \(y\in C^2(\R)\),
\(y''=\kappa_H y\), \(y(0)=1\), and \(y'(0)=0\). Define \(f:=H-y\). Then \(f\in C^2(\R)\),
\(f''=\kappa_H f\), and \(f(0)=f'(0)=0\). By Lemma~\ref{lem:ode-zero-pos}, \(f\equiv 0\), so
\(H(t)=\cosh(\lambda t)\).

\paragraph{Case \(\kappa_H<0\).}
Let \(\mu:=\sqrt{-\kappa_H}\) and set \(y(t):=\cos(\mu t)\). Then \(y\in C^2(\R)\),
\(y''=\kappa_H y\), \(y(0)=1\), and \(y'(0)=0\). With \(f:=H-y\) as above, we have
\(f''=\kappa_H f\) and \(f(0)=f'(0)=0\). By Lemma~\ref{lem:ode-zero-neg}, \(f\equiv 0\), so
\(H(t)=\cos(\mu t)\).
\end{proof}

\section{Discussion and implications}\label{sec:discussion}

\subsection{Auditability: why uniqueness is a gate, not a preference}
Theorem~\ref{thm:main} should be read as an \emph{audit gate}: it removes an entire class of
``hidden degrees of freedom'' that can otherwise enter through \emph{functional form choice}.
Even if a model has no tunable numerical parameters, it may still be effectively tunable if a key
construction depends on selecting a cost from a large admissible family. Uniqueness theorems
turn a cost from a choice into a consequence: once the hypotheses are fixed and made explicit,
the cost cannot be swapped without visibly breaking an assumption.

In that sense, the result is conceptually analogous to a rigidity theorem. Its value is not that it
produces a closed form (which one might guess), but that it eliminates an implicit dial.

\subsection{A ``certificate-circle'' pattern (optional methodological note)}
Although the present manuscript is self-contained and includes complete proofs, it is often useful
in larger derivation programs to track a \emph{certified surface}: the set of claims that have been
independently audited against a formal checklist.

One practical pattern for doing so is the following:
\begin{itemize}
  \item \textbf{State each checkpoint as a named proposition.} For example, ``canonical reciprocal
  cost uniqueness on \(\Rp\)'' is a single checkpoint statement.
  \item \textbf{Close the loop with a non-vacuity witness.} A checkpoint should not merely say
  ``if \(F\) satisfies hypotheses then \(F=J\)''; it should also exhibit that the intended canonical
  \(J\) does satisfy those hypotheses (Lemma~\ref{lem:J-meets}).
  \item \textbf{Keep dependencies explicit.} Each checkpoint’s hypotheses should be visible in the
  statement, so that later results cannot silently assume extra structure.
\end{itemize}
This pattern is useful whether the independent audit is done by another human, by a second
implementation, or by a proof assistant. The key point is methodological: \emph{make the gate
statements crisp, minimal, and non-vacuous}.

\subsection{Non-circularity: threat model and mitigations}
To clarify what we mean by ``non-circularity'' in this context, it is helpful to name the failure
modes that the present theorem (and its surrounding methodology) is designed to prevent.

\paragraph{Threat 1: tuning by cost swapping.}
Without uniqueness, one may choose a cost post hoc to fit downstream desiderata. Theorem~\ref{thm:main}
prevents this within the stated hypothesis class: any two costs satisfying the same explicit
conditions must coincide.

\paragraph{Threat 2: hiding scale in the functional equation.}
The d'Alembert equation admits rescaled families \(t\mapsto \cosh(\lambda t)\) and
\(t\mapsto \cos(\lambda t)\). The single scalar calibration (the quadratic curvature
\(\kappa_H=\lim_{t\to 0}2(H(t)-1)/t^2\), equivalently \(\kappa(F)\)) removes this freedom by pinning
\(\lambda^2=|\kappa_H|\) and selecting the hyperbolic versus circular branch
(Remark in Section~\ref{sec:roadmap}).

\paragraph{Threat 3: smuggling outcomes through numerics.}
In empirical settings it is easy to ``prove'' agreement by inserting a desired decimal into a
definition and then performing identity checking. The mathematical results in this paper avoid
this failure mode entirely: the statements are symbolic and do not depend on any empirical
numerals. More generally, when numerics are used for illustration, the recommended practice is a
\emph{quarantine principle}: keep numerical evaluation separate from theorem statements and
proofs, and label it as a check rather than a derivation.

\paragraph{Threat 4: hidden assumptions.}
Theorem~\ref{thm:main} makes all assumptions explicit: normalization, the \(\Rp\) composition law,
continuity, and the single scalar calibration \(\kappa(F)\). In particular, the proof does not
smuggle differentiability as a premise: \(C^2\) regularity is \emph{derived} from continuity plus the
curvature limit (Lemma~\ref{lem:dalembert-curvature-ode}), after which the ODE argument becomes
legitimate.

\subsection{Near-minimality of the hypotheses}\label{sec:minimality}
Theorem~\ref{thm:main} is intentionally small: each hypothesis plays a distinct role. The following
propositions show what breaks if one removes individual assumptions.

\begin{proposition}[Reciprocity is forced by normalization + the \(\Rp\) law]\label{prop:reciprocity-forced}
Let \(F:\Rp\to\R\) satisfy Definition~\ref{def:rp-law} and \(F(1)=0\). Then \(F(x)=F(x^{-1})\) for all
\(x>0\).
\end{proposition}
\begin{proof}
Plug \(x=1\) into Definition~\ref{def:rp-law}:
\[
F(y)+F(1/y)=2F(1)F(y)+2F(1)+2F(y)=2F(y),
\]
so \(F(1/y)=F(y)\) for all \(y>0\).
\end{proof}

\begin{proposition}[Without calibration, there is a one-parameter family]\label{prop:no-calibration-family}
For any \(\lambda>0\), define
\[
F_\lambda(x):=\cosh(\lambda\log x)-1\qquad(x>0).
\]
Then \(F_\lambda\) is continuous on \(\Rp\), satisfies \(F_\lambda(1)=0\), satisfies the \(\Rp\)
composition law (Definition~\ref{def:rp-law}), and has \(\kappa(F_\lambda)=\lambda^2\).
In particular, if one drops the unit calibration \(\kappa(F)=1\), the scale \(\lambda\) remains
undetermined.
\end{proposition}
\begin{proof}
Continuity and \(F_\lambda(1)=0\) are immediate.
Let \(H_\lambda(t):=F_\lambda(\e^t)+1=\cosh(\lambda t)\). By Lemma~\ref{lem:cosh-dalembert},
\(\cosh\) satisfies d'Alembert, hence so does \(H_\lambda\) (with \(t\mapsto \lambda t\)). By
Lemma~\ref{lem:equiv-rp-dalembert}, \(F_\lambda\) satisfies the \(\Rp\) composition law.

Finally, using \(\cosh(\lambda t)-1\sim \lambda^2 t^2/2\) as \(t\to 0\),
\[
\kappa(F_\lambda)=\lim_{t\to 0}\frac{2(\cosh(\lambda t)-1)}{t^2}=\lambda^2.
\]
\end{proof}

\begin{proposition}[Without the \(\Rp\) composition law, calibration does not force \(J\)]\label{prop:no-law-counterexample}
Define \(F_{\mathrm{quad}}(x):=\tfrac12(\log x)^2\) on \(\Rp\). Then \(F_{\mathrm{quad}}\) is
continuous, satisfies \(F_{\mathrm{quad}}(1)=0\), and has \(\kappa(F_{\mathrm{quad}})=1\), but it does
\emph{not} satisfy the \(\Rp\) composition law.
\end{proposition}
\begin{proof}
Continuity and \(F_{\mathrm{quad}}(1)=0\) are immediate. Also
\(
F_{\mathrm{quad}}(\e^t)=t^2/2
\),
so \(\kappa(F_{\mathrm{quad}})=\lim_{t\to 0}2(t^2/2)/t^2=1\).
Define \(H(t):=F_{\mathrm{quad}}(\e^t)+1=1+t^2/2\). Then for \(t,u\in\R\),
\[
H(t+u)+H(t-u)=2+\frac{(t+u)^2+(t-u)^2}{2}=2+t^2+u^2,
\]
while
\[
2H(t)H(u)=2\left(1+\frac{t^2}{2}\right)\left(1+\frac{u^2}{2}\right)
=2+t^2+u^2+\frac{t^2u^2}{2}.
\]
These differ when \(tu\ne 0\), so \(H\) fails the d'Alembert equation, hence \(F_{\mathrm{quad}}\)
fails the \(\Rp\) law by Lemma~\ref{lem:equiv-rp-dalembert}.
\end{proof}

\begin{proposition}[Without regularity, pathological solutions exist]\label{prop:pathological}
There exist functions \(F:\Rp\to\R\) satisfying \(F(1)=0\) and the \(\Rp\) composition law that are
not measurable (hence not continuous). In particular, some regularity hypothesis is necessary to
exclude non-physical ``Hamel-basis'' solutions.
\end{proposition}
\begin{proof}
It is a standard consequence of the existence of a Hamel basis of \(\R\) over \(\Q\) that there
exists an additive function \(a:\R\to\R\) (i.e., \(a(t+u)=a(t)+a(u)\)) that is not continuous and not
measurable.
Define \(H(t):=\cosh(a(t))\). Then \(H\) is not measurable (as a composition of a non-measurable
additive function with a continuous non-constant function). Moreover, using the additivity of \(a\)
and the identity \(\cosh(x+y)+\cosh(x-y)=2\cosh(x)\cosh(y)\),
\[
H(t+u)+H(t-u)
=\cosh(a(t)+a(u))+\cosh(a(t)-a(u))
=2\cosh(a(t))\cosh(a(u))
=2H(t)H(u).
\]
Thus \(H\) satisfies d'Alembert and \(H(0)=\cosh(a(0))=\cosh(0)=1\).
Now define \(F(x):=H(\log x)-1\) on \(\Rp\). Then \(F(1)=0\) and, by
Lemma~\ref{lem:equiv-rp-dalembert}, \(F\) satisfies the \(\Rp\) composition law. Since \(H\) is not
measurable, neither is \(F\).
\end{proof}

\subsection{Relation to Recognition Science (context, not required)}
In Recognition Science, costs on multiplicative ratios arise as an interface between composition
rules and measurement: ratios compose multiplicatively, while many structural constraints become
additive in log-coordinates. In that setting, d'Alembert-type identities arise as composition laws
for log-lifted quantities, and reciprocity symmetry encodes invariance under inversion of a ratio.
The present paper isolates the purely mathematical core of that story: once the composition law
and calibration are fixed, the cost is forced to be \(J(x)=\tfrac12(x+x^{-1})-1\).

\subsubsection*{A provenance lemma (how the \(\Rp\) law can arise)}
Theorem~\ref{thm:main} treats the \(\Rp\) composition law and calibration as explicit hypotheses.
To connect this to recognition/ledger-style modeling, we record one simple provenance result: a
very common ``multiplicative weight'' postulate forces the \(\Rp\) law, and continuity reduces the
remaining freedom to the single scale parameter \(\lambda\).

\begin{proposition}[From multiplicative weights to the \(\Rp\) composition law]\label{prop:rs-provenance}
Assume there is a function \(W:\Rp\to(0,\infty)\) satisfying the multiplicative (ledger) rule
\[
W(xy)=W(x)W(y)\qquad(x,y>0).
\]
Define \(F_W:\Rp\to\R\) by
\[
F_W(x):=\frac{W(x)+W(x)^{-1}}{2}-1.
\]
Then \(F_W(1)=0\), \(F_W(x)=F_W(x^{-1})\), and \(F_W\) satisfies the \(\Rp\) composition law
(Definition~\ref{def:rp-law}). If, in addition, \(W\) is continuous, then there exists \(\lambda\in\R\)
with \(W(x)=x^\lambda\) for all \(x>0\), hence
\[
F_W(x)=\cosh(\lambda\log x)-1.
\]
\end{proposition}
\begin{proof}
First, \(W(1)=W(1\cdot 1)=W(1)^2\) and \(W(1)>0\) force \(W(1)=1\), so \(F_W(1)=\tfrac12(1+1)-1=0\).
Also,
\[
W(x)W(x^{-1})=W(xx^{-1})=W(1)=1,
\]
so \(W(x^{-1})=W(x)^{-1}\) and hence \(F_W(x)=F_W(x^{-1})\).

Define \(H(t):=F_W(\e^t)+1=\tfrac12(W(\e^t)+W(\e^t)^{-1})\). Let \(t,u\in\R\). By multiplicativity,
\(W(\e^{t+u})=W(\e^t)W(\e^u)\) and \(W(\e^{t-u})=W(\e^t)W(\e^u)^{-1}\). Therefore
\begin{align*}
H(t+u)+H(t-u)
&=\frac{W(\e^{t+u})+W(\e^{t+u})^{-1}+W(\e^{t-u})+W(\e^{t-u})^{-1}}{2}\\
&=\frac{(W(\e^t)+W(\e^t)^{-1})(W(\e^u)+W(\e^u)^{-1})}{2}
=2H(t)H(u),
\end{align*}
so \(H\) satisfies d'Alembert. By Lemma~\ref{lem:equiv-rp-dalembert}, \(F_W\) satisfies the \(\Rp\)
composition law.

Finally, if \(W\) is continuous, define \(w(t):=\log W(\e^t)\). Then \(w:\R\to\R\) is additive:
using \(W(\e^{t+u})=W(\e^t)W(\e^u)\), we get \(w(t+u)=w(t)+w(u)\). Continuity of \(W\) implies
continuity of \(w\), hence \(w(t)=\lambda t\) for some \(\lambda\in\R\). Therefore
\(
W(\e^t)=\e^{\lambda t}
\),
i.e. \(W(x)=x^\lambda\) for \(x>0\), and
\(
F_W(\e^t)=\cosh(\lambda t)-1
\),
equivalently \(F_W(x)=\cosh(\lambda\log x)-1\).
\end{proof}

\begin{remark}[Scope]
Proposition~\ref{prop:rs-provenance} is not claimed as a derivation from the full Recognition
Science axiomatics; it is a minimal \emph{modeling bridge} showing that once one postulates a
multiplicative ``ledger weight'' and then takes the simplest symmetric scalar observable of that
weight, the d'Alembert structure appears automatically, with a single residual scale \(\lambda\)
removed by calibration.
\end{remark}

\subsection{Significance and cascading effects}\label{sec:significance}
This paper’s results are small in surface area but large in methodological consequence: they turn a
cost from a \emph{choice} into a \emph{forced output} of explicit assumptions.

\subsubsection*{What the uniqueness theorem prevents}
\begin{itemize}
  \item \textbf{Post hoc cost swapping.} If a downstream construction relies only on the hypotheses
  of Corollary~\ref{cor:cost-unique} (normalization, the \(\Rp\) composition law, continuity, and the
  single scalar calibration \(\kappa(F)\)), then the cost is no longer a dial: there is
  no alternative \(F\) within that class to ``switch to'' in order to fit outcomes.
  \item \textbf{Hidden functional parameters.} Without calibration one has a rescaling freedom
  \(t\mapsto \cosh(\lambda t)\) in log-coordinates, which corresponds to a one-parameter family of
  costs on \(\Rp\) (and similarly a \(\cos(\lambda t)\) family). The single scalar calibration
  \(\kappa(F)=\lim_{t\to 0}2F(\e^t)/t^2\) removes this implicit parameter and pins the unique cost
  (Remark in Section~\ref{sec:roadmap}).
\end{itemize}

\subsubsection*{What it enables downstream (minimal and defensible)}
\begin{itemize}
  \item \textbf{A canonical log-geometry.} The identity \(J(\e^t)=\cosh(t)-1\) provides a fixed,
  convex, even ``energy profile'' in log-coordinates. Near \(t=0\), \(\cosh(t)-1\sim t^2/2\), so the
  unique cost has a canonical quadratic approximation around the identity ratio \(x=1\), which is
  often the regime relevant for perturbative reasoning.
  \item \textbf{A stable interface for larger derivations.} In any larger framework where a ratio
  cost appears only through the assumptions of Corollary~\ref{cor:cost-unique}, one may reason at
  the level of those assumptions and then invoke uniqueness to conclude that the resulting
  identities are in fact identities for the closed form \(J\). This reduces the risk that later
  steps inadvertently depend on an untracked choice of functional form.
\end{itemize}

\subsubsection*{What it does not settle}
Theorem~\ref{thm:main} is a mathematical rigidity result. It does \emph{not} by itself:
\begin{itemize}
  \item justify that a particular physical measurement process must satisfy the d'Alembert
  identity and calibration (those are modeling inputs in an application);
  \item derive unrelated structural claims (e.g., discrete closure periods, preferred dimensions,
  or specific physical constants), which belong to separate arguments and are outside the scope of
  this paper;
  \item claim that no other cost could be appropriate under different assumptions. Rather, it
  states: \emph{within this explicit hypothesis class, the cost is uniquely \(J\).}
\end{itemize}

\subsection{Reproducibility}\label{sec:reproducibility}
This paper is designed to be reproducible without external dependencies beyond a standard
\LaTeX{} installation.

\paragraph{Document build.}
The manuscript uses the \texttt{revtex4-2} class and standard math packages. A typical build is:
\begin{itemize}
  \item \texttt{latexmk -pdf canonical\_cost\_uniqueness.tex}
\end{itemize}
No external data files are required.

\paragraph{Statement map (what to check).}
Readers who wish to audit the results can proceed directly by checking the following chain:
\begin{itemize}
  \item \textbf{Definitions and identities:} Definitions~\ref{def:recip-norm}, \ref{def:cosh},
  \ref{def:dalembert}; Lemmas~\ref{lem:J-squared}, \ref{lem:J-log-cosh},
  \ref{lem:cosh-dalembert}.
  \item \textbf{Main statements:} Theorem~\ref{thm:cosh-unique} and
  Corollary~\ref{cor:cost-unique} (Section~\ref{sec:results}), which imply
  Theorem~\ref{thm:main}.
  \item \textbf{Core proof steps:} the central-difference lemma (Lemma~\ref{lem:central-diff-C2}),
  the d'Alembert-to-ODE bootstrap (Lemma~\ref{lem:dalembert-curvature-ode}),
  evenness and \(H'(0)=0\) (Lemmas~\ref{lem:dalembert-even2} and \ref{lem:even-deriv0}),
  and ODE zero-uniqueness (Lemmas~\ref{lem:ode-zero-pos} and \ref{lem:ode-zero-neg}),
  culminating in the classification Theorem~\ref{thm:cosh-unique}.
\end{itemize}

\paragraph{Optional supplementary audit.}
An optional, independent audit of the named statements is provided by the supplementary artifact
referenced in the abstract. The paper remains the primary source of definitions, hypotheses, and
proofs; the artifact exists only to mirror the printed statements for readers who prefer a
machine-check.

\subsection{Figures and tables (recommended for exposition)}\label{sec:figtab}
This section lists high-signal figures and tables that (i) communicate the structure of the result
quickly and (ii) make common misunderstandings unlikely. The manuscript can be submitted without
these aids; they are included to improve readability for a broad audience.

\subsubsection*{Figures}
\paragraph{Figure 1: the canonical cost on a log scale.}
Plot \(J(x)\) versus \(x\) with a log-scaled horizontal axis to emphasize reciprocity symmetry
(\(x\leftrightarrow x^{-1}\)) and the unique minimum at \(x=1\).

\begin{figure}
\centering
\IfFileExists{figures/j_vs_x.pdf}{
  \includegraphics[width=0.95\columnwidth]{figures/j_vs_x.pdf}
}{
  \fbox{\parbox{0.95\columnwidth}{
    \vspace{1.4in}\centering
    Placeholder for \texttt{figures/j\_vs\_x.pdf}\\
    Plot \(J(x)=\tfrac12(x+x^{-1})-1\) vs.\ \(x\) on a log-\(x\) axis.\vspace{1.4in}
  }}
}
\caption{The canonical reciprocal cost \(J(x)\) on \(\Rp\). On a log-\(x\) axis the graph is
visibly symmetric under \(x\mapsto x^{-1}\) and has a unique minimum at \(x=1\).}
\label{fig:j-vs-x}
\end{figure}

\paragraph{Figure 2: log--cosh geometry and the quadratic approximation.}
Plot \(J(\e^t)=\cosh(t)-1\) together with its small-\(t\) approximation \(t^2/2\) to show how the
unique cost behaves near the identity ratio.

\begin{figure}
\centering
\IfFileExists{figures/jlog_vs_quad.pdf}{
  \includegraphics[width=0.95\columnwidth]{figures/jlog_vs_quad.pdf}
}{
  \fbox{\parbox{0.95\columnwidth}{
    \vspace{1.4in}\centering
    Placeholder for \texttt{figures/jlog\_vs\_quad.pdf}\\
    Plot \(\cosh(t)-1\) and \(t^2/2\) near \(t=0\).\vspace{1.4in}
  }}
}
\caption{Log-coordinates: \(J(\e^t)=\cosh(t)-1\). The approximation \(\cosh(t)-1\sim t^2/2\) as
\(t\to 0\) makes explicit the canonical quadratic behavior near \(x=1\).}
\label{fig:jlog-quad}
\end{figure}

\paragraph{Figure 3: dependency graph of the argument.}
A small diagram clarifies that the proof is a short pipeline:
d'Alembert \(+\) curvature \(\Rightarrow\) ODE \(\Rightarrow\) initial data \(\Rightarrow\) uniqueness
\(\Rightarrow\) cost rigidity.

\begin{figure}
\centering
\IfFileExists{figures/proof_dependency_graph.pdf}{
  \includegraphics[width=0.95\columnwidth]{figures/proof_dependency_graph.pdf}
}{
  \fbox{\parbox{0.95\columnwidth}{
    \vspace{1.4in}\centering
    Placeholder for \texttt{figures/proof\_dependency\_graph.pdf}\\
    Diagram: d'Alembert \(\Rightarrow\) ODE \(\Rightarrow\) uniqueness \(\Rightarrow\) \(F=J\).\vspace{1.4in}
  }}
}
\caption{Logical dependency graph for the main proof. This figure is a reader aid; every step is
proved in Section~\ref{sec:proof}.}
\label{fig:dep-graph}
\end{figure}

\subsubsection*{Tables}
\paragraph{Table 1: hypothesis bundle and roles.}
\begin{table}
\centering
\begin{tabular}{@{}p{0.28\columnwidth}p{0.62\columnwidth}@{}}
\toprule
Hypothesis & Role in the proof \\
\midrule
Normalization \(F(1)=0\) & Sets the reference point, giving \(H(0)=1\). Together with the \(\Rp\) law it also implies reciprocity \(F(x)=F(x^{-1})\) by plugging \(x=1\) into Definition~\ref{def:rp-law}. \\
\(\Rp\) composition law & Equivalent to the d'Alembert equation for \(H(t)=F(\e^t)+1\) (Lemma~\ref{lem:equiv-rp-dalembert}), which drives the rigidity. \\
Continuity of \(F\) & Ensures continuity of \(H\) and allows a \(C^2\) bootstrap from the curvature limit (Lemma~\ref{lem:dalembert-curvature-ode}). \\
Quadratic calibration \(\kappa(F)=1\) & Fixes the rescaling freedom \(t\mapsto \cosh(\lambda t)\) and excludes the \(\cos(\lambda t)\) branch, pinning the unique solution \(H=\cosh(t)\). \\
\bottomrule
\end{tabular}
\caption{Hypotheses of Theorem~\ref{thm:main} and why each is needed.}
\label{tab:hypotheses}
\end{table}

\paragraph{Table 2: nearby alternative costs and what they fail.}
\begin{table}
\centering
\begin{tabular}{@{}p{0.48\columnwidth}p{0.42\columnwidth}@{}}
\toprule
Candidate \(F(x)\) on \(\Rp\) & Status relative to Theorem~\ref{thm:main} \\
\midrule
\(J(x)=\tfrac12(x+x^{-1})-1\) & Satisfies all hypotheses (Lemma~\ref{lem:J-meets}). \\
\(\cosh(\lambda\log x)-1\) (\(\lambda>0\)) & Satisfies normalization, the \(\Rp\) composition law, and continuity, but has \(\kappa(F)=\lambda^2\); it matches Theorem~\ref{thm:main} only when \(\lambda=1\). \\
\((\log x)^2/2\) & Reciprocal and normalized, smooth, but its log-lift \(H(t)=1+t^2/2\) fails the d'Alembert equation (it introduces a \(t^2u^2\) term). \\
\(|\log x|\) & Reciprocal and normalized, but the calibration \(\kappa(F)\) does not exist (it diverges), so it is excluded by Definition~\ref{def:calibration}. \\
\(\tfrac12(x-1)^2\) & Normalized but not reciprocal (fails \(F(x)=F(x^{-1})\)). \\
\bottomrule
\end{tabular}
\caption{Examples showing that the hypotheses are not vacuous and that common alternatives are
excluded for concrete reasons.}
\label{tab:alternatives}
\end{table}

\paragraph{Table 3: scope and status.}
\begin{table}
\centering
\begin{tabular}{@{}p{0.32\columnwidth}p{0.58\columnwidth}@{}}
\toprule
Item & Status in this manuscript \\
\midrule
Theorems and lemmas & Fully stated and proved in the text (Sections~\ref{sec:prelim}--\ref{sec:proof}). \\
Recognition Science context & Motivational only; not required for any proof. \\
Supplementary audit artifact & Optional external mirror of the printed statements; not required to validate results. \\
\bottomrule
\end{tabular}
\caption{Scope and status of the components of the paper.}
\label{tab:scope}
\end{table}

\subsection{Supplementary independent audit}
For readers who want an additional layer of verification, a supplementary machine-checked audit
of the named statements in this paper is available in the artifact referenced in the abstract. This
audit is \emph{optional}: every proof needed to validate the results appears in the present text.

\appendix

\section{A central-difference lemma}\label{app:central-diff}
This appendix proves Lemma~\ref{lem:central-diff-C2}, which turns uniform convergence of central
second differences into classical \(C^2\) regularity.

\begin{proof}[Proof of Lemma~\ref{lem:central-diff-C2}]
Fix \(T>0\) and assume \(D_h f\to L\) uniformly on \([-T,T]\), with \(L\) continuous.

\paragraph{Step 1: reduce to the case \(D_h g\to 0\).}
Extend \(L\) to a continuous function \(\widetilde L:\R\to\R\) by constant extension:
\(\widetilde L(t)=L(-T)\) for \(t<-T\), \(\widetilde L(t)=L(t)\) for \(|t|\le T\), and
\(\widetilde L(t)=L(T)\) for \(t>T\). Define
\[
F(t):=\int_0^t\int_0^u \widetilde L(s)\,ds\,du \qquad (t\in\R).
\]
Then \(F\in C^2(\R)\) and \(F''=\widetilde L\). In particular, \(F''(t)=L(t)\) for \(|t|\le T\).

\begin{lemma}[Central second differences as a weighted average]\label{lem:triangular-kernel}
If \(G\in C^2(\R)\), then for every \(t\in\R\) and \(h\ne 0\),
\[
\frac{G(t+h)-2G(t)+G(t-h)}{h^2}
=\int_{-1}^{1}(1-|r|)\,G''(t+r h)\,dr.
\]
\end{lemma}
\begin{proof}
Fix \(t\) and \(h>0\) (the formula is symmetric in \(h\)). By the fundamental theorem of calculus,
\[
G(t+h)-G(t)=\int_0^{h} G'(t+u)\,du,\qquad
G(t)-G(t-h)=\int_0^{h} G'(t-u)\,du.
\]
Subtracting yields
\[
G(t+h)-2G(t)+G(t-h)=\int_0^{h}\bigl(G'(t+u)-G'(t-u)\bigr)\,du.
\]
Again by the fundamental theorem of calculus,
\[
G'(t+u)-G'(t-u)=\int_{-u}^{u} G''(t+v)\,dv.
\]
Therefore
\[
G(t+h)-2G(t)+G(t-h)=\int_0^{h}\int_{-u}^{u} G''(t+v)\,dv\,du.
\]
Swap the order of integration: the region \(\{(u,v):0\le u\le h,\ |v|\le u\}\) is the triangle
\(\{|v|\le u\le h\}\), so
\[
\int_0^{h}\int_{-u}^{u} G''(t+v)\,dv\,du
=\int_{-h}^{h}\left(\int_{|v|}^{h}du\right)G''(t+v)\,dv
=\int_{-h}^{h}(h-|v|)\,G''(t+v)\,dv.
\]
Divide by \(h^2\) and substitute \(v=rh\) to obtain the claimed formula.
\end{proof}

By Lemma~\ref{lem:triangular-kernel} with \(G=F\) and \(F''=\widetilde L\),
\[
D_h F(t)=\int_{-1}^{1}(1-|r|)\,\widetilde L(t+r h)\,dr.
\]
Since \(\widetilde L\) is uniformly continuous on the compact interval \([-T-1,T+1]\), the right-hand side
converges uniformly to \(\widetilde L(t)=L(t)\) as \(h\to 0\), for \(|t|\le T\). Thus \(D_h F\to L\)
uniformly on \([-T,T]\).

Now define \(g:=f-F\). Then \(g\) is continuous and
\[
D_h g(t)=D_h f(t)-D_h F(t)\xrightarrow[h\to 0]{}0
\]
uniformly on \([-T,T]\).

\paragraph{Step 2: if \(D_h g\to 0\) uniformly, then \(g\) is affine.}
We prove that \(g\) is affine on \([-T,T]\). Let \(\ell\) be the affine interpolant of \(g\) at the
endpoints:
\[
\ell(t):=\frac{T-t}{2T}\,g(-T)+\frac{T+t}{2T}\,g(T).
\]
Set \(u:=g-\ell\). Then \(u\) is continuous, \(u(-T)=u(T)=0\), and \(D_h u=D_h g\to 0\) uniformly.

Fix \(\varepsilon>0\). Choose \(n\in\mathbb{N}\) large enough that \(h:=2T/n\) satisfies
\(\sup_{|t|\le T}\,|D_h u(t)|\le\varepsilon\). Define grid points \(t_k:=-T+kh\) for \(k=0,1,\dots,n\)
and set \(a_k:=u(t_k)\). Then \(a_0=a_n=0\) and for each \(k=1,\dots,n-1\),
\[
|a_{k+1}-2a_k+a_{k-1}|
=|u(t_k+h)-2u(t_k)+u(t_k-h)|
\le \varepsilon h^2.
\]

Define \(b_k:=\frac{\varepsilon h^2}{2}\,k(n-k)\). A direct calculation shows
\[
b_{k+1}-2b_k+b_{k-1}=-\varepsilon h^2.
\]
Let \(c_k:=a_k-b_k\). Using the lower bound
\(
a_{k+1}-2a_k+a_{k-1}\ge-\varepsilon h^2
\),
we get
\[
c_{k+1}-2c_k+c_{k-1}
=(a_{k+1}-2a_k+a_{k-1})-(b_{k+1}-2b_k+b_{k-1})\ge 0.
\]
Thus \(\{c_k\}\) is discrete convex. With \(c_0=c_n=0\), discrete convexity implies \(c_k\le 0\) for
all \(k\), hence \(a_k\le b_k\). Applying the same argument to \(-a_k\) gives \(-a_k\le b_k\), so
\[
|a_k|\le b_k\le \frac{\varepsilon h^2}{2}\cdot \frac{n^2}{4}=\frac{\varepsilon T^2}{2}
\qquad(k=0,1,\dots,n).
\]
Therefore \(\sup_{k}|u(t_k)|\le \varepsilon T^2/2\).

Since \(u\) is uniformly continuous on \([-T,T]\), pick \(n\) larger if needed so that
\(|t-s|\le h\Rightarrow |u(t)-u(s)|\le\varepsilon\). For any \(t\in[-T,T]\), choose a grid point
\(t_k\) with \(|t-t_k|\le h\). Then
\[
|u(t)|\le |u(t_k)|+|u(t)-u(t_k)|\le \frac{\varepsilon T^2}{2}+\varepsilon.
\]
Because \(\varepsilon>0\) was arbitrary, \(u(t)=0\) for all \(t\in[-T,T]\), hence \(g=\ell\) is affine.

\paragraph{Step 3: conclude \(f\in C^2\) and \(f''=L\).}
We have shown \(f=F+g\) on \([-T,T]\), where \(F\in C^2\) with \(F''=L\) on \([-T,T]\) and \(g\) is
affine (thus \(g''=0\)). Therefore \(f\in C^2([-T,T])\) and \(f''=L\) on \([-T,T]\).
\end{proof}

\section{Formal statement of the uniqueness gate}\label{app:formal}
This appendix records a compact, fully explicit statement of the mathematical gate proved in the
main text.

\begin{definition}[Canonical cost and log-lift]\label{def:app-JH}
Define \(J:\Rp\to\R\) and the log-lift of a cost \(F:\Rp\to\R\) by
\[
J(x):=\frac{x+x^{-1}}{2}-1,\qquad
H_F(t):=F(\e^t)+1.
\]
\end{definition}

\begin{definition}[Calibrated d'Alembert class]\label{def:app-class}
We say that a cost \(F:\Rp\to\R\) lies in the \emph{calibrated d'Alembert class} if:
\begin{enumerate}
  \item \(F(1)=0\) (normalization);
  \item \(F\) satisfies the \(\Rp\) composition law (Definition~\ref{def:rp-law});
  \item \(F\) is continuous on \(\Rp\);
  \item \(\kappa(F)=1\) (Definition~\ref{def:calibration}).
\end{enumerate}
By Proposition~\ref{prop:reciprocity-forced}, reciprocity \(F(x)=F(x^{-1})\) is then automatic.
\end{definition}

\begin{theorem}[Uniqueness on \(\Rp\) within the calibrated d'Alembert class]\label{thm:app-unique}
If \(F:\Rp\to\R\) lies in the calibrated d'Alembert class, then \(F(x)=J(x)\) for all \(x>0\).
\end{theorem}
\begin{proof}
This is exactly Corollary~\ref{cor:cost-unique}.
\end{proof}

\section{Classical functional-equation perspective (optional)}\label{app:classical}
The d'Alembert equation has a long history and admits many equivalent characterizations under
regularity assumptions. The proof in this paper does not rely on external classification theorems,
but some readers may appreciate the surrounding classical context.

\subsection{Classification at a high level}
In broad terms, the d'Alembert equation is a cosine/hyperbolic-cosine addition law. Under mild
regularity (e.g., continuity plus boundedness on a nontrivial interval, or measurability), classical
results show that solutions \(H\) are restricted to familiar families (cosine-type or cosh-type)
parameterized by a scale.

In particular, one may view the single scalar calibration (here expressed as the quadratic
curvature \(\kappa_H=\lim_{t\to 0}2(H(t)-1)/t^2\), or \(\kappa(F)\) on \(\Rp\)) as the device that
eliminates the scale parameter and pins the unique branch.

\subsection{References}
Standard references on functional equations and d'Alembert-type identities include:
\begin{itemize}
  \item J.~Acz\'el, \emph{Lectures on Functional Equations and Their Applications}, Academic Press (1966).
  \item M.~Kuczma, \emph{An Introduction to the Theory of Functional Equations and Inequalities},
  2nd ed., Birkh\"auser (2009).
\end{itemize}

\section{Robustness: stability under bounded defect}\label{app:robustness}
Real data and numerical pipelines rarely satisfy a functional identity exactly. The theorem below
gives one rigorous (local) stability statement: if d'Alembert holds up to a uniform defect on a
compact set and the function is sufficiently smooth, then the solution is close to the appropriate
hyperbolic cosine profile.

\begin{definition}[d'Alembert defect]\label{def:defect}
For \(H:\R\to\R\), define the d'Alembert defect
\[
\Delta_H(t,u):=H(t+u)+H(t-u)-2H(t)H(u).
\]
\end{definition}

\begin{theorem}[A quantitative stability bound, hyperbolic branch]\label{thm:stability}
Fix \(T>0\). Let \(H\in C^3([-T,T])\) be even with \(H(0)=1\), and set \(a:=H''(0)\).
Assume \(a>0\). Let
\[
\varepsilon:=\sup_{|t|\le T,\ |u|\le T}\ |\Delta_H(t,u)|,\qquad
B:=\sup_{|t|\le T}\ |H(t)|,\qquad
K:=\sup_{|t|\le T}\ |H^{(3)}(t)|.
\]
Then for every \(h\) with \(0<h\le T\) and every \(t\) with \(|t|\le T-h\),
\[
\bigl|H(t)-\cosh(\sqrt{a}\,t)\bigr|
\le
\frac{\delta(h)}{a}\,\bigl(\cosh(\sqrt{a}\,|t|)-1\bigr),
\]
where
\[
\delta(h):=\frac{\varepsilon}{h^2}+\frac{(1+B)K}{3}\,h.
\]
\end{theorem}
\begin{proof}
Fix \(0<h\le T\) and \(|t|\le T-h\).

\paragraph{Step 1: control the central-difference remainder with bounded third derivative.}
We claim
\begin{equation}\label{eq:taylor1}
\bigl|H(t+h)+H(t-h)-2H(t)-h^2H''(t)\bigr|\le \frac{K}{3}\,h^3.
\end{equation}
To see this, use the integral form of Taylor's theorem:
\[
H(t+h)=H(t)+hH'(t)+\frac{h^2}{2}H''(t)+\int_0^h\frac{(h-s)^2}{2}\,H^{(3)}(t+s)\,ds,
\]
\[
H(t-h)=H(t)-hH'(t)+\frac{h^2}{2}H''(t)-\int_0^h\frac{(h-s)^2}{2}\,H^{(3)}(t-s)\,ds.
\]
Adding and bounding \(|H^{(3)}|\le K\) yields \eqref{eq:taylor1}.

Similarly, since \(H\) is even, \(H'(0)=0\), and the same integral form at \(0\) gives
\begin{equation}\label{eq:taylor2}
\bigl|H(h)-1-\tfrac{a}{2}h^2\bigr|\le \frac{K}{6}\,h^3.
\end{equation}

Now write the defect identity (Definition~\ref{def:defect}) at \((t,h)\) as
\[
H(t+h)+H(t-h)=2H(t)H(h)+\Delta_H(t,h).
\]
Subtract \(2H(t)+a h^2 H(t)\) from both sides and regroup:
\begin{align*}
h^2\bigl(H''(t)-aH(t)\bigr)
&=\bigl(H(t+h)+H(t-h)-2H(t)-h^2H''(t)\bigr)\\
&\quad+\Delta_H(t,h)
+2H(t)\bigl(H(h)-1-\tfrac{a}{2}h^2\bigr).
\end{align*}
Taking absolute values and using \eqref{eq:taylor1}, \eqref{eq:taylor2}, \(|H(t)|\le B\), and
\(|\Delta_H(t,h)|\le\varepsilon\), we obtain
\[
h^2|H''(t)-aH(t)|
\le \frac{K}{3}h^3+\varepsilon+2B\cdot\frac{K}{6}h^3
\le \varepsilon+\frac{(1+B)K}{3}h^3.
\]
Dividing by \(h^2\) yields the uniform bound
\begin{equation}\label{eq:resid}
|H''(t)-aH(t)|\le \delta(h)
\qquad(|t|\le T-h).
\end{equation}

Let \(y(t):=\cosh(\sqrt{a}\,t)\), so \(y''=ay\), \(y(0)=1\), and (since \(H\) is even) \(H'(0)=0=y'(0)\).
Define \(e(t):=H(t)-y(t)\). Then \(e\in C^2([-T+h,T-h])\), \(e(0)=e'(0)=0\), and
\[
e''(t)-a e(t)=H''(t)-aH(t),
\]
so by \eqref{eq:resid}, \(|e''(t)-a e(t)|\le\delta(h)\) for \(|t|\le T-h\).
For \(t\in[0,T-h]\), the variation-of-constants formula for \(e''=ae+r\) with zero initial data gives
\[
e(t)=\int_0^t \frac{1}{\sqrt{a}}\sinh(\sqrt{a}(t-s))\,r(s)\,ds,
\]
where \(r(s):=e''(s)-ae(s)\). Hence
\[
|e(t)|
\le \delta(h)\int_0^t \frac{1}{\sqrt{a}}\sinh(\sqrt{a}(t-s))\,ds
=\frac{\delta(h)}{a}\bigl(\cosh(\sqrt{a}\,t)-1\bigr).
\]
By evenness of \(e\) (difference of even functions), this bound holds for negative \(t\) as well, yielding
the claimed inequality for all \(|t|\le T-h\).
\end{proof}

\begin{remark}[Interpretation]
The bound trades exact functional identity for a quantified defect \(\varepsilon\) and a smoothness
envelope \(K\). The free parameter \(h\) allows balancing the terms \(\varepsilon/h^2\) and
\(\frac{(1+B)K}{3}h\); choosing \(h\asymp (\varepsilon/K)^{1/3}\) gives a typical
error scaling \(O(\varepsilon^{1/3})\) on compact sets.
\end{remark}

\begin{corollary}[Stability transferred back to \(\Rp\)]\label{cor:stability-rp}
In the setting of Theorem~\ref{thm:stability}, define \(F(x):=H(\log x)-1\) on \(\Rp\). Then for
all \(x\in(\e^{-(T-h)},\e^{T-h})\),
\[
\left|F(x)-\bigl(\cosh(\sqrt{a}\,\log x)-1\bigr)\right|
\le
\frac{\delta(h)}{a}\Bigl(\cosh(\sqrt{a}\,|\log x|)-1\Bigr).
\]
In particular, if \(a\approx 1\) and \(\delta(h)\) is small, then \(F\) is uniformly close to the
canonical cost \(J(x)=\cosh(\log x)-1\) on compact subintervals of \(\Rp\).
\end{corollary}
\begin{proof}
Apply Theorem~\ref{thm:stability} with \(t=\log x\), noting that \(F(x)=H(t)-1\).
\end{proof}

\section{Reader audit checklist}\label{app:checklist}
This appendix provides a ``walk the proof'' checklist for readers who want to verify the argument
quickly and mechanically.

\subsection{Step 1: verify the canonical identities}
\begin{itemize}
  \item Check the squared form \(J(x)=\frac{(x-1)^2}{2x}\) (Lemma~\ref{lem:J-squared}).
  \item Check the log--cosh identity \(J(\e^t)=\cosh(t)-1\) (Lemma~\ref{lem:J-log-cosh}).
  \item Check that \(\cosh\) satisfies d'Alembert (Lemma~\ref{lem:cosh-dalembert}).
\end{itemize}

\subsection{Step 2: check the functional-equation \(\Rightarrow\) ODE step}
\begin{itemize}
  \item Verify the uniform central-difference bootstrap (Lemma~\ref{lem:central-diff-C2}) and then
  apply it to d'Alembert to obtain \(H''(t)=\kappa_H H(t)\) (Lemma~\ref{lem:dalembert-curvature-ode}).
\end{itemize}

\subsection{Step 3: check the initial conditions}
\begin{itemize}
  \item From d'Alembert and \(H(0)=1\), verify \(H\) is even (Lemma~\ref{lem:dalembert-even2}).
  \item From evenness and differentiability, verify \(H'(0)=0\) (Lemma~\ref{lem:even-deriv0}).
\end{itemize}

\subsection{Step 4: check ODE uniqueness}
\begin{itemize}
  \item Verify the \(\kappa>0\) uniqueness lemma (Lemma~\ref{lem:ode-zero-pos}) and the \(\kappa<0\)
  uniqueness lemma (Lemma~\ref{lem:ode-zero-neg}).
  \item Apply them to \(f(t)=H(t)-\cosh(\sqrt{\kappa_H}t)\) (when \(\kappa_H>0\)) or
  \(f(t)=H(t)-\cos(\sqrt{-\kappa_H}t)\) (when \(\kappa_H<0\)) to conclude the classification
  Theorem~\ref{thm:cosh-unique}.
  \item Translate back to \(F\) on \(\Rp\) using \(x=\e^{\log x}\) (Corollary~\ref{cor:cost-unique}).
\end{itemize}

\section{Non-circularity checklist (methodological)}\label{app:noncirc}
The main results are purely symbolic and do not depend on any empirical numerals. In applications,
to preserve that property, we recommend the following non-circularity checklist:
\begin{itemize}
  \item \textbf{Separate modeling inputs from consequences.} Write the hypotheses (e.g., the
  d'Alembert identity and calibration) as explicit assumptions, and do not smuggle them via prose.
  \item \textbf{Quarantine numerics.} If numerical plots or evaluations are shown, keep them
  separate from theorem statements and label them as checks/illustrations, not derivations.
  \item \textbf{Avoid ``hidden scales''.} When an equation admits rescaling families, include a
  single explicit calibration to pin scale (as done here with \(\kappa(F)=1\)).
  \item \textbf{Minimize the hypothesis surface.} A smaller, named assumption set makes it easier
  for others to test whether an application truly satisfies the gate.
  \item \textbf{Provide a statement map.} Explicitly list what must be checked (as in
  Section~\ref{sec:reproducibility} and Appendix~\ref{app:checklist}).
\end{itemize}

\end{document}


