import Mathlib
import IndisputableMonolith.Thermodynamics.MaxEntFromCost

/-!
# Free Energy Monotonicity

This module proves that Recognition Free Energy (FR) is non-increasing
under RS dynamics (coarse-graining, equilibration).

This is the Recognition Science version of the Second Law of Thermodynamics.

## Main Results

1. **Coarse-graining decreases free energy**: Reducing state resolution cannot increase F_R
2. **Relaxation decreases free energy**: Time evolution toward equilibrium decreases F_R
3. **Arrow of Time**: The direction of time is defined by dF_R/dt â‰¤ 0

## The Key Insight

The monotonicity of F_R under coarse-graining is equivalent to:
- The Data Processing Inequality (DPI) for KL divergence
- The fact that the Gibbs distribution minimizes free energy

## References

- Cover & Thomas, "Elements of Information Theory", Ch. 2 (DPI)
- `Recognition-Science-Full-Theory.txt`, Section on Thermodynamic Stability
-/

namespace IndisputableMonolith
namespace Thermodynamics

open Real Cost RecognitionSystem

/-- f(x) = x log x is convex on (0, âˆ) -/
lemma mul_log_convexOn : ConvexOn â„ (Set.Ioi 0) (fun x => x * log x) := by
  apply convexOn_of_deriv2_nonneg (convex_Ioi 0)
  Â· apply ContinuousOn.mul continuousOn_id (continuousOn_log.mono (Set.subset_refl _))
  Â· intro x hx
    -- deriv (x log x) = log x + 1
    -- deriv (log x + 1) = 1/x
    have h_deriv : deriv (fun y => y * log y) x = log x + 1 := by
      rw [deriv_mul differentiableAt_id' (differentiableAt_log hx.ne')]
      simp [hx.ne']
    have h_deriv2 : deriv (fun y => deriv (fun z => z * log z) y) x = 1/x := by
      rw [deriv_congr_ev (Filter.EventuallyIn.ext (fun y hy => deriv_mul differentiableAt_id' (differentiableAt_log (Set.mem_Ioi.mp hy).ne')) (ğ“ x))]
      Â· simp [hx.ne']
        rw [deriv_add (differentiableAt_log hx.ne') (differentiableAt_const 1)]
        simp [deriv_log hx.ne']
      Â· exact Filter.EventuallyIn.of_mem (ğ“ x) (Ioi_mem_nhds hx)
    rw [h_deriv2]
    apply div_nonneg (by norm_num) hx.le

/-- **Log-Sum Inequality**: For positive sequences a, b with finite support,
    âˆ‘ aáµ¢ log(aáµ¢/báµ¢) â‰¥ (âˆ‘ aáµ¢) log((âˆ‘ aáµ¢)/(âˆ‘ báµ¢))

    This is a consequence of Jensen's inequality for the convex function f(x) = x log x.

    **PROOF STRUCTURE** (Cover & Thomas, "Elements of Information Theory", Theorem 2.7.1):
    1. Define weights wáµ¢ = báµ¢/B where B = âˆ‘ báµ¢. Then âˆ‘ wáµ¢ = 1.
    2. Define ratios xáµ¢ = aáµ¢/báµ¢. Then âˆ‘ wáµ¢ xáµ¢ = A/B where A = âˆ‘ aáµ¢.
    3. The function f(x) = x log x is convex on [0, âˆ).
    4. By Jensen's inequality: f(âˆ‘ wáµ¢ xáµ¢) â‰¤ âˆ‘ wáµ¢ f(xáµ¢).
    5. Substituting: (A/B) log(A/B) â‰¤ âˆ‘ wáµ¢ (xáµ¢ log xáµ¢).
    6. Multiplying by B: A log(A/B) â‰¤ âˆ‘ aáµ¢ log(aáµ¢/báµ¢).

    **STATUS**: SCAFFOLD (classical information-theoretic result, requires Jensen machinery) -/
theorem log_sum_inequality {Î¹ : Type*} [Fintype Î¹] [Nonempty Î¹] (a b : Î¹ â†’ â„)
    (ha : âˆ€ i, 0 < a i) (hb : âˆ€ i, 0 < b i) :
    âˆ‘ i, a i * log (a i / b i) â‰¥ (âˆ‘ i, a i) * log ((âˆ‘ i, a i) / (âˆ‘ i, b i)) := by
  let A := âˆ‘ i, a i
  let B := âˆ‘ i, b i
  have hA_pos : 0 < A := Finset.sum_pos (fun i _ => ha i) Finset.univ_nonempty
  have hB_pos : 0 < B := Finset.sum_pos (fun i _ => hb i) Finset.univ_nonempty
  let w := fun i => b i / B
  let x := fun i => a i / b i
  have hw_nonneg : âˆ€ i, 0 â‰¤ w i := fun i => div_nonneg (hb i).le hB_pos.le
  have hw_sum : âˆ‘ i, w i = 1 := by
    unfold w
    rw [â† Finset.sum_div, div_self hB_pos.ne']
  have hx_pos : âˆ€ i, x i âˆˆ Set.Ioi (0 : â„) := fun i => div_pos (ha i) (hb i)
  have h_center : âˆ‘ i, w i * x i = A / B := by
    unfold w x
    simp_rw [div_mul_div_cancel_left _ (hb _).ne']
    rw [â† Finset.sum_div]
  -- Apply Jensen
  have h_jensen := mul_log_convexOn.map_sum_le hw_nonneg hw_sum (fun i _ => hx_pos i)
  rw [h_center] at h_jensen
  -- h_jensen: (A/B) * log (A/B) â‰¤ âˆ‘ w i * (x i * log (x i))
  -- Multiply by B
  have h_final : B * ((A / B) * log (A / B)) â‰¤ B * (âˆ‘ i, w i * (x i * log (x i))) :=
    mul_le_mul_of_nonneg_left h_jensen hB_pos.le
  -- Simplify LHS
  have h_lhs : B * ((A / B) * log (A / B)) = A * log (A / B) := by
    field_simp [hB_pos.ne']
    ring
  -- Simplify RHS
  have h_rhs : B * (âˆ‘ i, w i * (x i * log (x i))) = âˆ‘ i, a i * log (a i / b i) := by
    rw [Finset.mul_sum]
    apply Finset.sum_congr rfl
    intro i _
    unfold w x
    field_simp [hB_pos.ne', (hb i).ne']
    ring
  rw [h_lhs] at h_final
  rw [h_rhs] at h_final
  exact h_final

/-- Log-Sum Inequality for conditional sums (fiberwise version).

    **PROOF STRUCTURE**: Reduce to the main log_sum_inequality by restricting
    to elements satisfying the predicate P. -/
theorem log_sum_inequality_fiber {Î¹ : Type*} [Fintype Î¹] (a b : Î¹ â†’ â„)
    (P : Î¹ â†’ Prop) [DecidablePred P]
    (ha_nonneg : âˆ€ i, 0 â‰¤ a i) (hb_nonneg : âˆ€ i, 0 â‰¤ b i)
    (ha_pos_fiber : âˆ€ i, P i â†’ 0 < a i) (hb_pos_fiber : âˆ€ i, P i â†’ 0 < b i)
    (h_nonempty : âˆƒ i, P i) :
    âˆ‘ i, (if P i then a i * log (a i / b i) else 0) â‰¥
    (âˆ‘ i, if P i then a i else 0) * log ((âˆ‘ i, if P i then a i else 0) / (âˆ‘ i, if P i then b i else 0)) := by
  let Î¹' := {i // P i}
  have h_fintype : Fintype Î¹' := inferInstance
  have h_nonempty' : Nonempty Î¹' := by
    obtain âŸ¨i, hiâŸ© := h_nonempty
    exact âŸ¨âŸ¨i, hiâŸ©âŸ©
  let a' := fun (i' : Î¹') => a i'.val
  let b' := fun (i' : Î¹') => b i'.val
  have ha' : âˆ€ i' : Î¹', 0 < a' i' := fun i' => ha_pos_fiber i'.val i'.property
  have hb' : âˆ€ i' : Î¹', 0 < b' i' := fun i' => hb_pos_fiber i'.val i'.property
  -- Apply log_sum_inequality to subtype
  have h_ls := log_sum_inequality a' b' ha' hb'
  -- Translate sums
  rw [Finset.sum_subtype (Finset.univ : Finset Î¹) (fun i => P i)] at h_ls
  Â· simp only [Finset.mem_univ, forall_true_left, a', b'] at h_ls
    have h_lhs : âˆ‘ i, (if P i then a i * log (a i / b i) else 0) = âˆ‘ i in (Finset.univ.filter P), a i * log (a i / b i) := by
      rw [Finset.sum_filter]
    have h_lhs_eq : (âˆ‘ i : Î¹', a i.val * log (a i.val / b i.val)) = âˆ‘ i, (if P i then a i * log (a i / b i) else 0) := by
      rw [Finset.sum_subtype]
      Â· simp only [Finset.mem_univ, forall_true_left]
      Â· intro i; simp only [Finset.mem_univ, forall_true_left, ite_self]
    have h_a_sum : (âˆ‘ i : Î¹', a i.val) = âˆ‘ i, if P i then a i else 0 := by
      rw [Finset.sum_subtype]
      Â· simp only [Finset.mem_univ, forall_true_left]
      Â· intro i; simp only [Finset.mem_univ, forall_true_left, ite_self]
    have h_b_sum : (âˆ‘ i : Î¹', b i.val) = âˆ‘ i, if P i then b i else 0 := by
      rw [Finset.sum_subtype]
      Â· simp only [Finset.mem_univ, forall_true_left]
      Â· intro i; simp only [Finset.mem_univ, forall_true_left, ite_self]
    rw [h_lhs_eq, h_a_sum, h_b_sum] at h_ls
    exact h_ls
  Â· intro i; simp only [Finset.mem_univ, forall_true_left]

/-! ## Distribution Coarse-Graining -/

/-- Push-forward of a probability distribution under a map Ï†: Î© â†’ Î©'.
    p'(Ï‰') = âˆ‘_{Ï‰ : Ï†(Ï‰) = Ï‰'} p(Ï‰) -/
noncomputable def push_forward (p : Î© â†’ â„) (Ï† : Î© â†’ Î©') : Î©' â†’ â„ :=
  fun Ï‰' => âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then p Ï‰ else 0

/-- Push-forward preserves non-negativity. -/
theorem push_forward_nonneg {p : Î© â†’ â„} (hp : âˆ€ Ï‰, 0 â‰¤ p Ï‰) (Ï† : Î© â†’ Î©') :
    âˆ€ Ï‰', 0 â‰¤ push_forward p Ï† Ï‰' := by
  intro Ï‰'
  unfold push_forward
  apply Finset.sum_nonneg
  intro Ï‰ _
  split_ifs <;> [apply hp; rfl]

/-- Push-forward preserves total probability. -/
theorem push_forward_sum_one {p : Î© â†’ â„} (hp_sum : âˆ‘ Ï‰, p Ï‰ = 1) (Ï† : Î© â†’ Î©') :
    âˆ‘ Ï‰', push_forward p Ï† Ï‰' = 1 := by
  unfold push_forward
  rw [Finset.sum_comm]
  simp only [Finset.sum_ite_eq, Finset.mem_univ, â†“reduceIte]
  exact hp_sum

/-- **Effective Cost**: The coarse-grained cost landscape.
    J'(Ï‰') = -TR * ln (âˆ‘_{Ï‰ : Ï†(Ï‰) = Ï‰'} exp(-J(Ï‰)/TR))
    This definition ensures the partition function is preserved under coarse-graining. -/
noncomputable def effective_cost (sys : RecognitionSystem) (X : Î© â†’ â„) (Ï† : Î© â†’ Î©') : Î©' â†’ â„ :=
  fun Ï‰' => -sys.TR * log (âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then exp (-Jcost (X Ï‰) / sys.TR) else 0)

/-- **THEOREM**: Partition function preservation under surjective coarse-graining.

    The partition function is preserved under coarse-graining.
    Z = âˆ‘_Ï‰ e^{-X_Ï‰/T} = âˆ‘_Ï‰' âˆ‘_{Ï‰âˆˆÏ†â»Â¹(Ï‰')} e^{-X_Ï‰/T}
    By defining the effective cost J' appropriately, the inner sum becomes e^{-J'_Ï‰'/T}.

    **STATUS**: PROVEN assuming every coarse state has a preimage. -/
theorem partition_function_preserved (sys : RecognitionSystem) (X : Î© â†’ â„) (Ï† : Î© â†’ Î©')
    (h_surj : Function.Surjective Ï†) :
    partition_function sys X = âˆ‘ Ï‰', exp (-effective_cost sys X Ï† Ï‰' / sys.TR) := by
  classical
  -- Unfold to Gibbs weights.
  unfold partition_function
  -- Show exp(-effective_cost/TR) recovers the fiber sum.
  have h_exp : âˆ€ Ï‰', exp (-effective_cost sys X Ï† Ï‰' / sys.TR) =
      âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then exp (-Jcost (X Ï‰) / sys.TR) else 0 := by
    intro Ï‰'
    unfold effective_cost
    -- Let s be the fiber sum.
    set s := âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then exp (-Jcost (X Ï‰) / sys.TR) else 0 with hs
    have hpos : 0 < s := by
      obtain âŸ¨Ï‰, hÏ‰âŸ© := h_surj Ï‰'
      have hterm : 0 < exp (-Jcost (X Ï‰) / sys.TR) := exp_pos _
      have hnonneg : âˆ€ Ï‰, 0 â‰¤ if Ï† Ï‰ = Ï‰' then exp (-Jcost (X Ï‰) / sys.TR) else 0 := by
        intro Ï‰
        split_ifs
        Â· exact (le_of_lt (exp_pos _))
        Â· exact le_rfl
      have hmem : Ï‰ âˆˆ (Finset.univ : Finset Î©) := by simp
      have hle : exp (-Jcost (X Ï‰) / sys.TR) â‰¤ s := by
        simpa [hs, hÏ‰] using
          (Finset.single_le_sum hnonneg (by simp [hmem, hÏ‰]))
      exact lt_of_lt_of_le hterm hle
    have hTR : sys.TR â‰  0 := sys.TR_pos.ne'
    -- Simplify exponent and use exp_log.
    have hlog : exp (-(-sys.TR * log s) / sys.TR) = exp (log s) := by
      field_simp [hTR]
      ring
    simp [hs, hlog, Real.exp_log hpos.ne'] 
  -- Swap sums and collapse the indicator.
  calc
    âˆ‘ Ï‰, exp (-Jcost (X Ï‰) / sys.TR)
        = âˆ‘ Ï‰', âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then exp (-Jcost (X Ï‰) / sys.TR) else 0 := by
            rw [Finset.sum_comm]
            simp [Finset.sum_ite_eq, Finset.mem_univ]
    _ = âˆ‘ Ï‰', exp (-effective_cost sys X Ï† Ï‰' / sys.TR) := by
            simp [h_exp]

/-- **THEOREM**: Data Processing Inequality for Relative Entropy.

    Coarse-graining reduces the distinguishability of distributions.
    D(p'â€–q') â‰¤ D(pâ€–q) where p', q' are push-forwards.

    **STATUS**: PROVEN using log-sum inequality on each fiber. -/
theorem data_processing_inequality (p q : Î© â†’ â„) (Ï† : Î© â†’ Î©')
    (hp : âˆ€ Ï‰, 0 < p Ï‰) (hq : âˆ€ Ï‰, 0 < q Ï‰)
    (hp_sum : âˆ‘ Ï‰, p Ï‰ = 1) (hq_sum : âˆ‘ Ï‰, q Ï‰ = 1) :
    kl_divergence (push_forward p Ï†) (push_forward q Ï†) â‰¤ kl_divergence p q := by
  classical
  have hp_nonneg : âˆ€ Ï‰, 0 â‰¤ p Ï‰ := fun Ï‰ => (hp Ï‰).le
  have hq_nonneg : âˆ€ Ï‰, 0 â‰¤ q Ï‰ := fun Ï‰ => (hq Ï‰).le
  -- Fiberwise log-sum inequality bounds each coarse term.
  have h_fiber_bound :
      âˆ€ Ï‰', (if push_forward p Ï† Ï‰' > 0 âˆ§ push_forward q Ï† Ï‰' > 0 then
              push_forward p Ï† Ï‰' * log (push_forward p Ï† Ï‰' / push_forward q Ï† Ï‰')
            else 0) â‰¤
            âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then p Ï‰ * log (p Ï‰ / q Ï‰) else 0 := by
    intro Ï‰'
    by_cases hne : âˆƒ Ï‰, Ï† Ï‰ = Ï‰'
    Â· have hp' : 0 < push_forward p Ï† Ï‰' := by
        obtain âŸ¨Ï‰, hÏ‰âŸ© := hne
        have hterm : 0 < p Ï‰ := hp Ï‰
        have hnonneg : âˆ€ Ï‰, 0 â‰¤ if Ï† Ï‰ = Ï‰' then p Ï‰ else 0 := by
          intro Ï‰; split_ifs <;> [exact (hp Ï‰).le, exact le_rfl]
        have hle : p Ï‰ â‰¤ push_forward p Ï† Ï‰' := by
          simpa [push_forward, hÏ‰] using
            (Finset.single_le_sum hnonneg (by simp) (by simp [hÏ‰]))
        exact lt_of_lt_of_le hterm hle
      have hq' : 0 < push_forward q Ï† Ï‰' := by
        obtain âŸ¨Ï‰, hÏ‰âŸ© := hne
        have hterm : 0 < q Ï‰ := hq Ï‰
        have hnonneg : âˆ€ Ï‰, 0 â‰¤ if Ï† Ï‰ = Ï‰' then q Ï‰ else 0 := by
          intro Ï‰; split_ifs <;> [exact (hq Ï‰).le, exact le_rfl]
        have hle : q Ï‰ â‰¤ push_forward q Ï† Ï‰' := by
          simpa [push_forward, hÏ‰] using
            (Finset.single_le_sum hnonneg (by simp) (by simp [hÏ‰]))
        exact lt_of_lt_of_le hterm hle
      have h_ls := log_sum_inequality_fiber p q (fun Ï‰ => Ï† Ï‰ = Ï‰')
        hp_nonneg hq_nonneg (fun Ï‰ hÏ‰ => hp Ï‰) (fun Ï‰ hÏ‰ => hq Ï‰) hne
      have h_term :
          (if push_forward p Ï† Ï‰' > 0 âˆ§ push_forward q Ï† Ï‰' > 0 then
              push_forward p Ï† Ï‰' * log (push_forward p Ï† Ï‰' / push_forward q Ï† Ï‰')
            else 0) =
          (âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then p Ï‰ else 0) *
            log ((âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then p Ï‰ else 0) / (âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then q Ï‰ else 0)) := by
        simp [push_forward, hp', hq']
      -- Combine.
      simpa [h_term] using h_ls
    Â· -- Empty fiber: both push-forward masses are 0, term is 0.
      have hpf : push_forward p Ï† Ï‰' = 0 := by
        unfold push_forward
        apply Finset.sum_eq_zero
        intro Ï‰ _
        split_ifs with h
        Â· exact (hne âŸ¨Ï‰, hâŸ©).elim
        Â· rfl
      have hqf : push_forward q Ï† Ï‰' = 0 := by
        unfold push_forward
        apply Finset.sum_eq_zero
        intro Ï‰ _
        split_ifs with h
        Â· exact (hne âŸ¨Ï‰, hâŸ©).elim
        Â· rfl
      simp [hpf, hqf]
  -- Sum the fiber bounds.
  have h_sum :
      kl_divergence (push_forward p Ï†) (push_forward q Ï†) â‰¤
        âˆ‘ Ï‰', âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then p Ï‰ * log (p Ï‰ / q Ï‰) else 0 := by
    unfold kl_divergence
    apply Finset.sum_le_sum
    intro Ï‰' _
    exact h_fiber_bound Ï‰'
  -- Swap sums and collapse indicators.
  have h_swap :
      (âˆ‘ Ï‰', âˆ‘ Ï‰, if Ï† Ï‰ = Ï‰' then p Ï‰ * log (p Ï‰ / q Ï‰) else 0) =
        âˆ‘ Ï‰, p Ï‰ * log (p Ï‰ / q Ï‰) := by
    rw [Finset.sum_comm]
    simp [Finset.sum_ite_eq, Finset.mem_univ]
  -- Finish by rewriting KL with positivity.
  have h_kl : kl_divergence p q = âˆ‘ Ï‰, p Ï‰ * log (p Ï‰ / q Ï‰) := by
    unfold kl_divergence
    apply Finset.sum_congr rfl
    intro Ï‰ _
    simp [hp Ï‰, hq Ï‰]
  linarith [h_sum, h_swap, h_kl]

/-- **THEOREM**: Free energy monotonicity under coarse-graining.

    Reducing state resolution cannot increase the Recognition Free Energy.
    This is the statistical mechanics version of the Second Law.

    **STATUS**: PROVEN assuming positivity and Gibbs/push-forward alignment. -/
theorem coarse_graining_decreases_free_energy
    (sys : RecognitionSystem) (X : Î© â†’ â„)
    (p : ProbabilityDistribution Î©) (Ï† : Î© â†’ Î©')
    (hp_pos : âˆ€ Ï‰, 0 < p.p Ï‰)
    (h_gibbs_push : âˆ€ Ï‰',
      gibbs_measure sys (effective_cost sys X Ï†) Ï‰' =
        push_forward (gibbs_measure sys X) Ï† Ï‰')
    (h_gibbs_FR_eq :
      recognition_free_energy sys (gibbs_measure sys (effective_cost sys X Ï†))
        (effective_cost sys X Ï†) =
      recognition_free_energy sys (gibbs_measure sys X) X) :
    let p' := push_forward p.p Ï†
    let J' := effective_cost sys X Ï†
    recognition_free_energy sys p' J' â‰¤ recognition_free_energy sys p.p X := by
  intro p' J'
  classical
  -- Package the push-forward as a probability distribution.
  let p'pd : ProbabilityDistribution Î©' :=
    { p := p'
      nonneg := push_forward_nonneg p.nonneg Ï†
      sum_one := push_forward_sum_one p.sum_one Ï† }
  -- KL identity for fine and coarse levels.
  have hkl_p' := free_energy_kl_identity (sys:=sys) (X:=J') (q:=p'pd)
  have hkl_p := free_energy_kl_identity (sys:=sys) (X:=X) (q:=p)
  -- Data processing inequality on KL divergence.
  have h_dpi :=
    data_processing_inequality (p:=p.p) (q:=gibbs_measure sys X) (Ï†:=Ï†)
      hp_pos (fun Ï‰ => gibbs_measure_pos sys X Ï‰)
      p.sum_one (gibbs_measure_sum_one sys X)
  have h_pf : push_forward (gibbs_measure sys X) Ï† = gibbs_measure sys J' := by
    funext Ï‰'; symm; exact h_gibbs_push Ï‰'
  have hkl_dec : kl_divergence p' (gibbs_measure sys J') â‰¤
      kl_divergence p.p (gibbs_measure sys X) := by
    simpa [p', h_pf] using h_dpi
  -- Compare free energies via KL identity.
  have h_diff :
      recognition_free_energy sys p' J' - recognition_free_energy sys p.p X =
        sys.TR * (kl_divergence p' (gibbs_measure sys J') -
                  kl_divergence p.p (gibbs_measure sys X)) +
        (recognition_free_energy sys (gibbs_measure sys J') J' -
         recognition_free_energy sys (gibbs_measure sys X) X) := by
    linarith [hkl_p', hkl_p]
  have hTR : 0 â‰¤ sys.TR := le_of_lt sys.TR_pos
  have h_gibbs_eq :
      recognition_free_energy sys (gibbs_measure sys J') J' -
      recognition_free_energy sys (gibbs_measure sys X) X = 0 := by
    simpa [h_gibbs_FR_eq]
  have h_nonpos :
      recognition_free_energy sys p' J' - recognition_free_energy sys p.p X â‰¤ 0 := by
    rw [h_diff, h_gibbs_eq, add_zero]
    have : kl_divergence p' (gibbs_measure sys J') -
             kl_divergence p.p (gibbs_measure sys X) â‰¤ 0 := by
      linarith [hkl_dec]
    exact mul_nonpos_of_nonneg_of_nonpos hTR this
  linarith

/-- **Arrow of Time**: The direction of time in RS is defined by decreasing F_R. -/
def rs_arrow_of_time (sys : RecognitionSystem) (X : Î© â†’ â„) : Prop :=
  âˆ€ (tâ‚ tâ‚‚ : â„), tâ‚ â‰¤ tâ‚‚ â†’
    âˆ€ (p : â„ â†’ ProbabilityDistribution Î©),
    -- If p(t) evolves via RS dynamics (approaching Gibbs equilibrium)
    -- then F_R decreases
    recognition_free_energy sys (p tâ‚‚).p X â‰¤ recognition_free_energy sys (p tâ‚).p X

/-- **H-Theorem for Recognition**: The free energy decreases toward equilibrium.

    If the system starts in any state and relaxes toward the Gibbs measure,
    then F_R decreases monotonically until it reaches F_R(Gibbs).

    **Proof**: Uses the variational identity F_R(p) = F_R(Gibbs) + TR * D_KL(p || Gibbs).
    If D_KL decreases monotonically under the dynamics (h_relax hypothesis),
    then F_R must also decrease monotonically.

    This is the Recognition Science version of Boltzmann's H-theorem. -/
theorem h_theorem_recognition
    (sys : RecognitionSystem) (X : Î© â†’ â„)
    (p : â„ â†’ ProbabilityDistribution Î©)
    (tâ‚ tâ‚‚ : â„) (h : tâ‚ â‰¤ tâ‚‚)
    -- Assume p(t) is a valid relaxation trajectory
    (h_relax : âˆ€ t Îµ, Îµ > 0 â†’
      kl_divergence (p (t + Îµ)).p (gibbs_measure sys X) â‰¤
      kl_divergence (p t).p (gibbs_measure sys X)) :
    recognition_free_energy sys (p tâ‚‚).p X â‰¤ recognition_free_energy sys (p tâ‚).p X := by
  -- F_R(p) = F_R(Gibbs) + TR * D_KL(p || Gibbs)
  have h_kl_identityâ‚ := free_energy_kl_identity sys X (p tâ‚)
  have h_kl_identityâ‚‚ := free_energy_kl_identity sys X (p tâ‚‚)

  by_cases heq : tâ‚ = tâ‚‚
  Â· rw [heq]
  Â· have hlt : tâ‚ < tâ‚‚ := lt_of_le_of_ne h heq
    have h_kl_dec : kl_divergence (p tâ‚‚).p (gibbs_measure sys X) â‰¤
                    kl_divergence (p tâ‚).p (gibbs_measure sys X) := by
      have := h_relax tâ‚ (tâ‚‚ - tâ‚) (sub_pos.mpr hlt)
      simp only [add_sub_cancel] at this
      exact this

    -- F_R(p tâ‚‚) â‰¤ F_R(p tâ‚)  iff  F_R(p tâ‚‚) - F_R(p tâ‚) â‰¤ 0
    rw [â† sub_nonpos]
    have : recognition_free_energy sys (p tâ‚‚).p X - recognition_free_energy sys (p tâ‚).p X =
           sys.TR * (kl_divergence (p tâ‚‚).p (gibbs_measure sys X) - kl_divergence (p tâ‚).p (gibbs_measure sys X)) := by
      linarith [h_kl_identityâ‚, h_kl_identityâ‚‚]
    rw [this]
    apply mul_nonpos_of_nonneg_of_nonpos
    Â· exact sys.TR_pos.le
    Â· linarith [h_kl_dec]

/-- Status report for Free Energy Monotonicity module. -/
def free_energy_monotone_status : List (String Ã— String) :=
  [ ("push_forward preserves prob", "THEOREM")
  , ("partition_function preserved", "SCAFFOLD")
  , ("data_processing_inequality", "SCAFFOLD")
  , ("coarse_graining_decreases_free_energy", "SCAFFOLD")
  , ("h_theorem_recognition", "PROVEN")
  ]

#eval free_energy_monotone_status

end Thermodynamics
end IndisputableMonolith
